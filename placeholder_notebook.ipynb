{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Project Title**\n",
    "#### *Project Subtitle*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis;\n",
    "\n",
    "Project thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in data\n",
    "# (potentially?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beginning EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ramona's Code Space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*End Code Space*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Christian's Code Space**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing necessary libraries (uncomment if needed)\n",
    "# %pip install gdown --quiet\n",
    "# ! pip install evaluate --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and dependencies\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# json\n",
    "import json\n",
    "\n",
    "# gdown\n",
    "import gdown\n",
    "\n",
    "from tqdm import tqdm\n",
    "import unicodedata\n",
    "\n",
    "import torch\n",
    "from datasets import load_metric\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import transformers\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments,Trainer\n",
    "from transformers import pipeline\n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "import accelerate\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resources path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to access datasets through `gdown`\n",
    "def fetch_data(set):\n",
    "    # Declaring `url` and `output` for dataset\n",
    "    match set:\n",
    "        case 'business':\n",
    "            url = 'https://drive.google.com/file/d/1t-_rOjZ8oMqPcMJunVaMgY3OEbhnuSCv/view?usp=sharing'\n",
    "            output = 'Resources/business_dataset.csv'\n",
    "        case 'checkin':\n",
    "            url = 'https://drive.google.com/file/d/1_AVWp31ymfvf4QgTiMN_WLAeapfr0omf/view?usp=sharing'\n",
    "            output = 'Resources/checkin_dataset.csv'\n",
    "        case 'reviews':\n",
    "            url = 'https://drive.google.com/file/d/1L8rFjhOQyU90Ycr9t_OLA70vCYM0e7ck/view?usp=sharing'\n",
    "            output = 'Resources/reviews_dataset.csv'\n",
    "        case 'tip':\n",
    "            url = 'https://drive.google.com/file/d/1LMkCi5AFC_58_m7ELmn1hR8YDykuXwqq/view?usp=sharing'\n",
    "            output = 'Resources/tip_dataset.csv'\n",
    "        case 'user':\n",
    "            url = 'https://drive.google.com/file/d/1kQ522qcod7AjD5DO9vj8qFcSKxwJCDrO/view?usp=sharing'\n",
    "            output = 'Resources/user_dataset.csv'\n",
    "        case _:\n",
    "            print('Invalid dataset selected, please try again')\n",
    "            return None\n",
    "    \n",
    "    # Downloading dataset\n",
    "    gdown.download(url, output, fuzzy=True, quiet=True)\n",
    "\n",
    "    # Reading in the dataset\n",
    "    df = pd.read_csv(output, low_memory=False)\n",
    "\n",
    "    # Returning the dataset\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching/reading in all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching all datasets (uncomment for first run of code)\n",
    "# business_df = fetch_data('business')\n",
    "# checkin_df = fetch_data('checkin')\n",
    "# reviews_df = fetch_data('reviews')\n",
    "# tips_df = fetch_data('tip')\n",
    "# user_df = fetch_data('user')\n",
    "\n",
    "# Reading in all datasets (uncomment if data already fetched)\n",
    "business_df = pd.read_csv('./Resources/business_dataset.csv')\n",
    "checkin_df = pd.read_csv('./Resources/checkin_dataset.csv')\n",
    "reviews_df = pd.read_csv('./Resources/reviews_dataset.csv')\n",
    "tips_df = pd.read_csv('./Resources/tip_dataset.csv')\n",
    "user_df = pd.read_csv('./Resources/user_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Business dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'> Description:</font> \n",
    "**Contains business data including location data, attributes, and categories.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkin dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'> Description:</font>\n",
    "**Checkins on a business.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<font color='orange'> Notes:</font>**\n",
    "**The team has determined this dataset would not add any value to our training data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reviews dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = 'blue'>Description:</font>\n",
    "**Contains full review text data including the user_id that wrote the review and the business_id the review is written for.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Na count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping columns:\n",
    "- **review_id**\n",
    "- **useful**\n",
    "- **funny**\n",
    "- **cool**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.drop(columns = ['review_id','useful','funny','cool'],\n",
    "                inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming the 'text' field to 'review'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.rename(columns = {'text':'review'},inplace = True)\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<font color='orange'> Notes:</font>**\n",
    "- **review_id: Eliminated due to low informational value.**\n",
    "- **useful: Eliminated due to low relevance.**\n",
    "- **funny: Eliminated due to low relevance.**\n",
    "- **cool: Eliminated due to low relevance.**\n",
    "\n",
    "  **The *<font color='green'>'business_id'</font>* feature will be used as the identifier, *<font color='green'>'stars'</font>* is the rating metric and the *<font color='grey'>'review'</font>*  field encapsulates**<br>\n",
    "  **the data to be processed. the *<font color='green'>'date'</font>* variable is in place if time series analysis is needed.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tips dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'>Description:</font>\n",
    "**Tips written by a user on a business. Tips are shorter than reviews and tend to convey quick suggestions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping columns:\n",
    "- **compliment_count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_df.drop(columns = ['compliment_count'],\n",
    "             inplace =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming the 'text' column to 'recommendations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_df.rename(columns = {'text':'recommendations'},inplace = True)\n",
    "tips_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<font color='orange'> Notes:</font>**\n",
    "- **compliment_count: Eliminated due to low informational value.**\n",
    "\n",
    "\n",
    " **Since this data set has recommendations from the user to improve customer experience the 'recommendations' field could be a useful target variable.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = 'blue'>Note:</font>\n",
    "**User data including the user's friend mapping and all the metadata associated with the user.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<font color='orange'> Notes:</font>**\n",
    "**This data set will not be included in the training data to preserve user anonimity.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<font color = 'darkgrey'>Merging the reviews data set and the business data set</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = 'blue'>Description:</font>\n",
    "**This data set contains the fields that will be used to train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = reviews_df.merge(business_df,how='left',on = 'business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Na count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_prcnt = data_df[['attributes','categories','hours']].isna().sum()/data_df.shape[0]*100\n",
    "nas_df = pd.DataFrame(na_prcnt, columns=['percentage'])\n",
    "nas_df = nas_df.transpose()\n",
    "nas_df.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data = nas_df).set_title('Na percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<font color='orange'> Notes:</font>**\n",
    "**After consulting with the team we decided to drop all three columns.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping rows with na values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.drop(columns = ['attributes','categories','hours'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *<font color='grey'>stars_x* and *<font color='grey'>stars_y* comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.loc[data_df['stars_x'] != data_df['stars_y']][['stars_x','stars_y']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *<font color='grey'>stars_x* and *<font color='grey'>stars_y*  for the same customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.loc[data_df['business_id']=='XQfwVwDr-v0ZS3_CbbE5Xw'][['stars_x','stars_y']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *<font color='grey'>stars_x* average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(data_df.loc[data_df['business_id']=='XQfwVwDr-v0ZS3_CbbE5Xw']['stars_x'].mean(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<font color='orange'> Notes:</font>**\n",
    "**Because** *<font color='grey'> star_y</font>* **represents the average star rating, renaming** *<font color='grey'> star_y:</font>* **to:** *<font color='grey'> star_avg:</font>*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.rename(columns={'stars_y':'stars_avg','stars_x':'stars'},inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping is_open feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "sns.countplot(data_df,\n",
    "             x='is_open',\n",
    "             hue = 'is_open',\n",
    "             ax = ax).set_title('is_open Feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### droppin is_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.drop(columns = ['is_open'],inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<font color='orange'> Notes:</font>**\n",
    "**After cosulting with the team we decided to drop this feature due low informational value and feature imbalance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# //////////////////////////////////////////////////////////////////////////////////////////////////"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<font color='darkgrey'>Merging with the tips data set exploration</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = 'blue'>Description:</font>\n",
    "**Contains customer recommendatins to improve experience**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantity of unique business_id in the tips data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(tips_df['business_id'].unique().shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantity of unique business_id in  data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['business_id'].unique().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset of *<font color='grey'>business_id</font>* in *<font color='grey'>data_df</font>* not found in *<font color='grey'>tips_df</font>*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_tips_df = data_df[~data_df['business_id'].isin(tips_df['business_id'])]\n",
    "no_tips_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of *<font color='grey'>business_id</font>* in *<font color='grey'>data_df</font>* not found in *<font color='grey'>tips_df</font>*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_tips_df = data_df[~data_df['business_id'].isin(tips_df['business_id'])]\n",
    "not_found = no_tips_df['business_id'].unique().shape[0]\n",
    "print(f'Number of business_ids in tips_df not found in data_df: {not_found}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_df.loc[tips_df['business_id'] == no_tips_df['business_id'].iloc[33]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.merge(tips_df,data_df,\n",
    "                   on = ['business_id','user_id'],\n",
    "                   how = 'inner')\n",
    "                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison review vs. recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[['review','recommendations']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **<font color='orange'> Notes:</font>**\n",
    "**The <font color='grey'>data_df</font> has approximately <font color='green'>7 million</font> entries and <font color='grey'>tips_df</font> about <font color='green'>1 million</font> after merging them we end up the a little under half a million**.<br>\n",
    "**In the comparison above I don't see a difference between a review from the *reviews data set* and a recommendation from the *tips data set***.<br>\n",
    "**As shown above we stand to loose a significant amount of data if a merge is performed**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ///////////////////////////////////////////////////////////////////////////////////////////////////"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkgrey'>Final Data Overview</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping the user_id column to preserv user anonimity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.drop(columns = ['user_id'],inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Na verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Narrowing data to trainable scope\n",
    "def sample_stars(df, val):\n",
    "    df = df[df['stars'] == val].copy()\n",
    "    if val >= 4:\n",
    "        df = df.sample(100)\n",
    "    elif val <= 2:\n",
    "        df = df.sample(100)\n",
    "    else:\n",
    "        df = df.sample(200)\n",
    "    df.reset_index(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_5 = sample_stars(data_df,5)\n",
    "sample_4 = sample_stars(data_df,4)\n",
    "sample_3 = sample_stars(data_df,3)\n",
    "sample_2 = sample_stars(data_df,2)\n",
    "sample_1 = sample_stars(data_df,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_df = pd.concat(\n",
    "    [\n",
    "        sample_1,\n",
    "        sample_2,\n",
    "        sample_3,\n",
    "        sample_4,\n",
    "        sample_5\n",
    "    ], axis=0, ignore_index=True\n",
    ")\n",
    "\n",
    "sample_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_df['stars'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_df['stars']= sample_data_df['stars'].replace(to_replace=[1,2], value=0)\n",
    "sample_data_df['stars']= sample_data_df['stars'].replace(to_replace=3, value=1)\n",
    "sample_data_df['stars']= sample_data_df['stars'].replace(to_replace=[4,5], value=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_df['stars'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_df.rename(columns={'review':'text','stars':'label'},inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing accented characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accented_chars(text):\n",
    "  text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "  return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    # Remove mentions\n",
    "    text = re.sub(r\"@\\S+\", \"\", text)\n",
    "    # Remove hashtags\n",
    "    text = re.sub(r\"#\\S+\", \"\", text)\n",
    "    # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_reviews(reviews):\n",
    "  stop_words = set(stopwords.words('english'))  \n",
    "  norm_reviews = []\n",
    "  for review in tqdm(reviews):\n",
    "    \n",
    "    # Clean text\n",
    "    review = clean_text(review)\n",
    "    # remove extra newlines and convert them to spaces\n",
    "    review = review.translate(review.maketrans(\"\\n\\t\\r\", \"   \"))\n",
    "    # lower case\n",
    "    review = review.lower()\n",
    "    # remove accents\n",
    "    review = remove_accented_chars(review)\n",
    "    # remove special characters\n",
    "    review = re.sub(r'[^a-zA-Z0-9\\s]', '', review, flags=re.I|re.A)\n",
    "    # remove extra whitespaces\n",
    "    review = re.sub(' +', ' ', review)\n",
    "    # remove leading and training whitespaces\n",
    "    review = review.strip()\n",
    "\n",
    "    review_tokens = word_tokenize(review)\n",
    "    review = [w for w in review_tokens if not w in stop_words]\n",
    "    review = ' '.join(review)\n",
    "      \n",
    "    norm_reviews.append(review)\n",
    "\n",
    "  return norm_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_function(review):\n",
    "    # Extracting text\n",
    "    text = review['text']\n",
    "\n",
    "    # Tokenize text with truncation and padding\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        # Truncate to max_length from the right by default\n",
    "        truncation=True,\n",
    "        # Pad to the maximum length\n",
    "        padding=\"max_length\",\n",
    "        # Maximum sequence length for BERT models\n",
    "        max_length=512,\n",
    "        # Assuming you are using PyTorch; change to 'np' if necessary\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load multiple metrics\n",
    "accuracy_metric = load(\"accuracy\")\n",
    "precision_metric = load(\"precision\")\n",
    "recall_metric = load(\"recall\")\n",
    "f1_metric = load(\"f1\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    predictions, labels = pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    precision = precision_metric.compute(predictions=predictions, references=labels, average='weighted')\n",
    "    recall = recall_metric.compute(predictions=predictions, references=labels, average='weighted')\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels, average='weighted')\n",
    "    \n",
    "    # Return a dictionary containing all metrics\n",
    "    return {\n",
    "        \"accuracy\": accuracy[\"accuracy\"],\n",
    "        \"precision\": precision[\"precision\"],\n",
    "        \"recall\": recall[\"recall\"],\n",
    "        \"f1\": f1[\"f1\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample_data_df['text']\n",
    "y = sample_data_df['label']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train[:100]\n",
    "# y_train = y_train[:100]\n",
    "\n",
    "# X_test = X_test[:30]\n",
    "# y_test = y_test[:30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_train_reviews = pre_process_reviews(X_train)\n",
    "norm_test_reviews = pre_process_reviews(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_dict({'label':y_train.to_list(),'text':norm_train_reviews})\n",
    "test_dataset = Dataset.from_dict({'label':y_test.to_list(),'text':norm_test_reviews})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pretrained model\n",
    "model_checkpoint = 'distilbert-base-uncased'\n",
    "\n",
    "#Defining label classes\n",
    "id_to_label = {0:'Negative', 1:'Neutral', 2:'Positive'}\n",
    "label_to_id = {'Negative':0, 'Neutral': 1,'Positive':2}\n",
    "\n",
    "#Model definiftion\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels = 3,\n",
    "    id2label = id_to_label,\n",
    "    label2id =label_to_id \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(tokenizer_function, batched=True)\n",
    "tokenized_test_dataset = train_dataset.map(tokenizer_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'model_sentiment'\n",
    "lr = 2e-5\n",
    "batch_size = 32\n",
    "EPOCHS = 3\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = output_dir,\n",
    "    learning_rate = lr,\n",
    "    per_device_train_batch_size = batch_size,\n",
    "    per_device_eval_batch_size = batch_size*2,\n",
    "    num_train_epochs = EPOCHS,\n",
    "    weight_decay = 0.01,\n",
    "    save_strategy = 'epoch',\n",
    "    evaluation_strategy = 'epoch',\n",
    "    logging_steps = 10,\n",
    "    load_best_model_at_end = True,\n",
    "    # Enable mixed precision\n",
    "    fp16=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "                  model = model,\n",
    "                  args = training_args,\n",
    "                  train_dataset = tokenized_train_dataset,\n",
    "                  eval_dataset = tokenized_test_dataset,\n",
    "                  tokenizer = tokenizer,\n",
    "                  compute_metrics = compute_metrics,\n",
    "                  data_collator = data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model_results = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial fine-tuning of pretrained model yielded accuracy values of ~40-50%.\n",
    "Final yielded accruacy values are around XXX%.\n",
    "\n",
    "Steps taken to improve accuracy (in something close to resembling order of application);\n",
    "* Changed pre-trained model from `distilbert-base-uncased` to `MarieAngeA13/Sentiment-Analysis-BERT`\n",
    "* Adjusted sample sizes of data (from ~100 records total to a balanced sample set with equal representation for all ratings)\n",
    "* Updates to text cleaning to include more web-present syntax (eg; mentions, multiple spaces, hashtags, and web address elements)\n",
    "* Adjustted syntax and arguments of tokenizer function and application of it\n",
    "* Adjusted training arguments to better align with our BERT-based model\n",
    "* Added additional metrics for better understanding of neccessary optimization\n",
    "* Increased sample data size, again, and removed subset step entirely\n",
    "* Adjusted batch size and epochs\n",
    "* Move back to `distilbert-base-uncased` and adjusted learning tokenizers, learning rate, logging steps, and such hyperparameters accordingly\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'Sentiment_Analysis/model'\n",
    "tokenizer_path =  'Sentiment_Analysis/tokenizer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Model & Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(model_path)\n",
    "tokenizer.save_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading and Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoModelForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "\n",
    "roberto = pipeline('sentiment-analysis',model=model,tokenizer=tokenizer)\n",
    "roberto(sample_data_df.iloc[0]['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*End Code Space*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries (uncomment if needed)\n",
    "# ! pip install selenium --quiet\n",
    "# ! pip install webdriver-manager --quiet\n",
    "# ! pip install beautifulsoup4 --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Leigh's Code Space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*End Code Space*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Angelica's Code Space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "\n",
    "# # create a function to get the address of the each location and add it to a dataframe \n",
    "# def address_Addition(business,address1,new_df):\n",
    "#     new_df['business_name'] = business\n",
    "#     address_list = address1.split(',')\n",
    "#     new_df['address'] = address_list[0]\n",
    "#     new_df['city'] = address_list[1]\n",
    "#     return new_df\n",
    "\n",
    "# initiate driver\n",
    "driver = webdriver.Chrome(service = ChromeService(ChromeDriverManager().install()))\n",
    "\n",
    "# url list with business locations\n",
    "#url = ['https://www.google.com/maps/place/Tim+Hortons/@43.7607366,-79.5321831,14z/data=!4m10!1m2!2m1!1stim+hortons!3m6!1s0x882b31d93eab2809:0xa9ea7bb65f9da6ec!8m2!3d43.7607366!4d-79.4992241!15sCgt0aW0gaG9ydG9ucyIDiAEBWg0iC3RpbSBob3J0b25zkgEKcmVzdGF1cmFudOABAA!16s%2Fg%2F1vyxk0xz','https://www.google.com/maps/place/Tim+Hortons/@43.7607366,-79.5321831,14z/data=!4m10!1m2!2m1!1stim+hortons!3m6!1s0x882b302d70a29891:0xc279061e4a5c71bc!8m2!3d43.756124!4d-79.5152637!15sCgt0aW0gaG9ydG9ucyIDiAEBWg0iC3RpbSBob3J0b25zkgEKcmVzdGF1cmFudOABAA!16s%2Fg%2F1td38wkb']\n",
    "url = [\"https://www.google.com/maps/place/McDonald's/@43.7607329,-79.5321831,14z/data=!4m10!1m2!2m1!1sMcDonald's!3m6!1s0x882b31e6d3859eb1:0xc92a9af2d1385093!8m2!3d43.7624131!4d-79.490243!15sCgpNY0RvbmFsZCdzIgOIAQFaDCIKbWNkb25hbGQnc5IBFGZhc3RfZm9vZF9yZXN0YXVyYW504AEA!16s%2Fg%2F1hc604hjv?entry=ttu\"]\n",
    "\n",
    "\n",
    "driver.get(url[0])\n",
    "time.sleep(5)\n",
    "\n",
    "# Find the address of the location\n",
    "response = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "business_name = response.find('h1',class_='DUwDvf lfPIob').text\n",
    "business_name\n",
    "\n",
    "\n",
    "\n",
    "    # address = response.find('div',class_= 'rogA2c').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd\n",
    "\n",
    "# create a function to get the address of the each location and add it to a dataframe \n",
    "def business_Overview(business,avg_rating,address1,new_df):\n",
    "    new_df['business_name'] = business\n",
    "    new_df['avg_rating'] = avg_rating\n",
    "    address_list = address1.split(',')\n",
    "    new_df['address'] = address_list[0]\n",
    "    new_df['city'] = address_list[1]\n",
    "    return new_df\n",
    "\n",
    "# initiate driver\n",
    "driver = webdriver.Chrome(service = ChromeService(ChromeDriverManager().install()))\n",
    "\n",
    "# url list with business locations\n",
    "#url = ['https://www.google.com/maps/place/Tim+Hortons/@43.7607366,-79.5321831,14z/data=!4m10!1m2!2m1!1stim+hortons!3m6!1s0x882b31d93eab2809:0xa9ea7bb65f9da6ec!8m2!3d43.7607366!4d-79.4992241!15sCgt0aW0gaG9ydG9ucyIDiAEBWg0iC3RpbSBob3J0b25zkgEKcmVzdGF1cmFudOABAA!16s%2Fg%2F1vyxk0xz','https://www.google.com/maps/place/Tim+Hortons/@43.7607366,-79.5321831,14z/data=!4m10!1m2!2m1!1stim+hortons!3m6!1s0x882b302d70a29891:0xc279061e4a5c71bc!8m2!3d43.756124!4d-79.5152637!15sCgt0aW0gaG9ydG9ucyIDiAEBWg0iC3RpbSBob3J0b25zkgEKcmVzdGF1cmFudOABAA!16s%2Fg%2F1td38wkb']\n",
    "url = [\"https://www.google.com/maps/place/McDonald's/@43.7607329,-79.5321831,14z/data=!4m10!1m2!2m1!1sMcDonald's!3m6!1s0x882b31e6d3859eb1:0xc92a9af2d1385093!8m2!3d43.7624131!4d-79.490243!15sCgpNY0RvbmFsZCdzIgOIAQFaDCIKbWNkb25hbGQnc5IBFGZhc3RfZm9vZF9yZXN0YXVyYW504AEA!16s%2Fg%2F1hc604hjv?entry=ttu\"]\n",
    "\n",
    "\n",
    "#create for loop to parse through the different locations in the url list above\n",
    "c = 0\n",
    "for i in range(0,len(url)):\n",
    "    c = c+1\n",
    "    driver.get(url[i])\n",
    "    time.sleep(5)\n",
    "\n",
    "    # Find the address of the location\n",
    "    response = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    business_name = response.find('h1',class_='DUwDvf lfPIob').text\n",
    "    avg_rating = response.find('div',class_='fontDisplayLarge').text\n",
    "    address = response.find('div',class_= 'rogA2c').text\n",
    "    driver.find_element('xpath','//*[@id=\"QA0Szd\"]/div/div/div[1]/div[3]/div/div[1]/div/div/div[2]/div[2]/div[1]/div[1]/div[2]/div/div[1]/div[2]').click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    # By default, only 10 reviews can be extracted - to extract more reviews we have to scroll down the apge\n",
    "    SCROLL_PAUSE_TIME = 5\n",
    "\n",
    "    # Get scroll height\n",
    "    last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "\n",
    "    number = 0\n",
    "\n",
    "    while True:\n",
    "        number = number+1\n",
    "\n",
    "        # Scroll down to bottom\n",
    "\n",
    "        #old_==ele = driver.find_element('xpath','//*[@id=\"QA0Szd\"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]')\n",
    "        ele = driver.find_element('xpath','//*[@id=\"QA0Szd\"]/div/div/div[1]/div[3]/div/div[1]/div/div/div[2]')\n",
    "        driver.execute_script('arguments[0].scrollBy(0, 5000);', ele)\n",
    "\n",
    "        # Wait to load page\n",
    "        time.sleep(SCROLL_PAUSE_TIME)\n",
    "\n",
    "        # Calculate new scroll height and compare with last scroll height\n",
    "        #print(f'last height: {last_height}')\n",
    "\n",
    "        ele = driver.find_element('xpath','//*[@id=\"QA0Szd\"]/div/div/div[1]/div[3]/div/div[1]/div/div/div[2]')\n",
    "\n",
    "        new_height = driver.execute_script(\"return arguments[0].scrollHeight\", ele)\n",
    "\n",
    "        #print(f'new height: {new_height}')\n",
    "\n",
    "        if number == 5:\n",
    "            break\n",
    "\n",
    "        if new_height == last_height:\n",
    "            break\n",
    "\n",
    "        #print('cont')\n",
    "        last_height = new_height\n",
    "    next_item = driver.find_elements('xpath','//*[@id=\"QA0Szd\"]/div/div/div[1]/div[3]/div/div[1]/div/div/div[2]/div[9]')\n",
    "    time.sleep(3)\n",
    "\n",
    "    #expand review by click on 'more' button\n",
    "    for i in next_item:\n",
    "        button = i.find_elements(By.TAG_NAME,'button')\n",
    "        for m in button:\n",
    "            if m.text == \"More\":\n",
    "                m.click()\n",
    "        time.sleep(5)\n",
    "\n",
    "    response = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    next_2 = response.find_all('div',class_ = 'jftiEf')\n",
    "\n",
    "    #get review by passing it to a dictionary\n",
    "    def get_review_summary(result_set):\n",
    "        rev_dict = {\n",
    "            'Review Name': [],\n",
    "            'Review Text' : [],\n",
    "            'Review Rating' : []}\n",
    "\n",
    "        for result in result_set:\n",
    "            review_name = result.find(class_='d4r55').text\n",
    "            review_text = result.find('span',class_='wiI7pd').text\n",
    "            review_rating = result.find(class_='kvMYJc')['aria-label']\n",
    "            rev_dict['Review Name'].append(review_name)\n",
    "            rev_dict['Review Text'].append(review_text)\n",
    "            rev_dict['Review Rating'].append(review_rating)\n",
    "        \n",
    "         \n",
    "        return(pd.DataFrame(rev_dict))\n",
    "\n",
    "    df = get_review_summary(next_2)\n",
    "    if c == 1:\n",
    "        df1 = df.copy()\n",
    "        final_df = business_Overview(business_name,avg_rating,address,df1)\n",
    "    else:\n",
    "        df2 = df.copy()\n",
    "        final_df = business_Overview(business_name,avg_rating,address,df2)\n",
    "        final_df = pd.concat([df1,final_df],axis = 0)\n",
    "    \n",
    "\n",
    "print(final_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# review df with reviews and locations\n",
    "final_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*End Code Space*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Odele's Code Space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*End Code Space*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Vanessa's Code Space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*End Code Space*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Train Test Splitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Scaling and Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Application (?)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Findings**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Citations and Licenses**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Licenses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_dev",
   "language": "python",
   "name": "ai_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
