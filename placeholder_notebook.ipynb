{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Project Title**\n",
    "#### *Project Subtitle*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis;\n",
    "\n",
    "Project thesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in data\n",
    "# (potentially?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beginning EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Ramona's Code Space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*End Code Space*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Christian's Code Space**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing necessary libraries (uncomment if needed)\n",
    "# %pip install gdown --quiet\n",
    "# ! pip install evaluate --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and dependencies\n",
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# json\n",
    "import json\n",
    "\n",
    "# gdown\n",
    "import gdown\n",
    "\n",
    "# zipfile\n",
    "import zipfile\n",
    "\n",
    "from tqdm import tqdm\n",
    "import unicodedata\n",
    "\n",
    "import torch\n",
    "from datasets import load_metric\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import transformers\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import DataCollatorWithPadding\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments,Trainer\n",
    "from transformers import pipeline\n",
    "\n",
    "from huggingface_hub import notebook_login\n",
    "\n",
    "import accelerate\n",
    "\n",
    "from datasets import Dataset\n",
    "\n",
    "from evaluate import load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resources path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to access datasets through `gdown`\n",
    "def fetch_data(set):\n",
    "    # Declaring `url` and `output` for dataset\n",
    "    match set:\n",
    "        case 'business':\n",
    "            url = 'https://drive.google.com/file/d/1t-_rOjZ8oMqPcMJunVaMgY3OEbhnuSCv/view?usp=sharing'\n",
    "            output = 'Resources/business_dataset.csv'\n",
    "        case 'checkin':\n",
    "            url = 'https://drive.google.com/file/d/1_AVWp31ymfvf4QgTiMN_WLAeapfr0omf/view?usp=sharing'\n",
    "            output = 'Resources/checkin_dataset.csv'\n",
    "        case 'reviews':\n",
    "            url = 'https://drive.google.com/file/d/1L8rFjhOQyU90Ycr9t_OLA70vCYM0e7ck/view?usp=sharing'\n",
    "            output = 'Resources/reviews_dataset.csv'\n",
    "        case 'tip':\n",
    "            url = 'https://drive.google.com/file/d/1LMkCi5AFC_58_m7ELmn1hR8YDykuXwqq/view?usp=sharing'\n",
    "            output = 'Resources/tip_dataset.csv'\n",
    "        case 'user':\n",
    "            url = 'https://drive.google.com/file/d/1kQ522qcod7AjD5DO9vj8qFcSKxwJCDrO/view?usp=sharing'\n",
    "            output = 'Resources/user_dataset.csv'\n",
    "        case _:\n",
    "            print('Invalid dataset selected, please try again')\n",
    "            return None\n",
    "    \n",
    "    # Downloading dataset\n",
    "    gdown.download(url, output, fuzzy=True, quiet=True)\n",
    "\n",
    "    # Reading in the dataset\n",
    "    df = pd.read_csv(output, low_memory=False)\n",
    "\n",
    "    # Returning the dataset\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching/reading in all datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetching all datasets (uncomment for first run of code)\n",
    "# business_df = fetch_data('business')\n",
    "# checkin_df = fetch_data('checkin')\n",
    "# reviews_df = fetch_data('reviews')\n",
    "# tips_df = fetch_data('tip')\n",
    "# user_df = fetch_data('user')\n",
    "\n",
    "# Reading in all datasets (uncomment if data already fetched)\n",
    "business_df = pd.read_csv('./Resources/business_dataset.csv')\n",
    "checkin_df = pd.read_csv('./Resources/checkin_dataset.csv')\n",
    "reviews_df = pd.read_csv('./Resources/reviews_dataset.csv')\n",
    "tips_df = pd.read_csv('./Resources/tip_dataset.csv')\n",
    "user_df = pd.read_csv('./Resources/user_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Business dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'> Description:</font> \n",
    "**Contains business data including location data, attributes, and categories.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checkin dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'> Description:</font>\n",
    "**Checkins on a business.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkin_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<font color='orange'> Notes:</font>**\n",
    "**The team has determined this dataset would not add any value to our training data.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reviews dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = 'blue'>Description:</font>\n",
    "**Contains full review text data including the user_id that wrote the review and the business_id the review is written for.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Na count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping columns:\n",
    "- **review_id**\n",
    "- **useful**\n",
    "- **funny**\n",
    "- **cool**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.drop(columns = ['review_id','useful','funny','cool'],\n",
    "                inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming the 'text' field to 'review'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_df.rename(columns = {'text':'review'},inplace = True)\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<font color='orange'> Notes:</font>**\n",
    "- **review_id: Eliminated due to low informational value.**\n",
    "- **useful: Eliminated due to low relevance.**\n",
    "- **funny: Eliminated due to low relevance.**\n",
    "- **cool: Eliminated due to low relevance.**\n",
    "\n",
    "  **The *<font color='green'>'business_id'</font>* feature will be used as the identifier, *<font color='green'>'stars'</font>* is the rating metric and the *<font color='grey'>'review'</font>*  field encapsulates**<br>\n",
    "  **the data to be processed. the *<font color='green'>'date'</font>* variable is in place if time series analysis is needed.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tips dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blue'>Description:</font>\n",
    "**Tips written by a user on a business. Tips are shorter than reviews and tend to convey quick suggestions.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping columns:\n",
    "- **compliment_count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_df.drop(columns = ['compliment_count'],\n",
    "             inplace =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming the 'text' column to 'recommendations'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_df.rename(columns = {'text':'recommendations'},inplace = True)\n",
    "tips_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<font color='orange'> Notes:</font>**\n",
    "- **compliment_count: Eliminated due to low informational value.**\n",
    "\n",
    "\n",
    " **Since this data set has recommendations from the user to improve customer experience the 'recommendations' field could be a useful target variable.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = 'blue'>Note:</font>\n",
    "**User data including the user's friend mapping and all the metadata associated with the user.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<font color='orange'> Notes:</font>**\n",
    "**This data set will not be included in the training data to preserve user anonimity.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# //////////////////////////////////////////////////////////////////////////////////////////////////////////////////////////"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<font color = 'darkgrey'>Merging the reviews data set and the business data set</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = 'blue'>Description:</font>\n",
    "**This data set contains the fields that will be used to train the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = reviews_df.merge(business_df,how='left',on = 'business_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Na count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "na_prcnt = data_df[['attributes','categories','hours']].isna().sum()/data_df.shape[0]*100\n",
    "nas_df = pd.DataFrame(na_prcnt, columns=['percentage'])\n",
    "nas_df = nas_df.transpose()\n",
    "nas_df.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data = nas_df).set_title('Na percentage')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<font color='orange'> Notes:</font>**\n",
    "**After consulting with the team we decided to drop all three columns.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping rows with na values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.drop(columns = ['attributes','categories','hours'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *<font color='grey'>stars_x* and *<font color='grey'>stars_y* comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.loc[data_df['stars_x'] != data_df['stars_y']][['stars_x','stars_y']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *<font color='grey'>stars_x* and *<font color='grey'>stars_y*  for the same customer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.loc[data_df['business_id']=='XQfwVwDr-v0ZS3_CbbE5Xw'][['stars_x','stars_y']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *<font color='grey'>stars_x* average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "round(data_df.loc[data_df['business_id']=='XQfwVwDr-v0ZS3_CbbE5Xw']['stars_x'].mean(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<font color='orange'> Notes:</font>**\n",
    "**Because** *<font color='grey'> star_y</font>* **represents the average star rating, renaming** *<font color='grey'> star_y:</font>* **to:** *<font color='grey'> star_avg:</font>*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.rename(columns={'stars_y':'stars_avg','stars_x':'stars'},inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping is_open feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots()\n",
    "sns.countplot(data_df,\n",
    "             x='is_open',\n",
    "             hue = 'is_open',\n",
    "             ax = ax).set_title('is_open Feature')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### droppin is_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.drop(columns = ['is_open'],inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **<font color='orange'> Notes:</font>**\n",
    "**After cosulting with the team we decided to drop this feature due low informational value and feature imbalance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# //////////////////////////////////////////////////////////////////////////////////////////////////"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **<font color='darkgrey'>Merging with the tips data set exploration</font>**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color = 'blue'>Description:</font>\n",
    "**Contains customer recommendatins to improve experience**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantity of unique business_id in the tips data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(tips_df['business_id'].unique().shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quantity of unique business_id in  data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df['business_id'].unique().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset of *<font color='grey'>business_id</font>* in *<font color='grey'>data_df</font>* not found in *<font color='grey'>tips_df</font>*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_tips_df = data_df[~data_df['business_id'].isin(tips_df['business_id'])]\n",
    "no_tips_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Number of *<font color='grey'>business_id</font>* in *<font color='grey'>data_df</font>* not found in *<font color='grey'>tips_df</font>*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "no_tips_df = data_df[~data_df['business_id'].isin(tips_df['business_id'])]\n",
    "not_found = no_tips_df['business_id'].unique().shape[0]\n",
    "print(f'Number of business_ids in tips_df not found in data_df: {not_found}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips_df.loc[tips_df['business_id'] == no_tips_df['business_id'].iloc[33]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.merge(tips_df,data_df,\n",
    "                   on = ['business_id','user_id'],\n",
    "                   how = 'inner')\n",
    "                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison review vs. recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[['review','recommendations']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **<font color='orange'> Notes:</font>**\n",
    "**The <font color='grey'>data_df</font> has approximately <font color='green'>7 million</font> entries and <font color='grey'>tips_df</font> about <font color='green'>1 million</font> after merging them we end up the a little under half a million**.<br>\n",
    "**In the comparison above I don't see a difference between a review from the *reviews data set* and a recommendation from the *tips data set***.<br>\n",
    "**As shown above we stand to loose a significant amount of data if a merge is performed**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ///////////////////////////////////////////////////////////////////////////////////////////////////"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='darkgrey'>Final Data Overview</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping the user_id column to preserv user anonimity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.drop(columns = ['user_id'],inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Na verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Narrowing data to trainable scope\n",
    "def sample_stars(df, val):\n",
    "    df = df[df['stars'] == val].copy()\n",
    "    if val >= 4:\n",
    "        df = df.sample(1000)\n",
    "    elif val <= 2:\n",
    "        df = df.sample(1000)\n",
    "    else:\n",
    "        df = df.sample(2000)\n",
    "    df.reset_index(inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_5 = sample_stars(data_df,5)\n",
    "sample_4 = sample_stars(data_df,4)\n",
    "sample_3 = sample_stars(data_df,3)\n",
    "sample_2 = sample_stars(data_df,2)\n",
    "sample_1 = sample_stars(data_df,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_df = pd.concat(\n",
    "    [\n",
    "        sample_1,\n",
    "        sample_2,\n",
    "        sample_3,\n",
    "        sample_4,\n",
    "        sample_5\n",
    "    ], axis=0, ignore_index=True\n",
    ")\n",
    "\n",
    "sample_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_df['stars'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_df['stars']= sample_data_df['stars'].replace(to_replace=[1,2], value=0)\n",
    "sample_data_df['stars']= sample_data_df['stars'].replace(to_replace=3, value=1)\n",
    "sample_data_df['stars']= sample_data_df['stars'].replace(to_replace=[4,5], value=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_df['stars'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_data_df.rename(columns={'review':'text','stars':'label'},inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing accented characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accented_chars(text):\n",
    "  text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "  return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cleaning text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    # Remove URLs\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    # Remove mentions\n",
    "    text = re.sub(r\"@\\S+\", \"\", text)\n",
    "    # Remove hashtags\n",
    "    text = re.sub(r\"#\\S+\", \"\", text)\n",
    "    # Replace multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_reviews(reviews):\n",
    "  stop_words = set(stopwords.words('english'))  \n",
    "  norm_reviews = []\n",
    "  for review in tqdm(reviews):\n",
    "    \n",
    "    # Clean text\n",
    "    review = clean_text(review)\n",
    "    # remove extra newlines and convert them to spaces\n",
    "    review = review.translate(review.maketrans(\"\\n\\t\\r\", \"   \"))\n",
    "    # lower case\n",
    "    review = review.lower()\n",
    "    # remove accents\n",
    "    review = remove_accented_chars(review)\n",
    "    # remove special characters\n",
    "    review = re.sub(r'[^a-zA-Z0-9\\s]', '', review, flags=re.I|re.A)\n",
    "    # remove extra whitespaces\n",
    "    review = re.sub(' +', ' ', review)\n",
    "    # remove leading and training whitespaces\n",
    "    review = review.strip()\n",
    "\n",
    "    review_tokens = word_tokenize(review)\n",
    "    review = [w for w in review_tokens if not w in stop_words]\n",
    "    review = ' '.join(review)\n",
    "      \n",
    "    norm_reviews.append(review)\n",
    "\n",
    "  return norm_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer_function(review):\n",
    "    # Extracting text\n",
    "    text = review['text']\n",
    "\n",
    "    # Tokenize text with truncation and padding\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        # Truncate to max_length from the right by default\n",
    "        truncation=True,\n",
    "        # Pad to the maximum length\n",
    "        padding=\"max_length\",\n",
    "        # Maximum sequence length for BERT models\n",
    "        max_length=512,\n",
    "        # Assuming you are using PyTorch; change to 'np' if necessary\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load multiple metrics\n",
    "accuracy_metric = load(\"accuracy\")\n",
    "precision_metric = load(\"precision\")\n",
    "recall_metric = load(\"recall\")\n",
    "f1_metric = load(\"f1\")\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    predictions, labels = pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "    \n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    precision = precision_metric.compute(predictions=predictions, references=labels, average='weighted')\n",
    "    recall = recall_metric.compute(predictions=predictions, references=labels, average='weighted')\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels, average='weighted')\n",
    "    \n",
    "    # Return a dictionary containing all metrics\n",
    "    return {\n",
    "        \"accuracy\": accuracy[\"accuracy\"],\n",
    "        \"precision\": precision[\"precision\"],\n",
    "        \"recall\": recall[\"recall\"],\n",
    "        \"f1\": f1[\"f1\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sample_data_df['text']\n",
    "y = sample_data_df['label']\n",
    "\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_train_reviews = pre_process_reviews(X_train)\n",
    "norm_test_reviews = pre_process_reviews(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = Dataset.from_dict({'label':y_train.to_list(),'text':norm_train_reviews})\n",
    "test_dataset = Dataset.from_dict({'label':y_test.to_list(),'text':norm_test_reviews})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pretrained model\n",
    "model_checkpoint = 'distilbert-base-uncased'\n",
    "\n",
    "#Defining label classes\n",
    "id_to_label = {0:'Negative', 1:'Neutral', 2:'Positive'}\n",
    "label_to_id = {'Negative':0, 'Neutral': 1,'Positive':2}\n",
    "\n",
    "#Model definiftion\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels = 3,\n",
    "    id2label = id_to_label,\n",
    "    label2id =label_to_id \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = DistilBertTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "tokenized_train_dataset = train_dataset.map(tokenizer_function, batched=True)\n",
    "tokenized_test_dataset = train_dataset.map(tokenizer_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = 'model_sentiment'\n",
    "lr = 2e-5\n",
    "batch_size = 32\n",
    "EPOCHS = 3\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = output_dir,\n",
    "    learning_rate = lr,\n",
    "    per_device_train_batch_size = batch_size,\n",
    "    per_device_eval_batch_size = batch_size*2,\n",
    "    num_train_epochs = EPOCHS,\n",
    "    weight_decay = 0.01,\n",
    "    save_strategy = 'epoch',\n",
    "    evaluation_strategy = 'epoch',\n",
    "    logging_steps = 10,\n",
    "    load_best_model_at_end = True,\n",
    "    # Enable mixed precision\n",
    "    fp16=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "                  model = model,\n",
    "                  args = training_args,\n",
    "                  train_dataset = tokenized_train_dataset,\n",
    "                  eval_dataset = tokenized_test_dataset,\n",
    "                  tokenizer = tokenizer,\n",
    "                  compute_metrics = compute_metrics,\n",
    "                  data_collator = data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning the model with sample set of balanced data\n",
    "# (commented out to prevent re-training)\n",
    "\n",
    "# trained_model_results = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial fine-tuning of pretrained model yielded accuracy values of ~40-50%.\\\n",
    "Final yielded accruacy values are around ~81%.\n",
    "\n",
    "Steps taken to improve accuracy (in something close to resembling order of application);\n",
    "* Changed pre-trained model from `distilbert-base-uncased` to `MarieAngeA13/Sentiment-Analysis-BERT`\n",
    "* Adjusted sample sizes of data <br> (from ~100 records total to a balanced sample set of 1000 with equal representation for all ratings) <br> (it would be another iteration before that sample set would be a balanced represntaion of the *labels*, though)\n",
    "* Updates to text cleaning to include more web-present syntax <br> (eg; mentions, multiple spaces, hashtags, and web address elements) <br> (because reviews aren't literary works, typically)\n",
    "* Adjustted syntax and arguments of tokenizer function and the application of it\n",
    "* Adjusted training arguments to better align with our BERT-based model <br> (*spoiler: this gets undone pretty soon after*)\n",
    "* Added additional metrics for better understanding of neccessary optimization\n",
    "* Increased sample data size, again, and removed subset step entirely <br> (started at 10,000 only to then decrease that sample size to 600 because of time, but it was still a larger sample than where it started)\n",
    "* Adjusted batch size and epochs <br> (twice)\n",
    "* Moved back to `distilbert-base-uncased` and adjusted learning tokenizers, learning rate, logging steps, and such hyperparameters accordingly <br> (because sometimes less Bert is better Bert)\n",
    "* Bargained with Eldritch beings in the hopes of a single soul buying even just a 10% boost to accuracy <br> (which is to say the sample size was changed to 3,000) <br> (also added and evaluation step to get a better idea of performance)\n",
    "* Exchanged soul because the deal was pretty tempting <br> (3,000 records had an accuracy of ~78%, so set the model to train overnight with 6,000 records in the hopes of an above 80% result)\n",
    "\n",
    "Copied output from final evaluation;\n",
    "\n",
    "> {'eval_loss': 0.4815390408039093, 'eval_accuracy': 0.8169047619047619, 'eval_precision': 0.8175331785953032, 'eval_recall': 0.8169047619047619, 'eval_f1': 0.8171466024398222, 'eval_runtime': 1743.5234, 'eval_samples_per_second': 2.409, 'eval_steps_per_second': 0.038, 'epoch': 3.0}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model (commented out due to trainer already being trained)\n",
    "# evaluation_metrics = trainer.evaluate()\n",
    "\n",
    "# Print the final score (commented out due to trainer already being trained)\n",
    "# print(evaluation_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving Model & Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model and toekenizer\n",
    "# (commented out to prevent overwriting, # fetching handled through `gdown` and `zipfile`)\n",
    "# trainer.save_model(model_path)\n",
    "\n",
    "# tokenizer.save_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching and unzipping model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1tzYRkjv3wWpfg21pJ02SEYNXEcj-TVH3\n",
      "From (redirected): https://drive.google.com/uc?id=1tzYRkjv3wWpfg21pJ02SEYNXEcj-TVH3&confirm=t&uuid=fbba920e-71af-4885-98ba-db048c2f7301\n",
      "To: /Users/angelicacalderon/repos/AI_Project_3_Group_01/Resources/Sentiment_Analysis.zip\n",
      "100%|██████████| 247M/247M [00:21<00:00, 11.7MB/s] \n"
     ]
    }
   ],
   "source": [
    "# Fetching model through `gdown`\n",
    "url = 'https://drive.google.com/file/d/1tzYRkjv3wWpfg21pJ02SEYNXEcj-TVH3/view?usp=sharing'\n",
    "output = 'Resources/Sentiment_Analysis.zip'\n",
    "# Download model\n",
    "gdown.download(url, output, fuzzy=True, quiet=False)\n",
    "\n",
    "# Extracting model\n",
    "with zipfile.ZipFile(output, 'r') as zip_ref:\n",
    "    zip_ref.extractall('./Sentiment_Analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = 'Sentiment_Analysis/Sentiment_Analysis/model'\n",
    "tokenizer_path =  'Sentiment_Analysis/Sentiment_Analysis/tokenizer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loading and Testing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DistilBertForSequenceClassification.from_pretrained(model_path)\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(tokenizer_path)\n",
    "\n",
    "roberto = pipeline('sentiment-analysis',model=model,tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply `roberto` to any DF\n",
    "def apply_roberto(df,review_col):\n",
    "    # Iterate through `df`\n",
    "    for index,row in df.iterrows():\n",
    "        # Set review text as `text`\n",
    "        text = row[review_col]\n",
    "        # Generate results for a given review\n",
    "        result = roberto(text, truncation=True)[0]\n",
    "        # Append the sentiment label\n",
    "        df.at[index, 'sent_label'] = result['label']\n",
    "        #Append the sentiment score\n",
    "        df.at[index, 'sent_score'] = result['score']\n",
    "    # Return `df`\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a susbet to test model\n",
    "sample_set_df = sample_data_df[:100]\n",
    "\n",
    "# Applying `apply_roberto` to `sample_set_df` (commented out as a saved subset exists)\n",
    "# sample_set_df = apply_roberto(sample_data_df,'text')\n",
    "\n",
    "# Confirming results\n",
    "sample_set_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*End Code Space*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting sample subset for later use (commented out because `.csv` in `Resources/`)\n",
    "# sample_set_df.to_csv('./Resources/sample_set.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in existing subset with `roberto` applied\n",
    "sample_set_df = pd.read_csv('Resources/sample_set.csv')\n",
    "\n",
    "# Confirming subset\n",
    "sample_set_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions (Pt 1)\n",
    "\n",
    "While trained on Yelp! data, and developed for Google Reviews, the goal of the application is to be as univerally applicable to business reviews as possible - regardless of the source. The following functions were developed with their annotated purposes in mind:\n",
    "\n",
    "| **Function** | **Notes** |\n",
    "| :--- | :---|\n",
    "| `apply_roberto()` | Generates sentiment analysis for reviews in a given dataset, and a confidence in that sentiment |\n",
    "| `business_names_list()` | Generates a list of unique business names from a given dataset |\n",
    "| `reviews_list()` | Generates a list of all reviews submitted to a business for all its locations |\n",
    "| `general_sentiment()` | Classifies the general sentiment for a business' reviews and provides a mean confidence in that sentiment <br> *Note: To be run after a DataFrame has been passed through* `apply_roberto()` |\n",
    "\n",
    "Function outlined in more detail below require a DataFrame with the following features:\n",
    "\n",
    "| **Feature** | **Notes** |\n",
    "| :--- | :--- |\n",
    "| `bus_name_col` | A text column with the name of a business |\n",
    "| `bus_add` | A text column with the street address of a business' location |\n",
    "| `rev_col` | A text column with available reviews |\n",
    "| `sent_lbl` | A text column with the generated sentiment classification <br> *Note: Generated through* `apply_roberto()` |\n",
    "| `sent_scr` | A text column with the generated sentiment classification <br> *Note: Generated through* `apply_roberto()` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply `roberto` to any DF\n",
    "def apply_roberto(df,rev_col):\n",
    "    '''\n",
    "    Applies the `roberto` model to generate sentiment analysis for the reviews in a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame):     Any DataFrame with sufficient data.\n",
    "        rev_col (str):      A string with the feature name that contains the review text.\n",
    "    \n",
    "    Returns:\n",
    "        df (DataFrame):     The same DataFrame with the appended sentiments and confidence scores.\n",
    "    \n",
    "    Raises:\n",
    "        KeyError: If `rev_col` is not a valid column name in the DataFrame.\n",
    "        TypeError: If `df` is not a DataFrame or if `review_col` is not a string.\n",
    "    '''\n",
    "    #Raises\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError('The input `df` must be a pandas DataFrame.')\n",
    "    if not isinstance(rev_col, str):\n",
    "        raise TypeError('The `rev_col` parameter must be passed as a string.')\n",
    "    if rev_col not in df.columns:\n",
    "        raise KeyError(f\"Column '{rev_col}' not found in DataFrame.\")\n",
    "    \n",
    "    # Initializing features for results\n",
    "    df['sent_label'] = ''\n",
    "    df['sent_score'] = 0.0\n",
    "\n",
    "    # Iterating through `df`\n",
    "    for index,row in df.iterrows():\n",
    "        # Setting review text as `text`\n",
    "        text = row[rev_col]\n",
    "        # Generating results for a given review\n",
    "        result = roberto(text, truncation=True)[0]\n",
    "        # Appending the sentiment label\n",
    "        df.at[index, 'sent_label'] = result['label']\n",
    "        #Appending the sentiment score\n",
    "        df.at[index, 'sent_score'] = result['score']\n",
    "    \n",
    "    # Returning `df`\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve unique business names\n",
    "def business_names_list(df, bus_name_col):\n",
    "    '''\n",
    "    Places unique names from a list of businesses into a list.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame):     Any DataFrame with sufficient data.\n",
    "        bus_name_col (str): A string with the feature name that contains the business name.\n",
    "\n",
    "    Returns:\n",
    "        names (list):       A list of strings with only unique values.\n",
    "\n",
    "    Raises:\n",
    "        KeyError:           If `bus_name` is not a valid column name in the DataFrame.\n",
    "        TypeError:          If `df` is not a DataFrame or if `bus_name` is not a string.\n",
    "    '''\n",
    "    # Raises\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError('The input `df` must be a pandas DataFrame.')\n",
    "    if not isinstance(bus_name_col, str):\n",
    "        raise TypeError('The `bus_name` parameter must be passed as a string.')\n",
    "    if bus_name_col not in df.columns:\n",
    "        raise KeyError(f\"Column '{bus_name_col}' not found in DataFrame.\")\n",
    "\n",
    "    # Generating a list of business names\n",
    "    names = df[bus_name_col].unique().tolist()\n",
    "    \n",
    "    # Returning the list\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve all reviews\n",
    "def reviews_list(df, bus_name_col, bus_name, bus_add, rev_col):\n",
    "    '''\n",
    "    Places all reviews for a given business into a list, attributing each review to its specific location.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame):     Any DataFrame with sufficient data.\n",
    "        bus_name_col (str): A string with the feature name that contains the business name.\n",
    "        bus_name (str):     A string of a specific business' name for which to map the locations.\n",
    "        bus_add (str):      A string with the feature name that contains the business street address.\n",
    "        rev_col (str):      A string with the feature name that contains the review text.\n",
    "\n",
    "    Returns:\n",
    "        reviews (list):     A list of strings with all the reviews for a given business.\n",
    "\n",
    "    Raises:\n",
    "        KeyError:           If any passed str is not a valid column name in the DataFrame, or if `bus_name` is not a value in `bus_name_col`.\n",
    "        TypeError:          If `df` is not a DataFrame  if and feature is not a string, or if `bus_name` is not a string.\n",
    "    '''\n",
    "    # Raises\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError('The input `df` must be a pandas DataFrame.')\n",
    "    for param, name in zip(\n",
    "        [bus_name_col, bus_add, rev_col],\n",
    "        ['bus_name_col', 'bus_add', 'rev_col']\n",
    "    ):\n",
    "        if not isinstance(param, str):\n",
    "            raise TypeError(f\"The '{name}' parameter must be passed as a string.\")\n",
    "        if param not in df.columns:\n",
    "            raise KeyError(f\"Column '{param}' not found in DataFrame.\")\n",
    "    if not isinstance(bus_name, str):\n",
    "        raise TypeError('The `bus_name` parameter must be passed as a string.')\n",
    "    if bus_name not in df[bus_name_col].values:\n",
    "        raise KeyError(f\"Value '{bus_name}' not found in column '{bus_name_col}'.\")\n",
    "    \n",
    "    # Filtering `df`\n",
    "    filtered_df = df[[bus_add, rev_col]][df[bus_name_col] == bus_name].copy()\n",
    "\n",
    "    # Handling missing or empty reviews\n",
    "    filtered_df[rev_col] = filtered_df[rev_col].fillna('No review provided.')\n",
    "\n",
    "    # Creating a list of all reviews\n",
    "    reviews = filtered_df[bus_add] + ':\\n' + filtered_df[rev_col] + '\\n\\n'\n",
    "\n",
    "    # Converting to a list\n",
    "    reviews = reviews.to_list()\n",
    "\n",
    "    # Returning reviews\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generalize the overall sentiment\n",
    "def general_sentiment(df, bus_name_col, bus_name, sent_lbl, sent_scr):\n",
    "    '''\n",
    "    Compares the total positive, negative, and neutral reviews to classify an overall sentiment.\n",
    "\n",
    "    Note:\n",
    "        To be run after passing a DataFrame through `apply_roberto()`.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame):     Any DataFrame with sufficient data.\n",
    "        bus_name_col (str): A string with the feature name that contains the business name.\n",
    "        bus_name (str):     A string of a specific business' name for which to map the locations.\n",
    "        sent_lbl (str):     A string with the feature name that contains the modeled sentiment label.\n",
    "        sent_scr (str):     A string with the feature name that contains the modeled sentiment confidence.\n",
    "\n",
    "    Returns:\n",
    "        gen_sent (str):     A string with the overall sentiment, and the model's mean confidence in that classification.\n",
    "    \n",
    "    Raises:\n",
    "        KeyError:           If any passed str is not a valid column name in the DataFrame, or if `bus_name` is not a value in `bus_name_col`.\n",
    "        TypeError:          If `df` is not a DataFrame  if and feature is not a string, or if `bus_name` is not a string.\n",
    "    '''\n",
    "    # Raises\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError('The input `df` must be a pandas DataFrame.')\n",
    "    for param, name in zip(\n",
    "        [bus_name_col, sent_lbl, sent_scr],\n",
    "        ['bus_name_col', 'sent_lbl', 'sent_scr']\n",
    "    ):\n",
    "        if not isinstance(param, str):\n",
    "            raise TypeError(f\"The '{name}' parameter must be passed as a string.\")\n",
    "        if param not in df.columns:\n",
    "            raise KeyError(f\"Column '{param}' not found in DataFrame.\")\n",
    "    if not isinstance(bus_name, str):\n",
    "        raise TypeError('The `bus_name` parameter must be passed as a string.')\n",
    "    if bus_name not in df[bus_name_col].values:\n",
    "        raise KeyError(f\"Value '{bus_name}' not found in column '{bus_name_col}'.\")\n",
    "    \n",
    "    # Filtering `df`\n",
    "    filtered_df = df[[sent_lbl, sent_scr]][df[bus_name_col] == bus_name].copy()\n",
    "\n",
    "    # Converting `sentiment` to lower case\n",
    "    filtered_df[sent_lbl] = filtered_df[sent_lbl].str.lower()\n",
    "\n",
    "    # Calculating total `positive` sentiment\n",
    "    pos = filtered_df.loc[filtered_df[sent_lbl] == 'positive'].shape[0]\n",
    "    # Calculating total `neutral` sentiment\n",
    "    ntrl = filtered_df.loc[filtered_df[sent_lbl] == 'neutral'].shape[0]\n",
    "    # Calculating total `negative` sentiment\n",
    "    neg = filtered_df.loc[filtered_df[sent_lbl] == 'negative'].shape[0]\n",
    "\n",
    "    # Match case to generate general sentiment\n",
    "    match (pos, ntrl, neg):\n",
    "        case (p, n, ng) if p > n > ng:\n",
    "            sent = 'highly positive'\n",
    "        case (p, n, ng) if p > n + ng:\n",
    "            sent = 'strongly positive'\n",
    "        case (p, n, ng) if p + n > ng:\n",
    "            sent = 'moderately positive'\n",
    "        case (p, n, ng) if p < n > ng:\n",
    "            sent = 'generally neutral'\n",
    "        case (p, n, ng) if p < n < ng:\n",
    "            sent = 'moderately negative'\n",
    "        case (p, n, ng) if p + n < ng:\n",
    "            sent = 'strongly negative'\n",
    "        case (p, n, ng) if ng > n > p:\n",
    "            sent = 'highly negative'\n",
    "        case (p, n, ng) if p == n == ng:\n",
    "            sent = 'perfectly neutral'\n",
    "        case _:\n",
    "            sent = 'undetermined'\n",
    "    \n",
    "    # Calculate the mean confidence\n",
    "    conf = filtered_df[sent_scr].mean() * 100\n",
    "\n",
    "    # Generating the final sentiment\n",
    "    if pos + ntrl + neg != 0:\n",
    "        # Concatenating sentiment and confidence\n",
    "        gen_sent = f'The general sentiment is {sent}, with an average confidence of {conf:.1f}%.'\n",
    "    else:\n",
    "        # When no sentment available due to no reviews\n",
    "        gen_sent = 'Cannot confirm sentiment due to a lack of reviews.'\n",
    "\n",
    "    # Returning sentiment\n",
    "    return gen_sent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary libraries (uncomment if needed)\n",
    "# ! pip install selenium --quiet\n",
    "# ! pip install webdriver-manager --quiet\n",
    "# ! pip install beautifulsoup4 --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Leigh's Code Space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*End Code Space*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Angelica's Code Space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import required libraries\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>bus_id</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>bus_add</th>\n",
       "      <th>bus_city</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The cakes are beautiful and delicious, but you...</td>\n",
       "      <td>5</td>\n",
       "      <td>Dulce De Leche Bakery</td>\n",
       "      <td>4.7</td>\n",
       "      <td>376 Central Ave</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>40.7476428</td>\n",
       "      <td>-74.0527625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The entire experience was excellent: well-brew...</td>\n",
       "      <td>5</td>\n",
       "      <td>Dulce De Leche Bakery</td>\n",
       "      <td>4.7</td>\n",
       "      <td>376 Central Ave</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>40.7476428</td>\n",
       "      <td>-74.0527625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Everything was great.\\n\\nFood, service, and th...</td>\n",
       "      <td>5</td>\n",
       "      <td>Dulce De Leche Bakery</td>\n",
       "      <td>4.7</td>\n",
       "      <td>376 Central Ave</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>40.7476428</td>\n",
       "      <td>-74.0527625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The soup is amazing. My family likes the Itali...</td>\n",
       "      <td>5</td>\n",
       "      <td>Dulce De Leche Bakery</td>\n",
       "      <td>4.7</td>\n",
       "      <td>376 Central Ave</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>40.7476428</td>\n",
       "      <td>-74.0527625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Absolutely love Dulce de Leche Bakery in Jerse...</td>\n",
       "      <td>5</td>\n",
       "      <td>Dulce De Leche Bakery</td>\n",
       "      <td>4.7</td>\n",
       "      <td>376 Central Ave</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>40.7476428</td>\n",
       "      <td>-74.0527625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>Absolutely amazing. We ordered  from their \"fa...</td>\n",
       "      <td>5</td>\n",
       "      <td>Texas Roadhouse</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2105 NJ-35 Suite 103</td>\n",
       "      <td>Holmdel</td>\n",
       "      <td>40.412299</td>\n",
       "      <td>-74.145973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>This place’s onion rings are my comfort food (...</td>\n",
       "      <td>5</td>\n",
       "      <td>Texas Roadhouse</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2105 NJ-35 Suite 103</td>\n",
       "      <td>Holmdel</td>\n",
       "      <td>40.412299</td>\n",
       "      <td>-74.145973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>Very good chain restaurant the food is always ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Texas Roadhouse</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2105 NJ-35 Suite 103</td>\n",
       "      <td>Holmdel</td>\n",
       "      <td>40.412299</td>\n",
       "      <td>-74.145973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>Loaded sweet potato and the rolls are the best...</td>\n",
       "      <td>5</td>\n",
       "      <td>Texas Roadhouse</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2105 NJ-35 Suite 103</td>\n",
       "      <td>Holmdel</td>\n",
       "      <td>40.412299</td>\n",
       "      <td>-74.145973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>Had the bone in ribeye with onion and mushroom...</td>\n",
       "      <td>5</td>\n",
       "      <td>Texas Roadhouse</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2105 NJ-35 Suite 103</td>\n",
       "      <td>Holmdel</td>\n",
       "      <td>40.412299</td>\n",
       "      <td>-74.145973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>550 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review rating  \\\n",
       "0    The cakes are beautiful and delicious, but you...      5   \n",
       "1    The entire experience was excellent: well-brew...      5   \n",
       "2    Everything was great.\\n\\nFood, service, and th...      5   \n",
       "3    The soup is amazing. My family likes the Itali...      5   \n",
       "4    Absolutely love Dulce de Leche Bakery in Jerse...      5   \n",
       "..                                                 ...    ...   \n",
       "545  Absolutely amazing. We ordered  from their \"fa...      5   \n",
       "546  This place’s onion rings are my comfort food (...      5   \n",
       "547  Very good chain restaurant the food is always ...      4   \n",
       "548  Loaded sweet potato and the rolls are the best...      5   \n",
       "549  Had the bone in ribeye with onion and mushroom...      5   \n",
       "\n",
       "                    bus_id avg_rating               bus_add      bus_city  \\\n",
       "0    Dulce De Leche Bakery        4.7       376 Central Ave   Jersey City   \n",
       "1    Dulce De Leche Bakery        4.7       376 Central Ave   Jersey City   \n",
       "2    Dulce De Leche Bakery        4.7       376 Central Ave   Jersey City   \n",
       "3    Dulce De Leche Bakery        4.7       376 Central Ave   Jersey City   \n",
       "4    Dulce De Leche Bakery        4.7       376 Central Ave   Jersey City   \n",
       "..                     ...        ...                   ...           ...   \n",
       "545        Texas Roadhouse        4.4  2105 NJ-35 Suite 103       Holmdel   \n",
       "546        Texas Roadhouse        4.4  2105 NJ-35 Suite 103       Holmdel   \n",
       "547        Texas Roadhouse        4.4  2105 NJ-35 Suite 103       Holmdel   \n",
       "548        Texas Roadhouse        4.4  2105 NJ-35 Suite 103       Holmdel   \n",
       "549        Texas Roadhouse        4.4  2105 NJ-35 Suite 103       Holmdel   \n",
       "\n",
       "            lat          lon  \n",
       "0    40.7476428  -74.0527625  \n",
       "1    40.7476428  -74.0527625  \n",
       "2    40.7476428  -74.0527625  \n",
       "3    40.7476428  -74.0527625  \n",
       "4    40.7476428  -74.0527625  \n",
       "..          ...          ...  \n",
       "545   40.412299   -74.145973  \n",
       "546   40.412299   -74.145973  \n",
       "547   40.412299   -74.145973  \n",
       "548   40.412299   -74.145973  \n",
       "549   40.412299   -74.145973  \n",
       "\n",
       "[550 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a function to create df with the business name, avg rating and address of each location\n",
    "def business_Overview(business_name,avg_rating,address1,lat,long,df):\n",
    "    df['bus_id'] = business_name\n",
    "    df['avg_rating'] = avg_rating\n",
    "    address_list = address1.split(',')\n",
    "    df['bus_add'] = address_list[0]\n",
    "    df['bus_city'] = address_list[1]\n",
    "    df['lat'] = lat\n",
    "    df['lon'] = long\n",
    "    return df\n",
    "\n",
    "# import business df with Google Maps url for web scrapping\n",
    "url_df = pd.read_csv('Resources/business_urls.csv')\n",
    "\n",
    "# select the fist 11 business urls from the file\n",
    "url_df = url_df.head(11)\n",
    "\n",
    "# create list of urls and lat/long for web scrapping step \n",
    "url = url_df['url'].tolist()\n",
    "lat = url_df['lat'].astype(str).tolist()\n",
    "long = url_df['long'].astype(str).tolist()\n",
    "\n",
    "# initiate driver\n",
    "driver = webdriver.Chrome(service = ChromeService(ChromeDriverManager().install()))\n",
    "\n",
    "#create for loop to parse through the different locations in the url list above\n",
    "c = 0\n",
    "df_list = []\n",
    "\n",
    "for i in range(0,len(url)):\n",
    "    c += 1\n",
    "    driver.get(url[i])\n",
    "    time.sleep(5)\n",
    "\n",
    "    # get parameters needed for business overview function\n",
    "    response = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    business_name = response.find('h1',class_='DUwDvf lfPIob').text\n",
    "    avg_rating = response.find('div',class_='fontDisplayLarge').text\n",
    "    address = response.find('div',class_= 'rogA2c').text\n",
    "    lat_ = lat[i]\n",
    "    long_ = long[i]\n",
    "    \n",
    "    # navigate to Reviews tab\n",
    "    driver.find_element(By.CLASS_NAME, \"RWPxGd\").click()\n",
    "    time.sleep(3)\n",
    "\n",
    "    #Find the total number of reviews\n",
    "    total_number_of_reviews = driver.find_element('xpath','//*[@id=\"QA0Szd\"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div[2]/div/div[2]/div[3]').text.split(\" \")[0]\n",
    "    total_number_of_reviews = int(total_number_of_reviews.replace(',','')) if ',' in total_number_of_reviews else int(total_number_of_reviews)\n",
    "\n",
    "    total_number_of_reviews = 50\n",
    "\n",
    "    #Find scroll layout\n",
    "    scrollable_div = driver.find_element('xpath','//*[@id=\"QA0Szd\"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]')\n",
    "\n",
    "    #Scroll as many times as necessary to load all reviews - 10 reviews shown at a time\n",
    "    for i in range(0,(round(total_number_of_reviews/10 - 1))):\n",
    "        driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', scrollable_div)\n",
    "        time.sleep(1)\n",
    "\n",
    "    # #parse HTML and Data Extraction\n",
    "    # loop over the number of reviews \n",
    "    next_item = driver.find_elements('xpath','//*[@id=\"QA0Szd\"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div[9]/div[1]/div/div')\n",
    "    time.sleep(3)\n",
    "\n",
    "    #expand review by click on 'more' button\n",
    "    for i in next_item:\n",
    "        button = i.find_elements(By.TAG_NAME,'button')\n",
    "        for m in button:\n",
    "            if m.text == \"More\":\n",
    "                m.click()\n",
    "        time.sleep(5)\n",
    "\n",
    "    # parse through the HTML \n",
    "    response = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    reviews = response.find_all('div',class_ = 'jftiEf')\n",
    "\n",
    "    # define function to gather relevant data from the reviews result set obtained by parsing through HTML\n",
    "    def get_review_summary(result_set):\n",
    "            rev_dict = {\n",
    "                'review' : [],\n",
    "                'rating' : []}\n",
    "\n",
    "            for result in result_set:\n",
    "                #review_name = result.find(class_='d4r55').text\n",
    "                review_text = result.find('span',class_='wiI7pd').text\n",
    "                review_rating = result.find(class_='kvMYJc')['aria-label']\n",
    "                review_rating = review_rating[0]\n",
    "                rev_dict['review'].append(review_text)\n",
    "                rev_dict['rating'].append(review_rating)\n",
    "            \n",
    "            import pandas as pd\n",
    "            return(pd.DataFrame(rev_dict))\n",
    "    \n",
    "    # gather relevant data using newly created function above \n",
    "    summary_df = get_review_summary(reviews)\n",
    "\n",
    "    # access the number of locations in the url list\n",
    "    df = business_Overview(business_name,avg_rating,address,lat_,long_,summary_df)\n",
    "\n",
    "    # append df to df list \n",
    "    df_list.append(df)\n",
    "\n",
    "\n",
    "#concat list of data frames into one \n",
    "spooder_df = pd.concat(df_list, ignore_index=True)\n",
    "spooder_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting spooder_df for later use (commented out because `.csv` in `Resources/`)\n",
    "spooder_df.to_csv('./Resources/spooder.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the Sentiment Analysis Model to the Web Scrapped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>bus_id</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>bus_add</th>\n",
       "      <th>bus_city</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>sent_label</th>\n",
       "      <th>sent_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The cakes are beautiful and delicious, but you...</td>\n",
       "      <td>5</td>\n",
       "      <td>Dulce De Leche Bakery</td>\n",
       "      <td>4.7</td>\n",
       "      <td>376 Central Ave</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>40.7476428</td>\n",
       "      <td>-74.0527625</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.763528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The entire experience was excellent: well-brew...</td>\n",
       "      <td>5</td>\n",
       "      <td>Dulce De Leche Bakery</td>\n",
       "      <td>4.7</td>\n",
       "      <td>376 Central Ave</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>40.7476428</td>\n",
       "      <td>-74.0527625</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.889528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Everything was great.\\n\\nFood, service, and th...</td>\n",
       "      <td>5</td>\n",
       "      <td>Dulce De Leche Bakery</td>\n",
       "      <td>4.7</td>\n",
       "      <td>376 Central Ave</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>40.7476428</td>\n",
       "      <td>-74.0527625</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.810901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The soup is amazing. My family likes the Itali...</td>\n",
       "      <td>5</td>\n",
       "      <td>Dulce De Leche Bakery</td>\n",
       "      <td>4.7</td>\n",
       "      <td>376 Central Ave</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>40.7476428</td>\n",
       "      <td>-74.0527625</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.791038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Absolutely love Dulce de Leche Bakery in Jerse...</td>\n",
       "      <td>5</td>\n",
       "      <td>Dulce De Leche Bakery</td>\n",
       "      <td>4.7</td>\n",
       "      <td>376 Central Ave</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>40.7476428</td>\n",
       "      <td>-74.0527625</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.932732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>Absolutely amazing. We ordered  from their \"fa...</td>\n",
       "      <td>5</td>\n",
       "      <td>Texas Roadhouse</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2105 NJ-35 Suite 103</td>\n",
       "      <td>Holmdel</td>\n",
       "      <td>40.412299</td>\n",
       "      <td>-74.145973</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.650678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>This place’s onion rings are my comfort food (...</td>\n",
       "      <td>5</td>\n",
       "      <td>Texas Roadhouse</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2105 NJ-35 Suite 103</td>\n",
       "      <td>Holmdel</td>\n",
       "      <td>40.412299</td>\n",
       "      <td>-74.145973</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.456376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>Very good chain restaurant the food is always ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Texas Roadhouse</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2105 NJ-35 Suite 103</td>\n",
       "      <td>Holmdel</td>\n",
       "      <td>40.412299</td>\n",
       "      <td>-74.145973</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.725514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>Loaded sweet potato and the rolls are the best...</td>\n",
       "      <td>5</td>\n",
       "      <td>Texas Roadhouse</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2105 NJ-35 Suite 103</td>\n",
       "      <td>Holmdel</td>\n",
       "      <td>40.412299</td>\n",
       "      <td>-74.145973</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.718005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>Had the bone in ribeye with onion and mushroom...</td>\n",
       "      <td>5</td>\n",
       "      <td>Texas Roadhouse</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2105 NJ-35 Suite 103</td>\n",
       "      <td>Holmdel</td>\n",
       "      <td>40.412299</td>\n",
       "      <td>-74.145973</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.806610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>550 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review rating  \\\n",
       "0    The cakes are beautiful and delicious, but you...      5   \n",
       "1    The entire experience was excellent: well-brew...      5   \n",
       "2    Everything was great.\\n\\nFood, service, and th...      5   \n",
       "3    The soup is amazing. My family likes the Itali...      5   \n",
       "4    Absolutely love Dulce de Leche Bakery in Jerse...      5   \n",
       "..                                                 ...    ...   \n",
       "545  Absolutely amazing. We ordered  from their \"fa...      5   \n",
       "546  This place’s onion rings are my comfort food (...      5   \n",
       "547  Very good chain restaurant the food is always ...      4   \n",
       "548  Loaded sweet potato and the rolls are the best...      5   \n",
       "549  Had the bone in ribeye with onion and mushroom...      5   \n",
       "\n",
       "                    bus_id avg_rating               bus_add      bus_city  \\\n",
       "0    Dulce De Leche Bakery        4.7       376 Central Ave   Jersey City   \n",
       "1    Dulce De Leche Bakery        4.7       376 Central Ave   Jersey City   \n",
       "2    Dulce De Leche Bakery        4.7       376 Central Ave   Jersey City   \n",
       "3    Dulce De Leche Bakery        4.7       376 Central Ave   Jersey City   \n",
       "4    Dulce De Leche Bakery        4.7       376 Central Ave   Jersey City   \n",
       "..                     ...        ...                   ...           ...   \n",
       "545        Texas Roadhouse        4.4  2105 NJ-35 Suite 103       Holmdel   \n",
       "546        Texas Roadhouse        4.4  2105 NJ-35 Suite 103       Holmdel   \n",
       "547        Texas Roadhouse        4.4  2105 NJ-35 Suite 103       Holmdel   \n",
       "548        Texas Roadhouse        4.4  2105 NJ-35 Suite 103       Holmdel   \n",
       "549        Texas Roadhouse        4.4  2105 NJ-35 Suite 103       Holmdel   \n",
       "\n",
       "            lat          lon sent_label  sent_score  \n",
       "0    40.7476428  -74.0527625   Positive    0.763528  \n",
       "1    40.7476428  -74.0527625   Positive    0.889528  \n",
       "2    40.7476428  -74.0527625   Positive    0.810901  \n",
       "3    40.7476428  -74.0527625   Positive    0.791038  \n",
       "4    40.7476428  -74.0527625   Positive    0.932732  \n",
       "..          ...          ...        ...         ...  \n",
       "545   40.412299   -74.145973   Positive    0.650678  \n",
       "546   40.412299   -74.145973    Neutral    0.456376  \n",
       "547   40.412299   -74.145973   Positive    0.725514  \n",
       "548   40.412299   -74.145973   Negative    0.718005  \n",
       "549   40.412299   -74.145973   Positive    0.806610  \n",
       "\n",
       "[550 rows x 10 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply Roberto to web scrapping dataframe with Google Reviews\n",
    "roberto_df = apply_roberto(spooder_df,'review')\n",
    "roberto_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting roberto_df for later use (commented out because `.csv` in `Resources/`)\n",
    "roberto_df.to_csv('./Resources/roberto.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The general sentiment is highly positive, with an average confidence of 75.4%.'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run function to get general sentiment per business to be used as input into chatgpt model \n",
    "general_sentiment_web_scrapping = general_sentiment(roberto_df, 'bus_id', 'Dulce de Leche Bakery', 'sent_label', 'sent_score')\n",
    "general_sentiment_web_scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['55 W Palisade Ave:\\nAwesome bakery right in the heart of Englewood. They are very busy, especially on weekends and holidays, but the staff keep the line moving quickly. All of their pastries are delicious, and their coffee is just right. The inside of the establishment is quite beautiful as well, with a minimalist open air decor and aesthetic. Highly recommend a visit!\\n\\n',\n",
       " '55 W Palisade Ave:\\nLove! Love! Love! My favorite bakery! The cakes (slice or whole) is always so fresh and delicious! I order the Dulce De Leche Chantilly Cake Slice and it’s honestly omg. The top frosting tastes like hot chocolate. The chocolate cake is …\\n\\n',\n",
       " \"55 W Palisade Ave:\\nThis place gets crazy! This place is spacious and gets busy quickly. The staff is awesome and professional. They definitely try to get you out in advance. They have all kinds I'd pastries and they make cakes. I ordered chicken empanadas and …\\n\\n\",\n",
       " '55 W Palisade Ave:\\nThe cake was beautiful and delicious! Perfect for the  Birthday theme!🤩 The staff were very helpful and friendly. The lady that helped me with the cake order was great 😊 The delivery driver was also very helpful and responsible. He send me pictures of the cake after it was delivered. They are highly recommended! …\\n\\n',\n",
       " '55 W Palisade Ave:\\nLegendary Dulce de leche has a branch in englewood.. it’s a nice bakery with v v positive vibes and very popular for their sweet and savory treats .. the cakes are very different and very flavorful.. I love the coffee, tiramisu and the …\\n\\n',\n",
       " '55 W Palisade Ave:\\nIt’s not expensive, but the taste is satisfying.  Sandwiches in the refrigerator were perfect for taking out for a snack after picnics, lunch, and kids’ outdoor activities. But the attitude of the cashier needs to something change.\\n\\n',\n",
       " '55 W Palisade Ave:\\nEverything I had from here was absolutely delicious - the pastries were flakey and buttery and all the fillings were just as good, the coffee and fresh juices are a delight as well. The staff works quickly and the seating area is spacious …\\n\\n',\n",
       " '55 W Palisade Ave:\\nI was impressed by how popular the cafe is on a Sunday morning, it had at least 40 people sitting and 20 in line, showing how popular it is! It was SO DELICIOUS the tres leches cake , liked the turkey sandwich and a smoothie too\\n\\n',\n",
       " '55 W Palisade Ave:\\nDelicious deserts and baked goods here. I ordered the sandwich 🥪 in my picture. I forgot what it’s called. I think it’s originally the ham and cheese, but I customized it to just spinach, cheese and tomatoes 🍅. For drink I ordered their green drink. It comes with spinach, cucumber 🥒, 🍋, ginger \\U0001fada, and 🍏 green apple. …\\n\\n',\n",
       " '55 W Palisade Ave:\\nThis place is out of control, breakfast for two with coffee and a sweet is literally $14.. would be triple anywhere else. Fun stuff to try\\n\\n']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run function to add all reviews of a given business as a list\n",
    "review_list_web_scrapping = reviews_list(roberto_df, 'bus_id', 'Dulce de Leche Bakery', 'bus_add', 'review')\n",
    "review_list_web_scrapping[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Reviews from Selected Business to run ChatGPT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import ChatOpenAI and os\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Additional imports for prompt template and LLM chain.\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables.\n",
    "load_dotenv()\n",
    "\n",
    "# Set the model name for our LLMs.\n",
    "OPENAI_MODEL = \"gpt-3.5-turbo\"\n",
    "# Store the API key in a variable.\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Summary:\n",
      "The reviews for 55 W Palisade Ave highlight the bakery's delicious pastries, cakes, and coffee, as well as its beautiful interior and efficient staff. Customers appreciate the variety of offerings, reasonable prices, and friendly service. However, some reviews mention issues with service quality, cleanliness, and specific food items.\n",
      "\n",
      "### Recommendations for Improvement:\n",
      "1. **Enhance Customer Service:** Address complaints about lazy service and improve the overall attitude of staff members.\n",
      "   \n",
      "2. **Maintain Cleanliness:** Ensure that all food items are prepared and served in a hygienic manner to avoid issues like finding foreign objects in the food.\n",
      "   \n",
      "3. **Consistent Quality:** Maintain the high standard of food quality and service to meet customer expectations and avoid any negative experiences.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model.\n",
    "llm=ChatOpenAI(openai_api_key=OPENAI_API_KEY, model_name=OPENAI_MODEL, temperature=0.3)\n",
    "\n",
    "# Define the format for the template.\n",
    "format = \"\"\"\n",
    "\n",
    "Provide a summary of the given reviews:{review_list} and three ways in which to improve the business. The summary should capture the main points and key details of the text \n",
    "while conveying the author's intended meaning accurately. The recommendations should be actionable, clear and conscise. Please ensure that the summary is well-organized and easy to read, \n",
    "with clear headings and subheadings to guide the reader through each section. The length of the summary should be appropriate to capture the main points and key details of the text, \n",
    "without including unnecessary information or becoming overly long.\n",
    "\n",
    "reviews = {review_list}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Construct the prompt template.\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"review_list\"],\n",
    "    template=format\n",
    ")\n",
    "\n",
    "# Construct a chain using this template.\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "# Define the input variable as a dictionary\n",
    "review_list = {\"review_list\": review_list}\n",
    "\n",
    "# Run the chain using the query as input and get the result.\n",
    "result = chain.invoke(review_list)\n",
    "results = result[\"text\"]\n",
    "\n",
    "# split the results by new lines to extract review summary and business recommendations\n",
    "results_list = results.split('\\n')\n",
    "reviews_summary = results_list[1]\n",
    "recommendations = results_list[4]\n",
    "\n",
    "\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*End Code Space*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Odele's Code Space**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Additional Libraries and Dependencies;\n",
    "\n",
    "Application being developed with `Dash` by `Plotly`. Additional `pip install`s will be necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install necessary packages\n",
    "# Note: Uncomment if needed\n",
    "# ! pip install dash\n",
    "# ! pip install dash-bootstrap-components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and dependencies\n",
    "import pandas as pd\n",
    "\n",
    "# Dash\n",
    "from dash import Dash, dcc, html, callback, callback_context\n",
    "from dash.dependencies import Input, Output, State\n",
    "from dash.exceptions import PreventUpdate\n",
    "\n",
    "# Dash Boostrap Components\n",
    "import dash_bootstrap_components as dbc\n",
    "\n",
    "# Plotly\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Other\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Components;\n",
    "\n",
    "Existing variables and functions may necessistate refactoring. Temporary facsimiles used for development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_set_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Components\n",
    "'''\n",
    "Inputs and declearations necessary to make app function:\n",
    "\n",
    "user_input: a URL or name of a business (tbd) for which to fetch reviews\n",
    "\n",
    "sbmt_bttn: a submit button\n",
    "\n",
    "bus_id: an ID str or name of a business (tbd) to display for a given business\n",
    "\n",
    "bus_loc: an array or a str (tbd) representing the location(s) of a given business\n",
    "\n",
    "avg_rating: an int representing the average rating for a given business\n",
    "\n",
    "tot_ratings: an int representing the toal reviews submitted for a given business\n",
    "\n",
    "reviews: a dictionary of reviews containing a given rating and associated comment\n",
    "\n",
    "sentiment: a str representing the generated sentiment analysis based on all reviews\n",
    "\n",
    "recommendation: a str representing the generated recommendations based on the generated sentiment\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions (Pt 2)\n",
    "\n",
    "While trained on Yelp! data, and developed for Google Reviews, the goal of the application is to be as univerally applicable to business reviews as possible - regardless of the source. The following functions were developed with their annotated purposes in mind:\n",
    "\n",
    "| **Function** | **Notes** |\n",
    "| :--- | :---|\n",
    "| `unique_locs_df()` | Creates a DataFrame with all unique locations in a given dataset |\n",
    "| `location_details()` | Generates a dictionary with geographic coordinates for all locations of a given business <br> *Note: To be run on the DataFrame generated by* `unique_locs_df()` |\n",
    "| `build_map()` | Constructs a Scattermapbox based on the locations from `location_details()` |\n",
    "| `apply_davidlingo()` | Generates the final summary of a business' reviews, or recommendations for improvement based off the reviews and overall sentiment <br> *Note: To be used with the ouputs of* `reviews_list()` *and* `general_sentiment()` |\n",
    "\n",
    "Each function outlined in more detail below requires a DataFrame with the following features:\n",
    "\n",
    "| **Feature** | **Notes** |\n",
    "| :--- | :--- |\n",
    "| `bus_name_col` | A text column with the name of a business |\n",
    "| `bus_add` | A text column with the street address of a business' location |\n",
    "| `bus_lat` | A float column with the latitude coordinate for a business' location |\n",
    "| `bus_lon` | A float column with the longitude coordinate for a business' location |\n",
    "| `rev_col` | A text column with available reviews |\n",
    "| `sent_lbl` | A text column with the generated sentiment classification <br> *Note: Generated through* `apply_roberto()` |\n",
    "| `sent_scr` | A text column with the generated sentiment classification <br> *Note: Generated through* `apply_roberto()` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve unique business locations\n",
    "def unique_locs_df(df, bus_name_col, bus_add, bus_lat, bus_lon):\n",
    "    '''\n",
    "    Gathers unique adresses and coordinates for unique locations into a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame):     Any DataFrame with sufficient data.\n",
    "        bus_name_col (str): A string with the feature name that contains the business name.\n",
    "        bus_add (str):      A string with the feature name that contains the business street address.\n",
    "        bus_lat (str):      A string with the feature name that contains the latitude of a location.\n",
    "        bus_lon (str):      A string with the feature name that contains the longitude of a location.\n",
    "    \n",
    "    Returns:\n",
    "        loc (DataFrame):    A DataFrame with only unique locations.\n",
    "\n",
    "    Raises:\n",
    "        KeyError:           If any passed str is not a valid column name in the DataFrame.\n",
    "        TypeError:          If `df` is not a DataFrame or if and feature is not a string.\n",
    "    '''\n",
    "    # Raises\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError('The input `df` must be a pandas DataFrame.')\n",
    "    for param, name in zip(\n",
    "        [bus_name_col, bus_add, bus_lat, bus_lon],\n",
    "        ['bus_name_col', 'bus_add', 'bus_lat', 'bus_lon']\n",
    "    ):\n",
    "        if not isinstance(param, str):\n",
    "            raise TypeError(f\"The '{name}' parameter must be passed as a string.\")\n",
    "        if param not in df.columns:\n",
    "            raise KeyError(f\"Column '{param}' not found in DataFrame.\")\n",
    "    \n",
    "    # Generating a DataFrame of unique locations\n",
    "    locs = df[[bus_name_col, bus_add, bus_lat, bus_lon]].drop_duplicates()\n",
    "    \n",
    "    # Returning the DataFrame\n",
    "    return locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a `locations` list of dictionaries\n",
    "def location_details(df, bus_name_col, bus_name, bus_add, bus_lat, bus_lon):\n",
    "    '''\n",
    "    Transfers the latitude, longitude, and a concatenated identifier into a dictionary for later use in generating a Scattermapbox figure.\n",
    "\n",
    "    Note:\n",
    "        Advised to run `location_details()` on the DataFrame generated by `unique_locs_df()`\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame):     Any DataFrame with sufficient data.\n",
    "        bus_name_col (str): A string with the feature name that contains the business name.\n",
    "        bus_name (str):     A string of a specific business' name for which to map the locations.\n",
    "        bus_add (str):      A string with the feature name that contains the business street address.\n",
    "        bus_lat (str):      A string with the feature name that contains the latitude of a location.\n",
    "        bus_lon (str):      A string with the feature name that contains the longitude of a location.\n",
    "\n",
    "    Returns:\n",
    "        locs (dict):        A list of dictionaries with the necessary details for building a figure.\n",
    "    \n",
    "    Raises:\n",
    "        KeyError:           If any passed str is not a valid column name in the DataFrame.\n",
    "        TypeError:          If `df` is not a DataFrame or if and feature is not a string.\n",
    "        ValueError:         If `bus_name` is not a value in `bus_col_name`.\n",
    "    '''\n",
    "    # Raises\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError('The input `df` must be a pandas DataFrame.')\n",
    "    for param, name in zip(\n",
    "        [bus_name_col, bus_add, bus_lat, bus_lon],\n",
    "        ['bus_name_col', 'bus_add', 'bus_lat', 'bus_lon']\n",
    "    ):\n",
    "        if not isinstance(param, str):\n",
    "            raise TypeError(f\"The '{name}' parameter must be passed as a string.\")\n",
    "        if param not in df.columns:\n",
    "            raise KeyError(f\"Column '{param}' not found in DataFrame.\")\n",
    "    if bus_name not in df[bus_name_col].values:\n",
    "        raise ValueError(f\"'{bus_name}' not found in column '{bus_name_col}'.\")\n",
    "    \n",
    "    # Creating a list of features to retain\n",
    "    retain = [bus_name_col, bus_add, bus_lat, bus_lon]\n",
    "\n",
    "    # Filtering `df`\n",
    "    filtered_df = df[retain][df[bus_name_col] == bus_name].copy()\n",
    "\n",
    "    # Intializing a `name` feature\n",
    "\n",
    "    # Creating a concatenated `name` feature with a business' name and location address\n",
    "    filtered_df['loc_name'] = filtered_df[bus_name_col] + ' - ' + filtered_df[bus_add]\n",
    "\n",
    "    # Renaming features\n",
    "    filtered_df.rename(columns={bus_lat: 'lat', bus_lon: 'lon'}, inplace=True)\n",
    "\n",
    "    # Dropping features\n",
    "    filtered_df.drop([bus_name_col, bus_add], axis=1, inplace=True)\n",
    "\n",
    "    # Converting `filtered_df` to a dictionary\n",
    "    locs = filtered_df.to_dict('records')\n",
    "\n",
    "    # Returning list of dictionaries\n",
    "    return locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build a map\n",
    "def build_map(locs):\n",
    "    '''\n",
    "    Generates and updates a Scattermapbox figure based on the location details previously generated.\n",
    "\n",
    "    Note:\n",
    "        To be run on the dictionary returned by `location_details()`.\n",
    "\n",
    "    Args:\n",
    "        locs (dict):    A dictionary containing the latitude and longitude coordinates, as well as the business name and street address, of all given locations for that business.\n",
    "    \n",
    "    Returns:\n",
    "        fig (fig):      A Scattermapbox formated to an appropriate zoom level and centered on all given locations for a business.\n",
    "    \n",
    "    Raises:\n",
    "        TypeError:      If `locs` is not a list of dictionaries, or if the dictionaries do not contain the expected keys.\n",
    "        KeyError:       If any of the expected keys are missing from the dictionaries.\n",
    "        ValueError:     If `locs` is empty, or if latitude and longitude values are not valid numbers.\n",
    "    '''\n",
    "    # Raises\n",
    "    if not isinstance(locs, list) or not all(isinstance(loc, dict) for loc in locs):\n",
    "        raise TypeError(\"`locs` must be a list of dictionaries.\")\n",
    "    required_keys = {'lat', 'lon', 'loc_name'}\n",
    "    for loc in locs:\n",
    "        if not required_keys.issubset(loc):\n",
    "            raise KeyError(f\"Each dictionary in `locs` must contain the keys: {required_keys}.\")\n",
    "    if not locs:\n",
    "        raise ValueError(\"`locs` cannot be an empty list.\")\n",
    "\n",
    "    # Generating location text\n",
    "    hover_text = [loc['loc_name'] for loc in locs]\n",
    "\n",
    "    # Generating location lat and lon\n",
    "    lat_loc = [loc['lat'] for loc in locs]\n",
    "    lon_loc = [loc['lon'] for loc in locs]\n",
    "\n",
    "    # Calculating middle point for lat and lon\n",
    "    lat_mean = sum(lat_loc)/len(lat_loc)\n",
    "    lon_mean = sum(lon_loc)/len(lon_loc)\n",
    "\n",
    "    # Calculating borders of locatoins\n",
    "    lat_min, lat_max = min(lat_loc), max(lat_loc)\n",
    "    lon_min, lon_max = min(lon_loc), max(lon_loc)\n",
    "\n",
    "    # Calculating size of borders\n",
    "    lat_diff = lat_max - lat_min\n",
    "    lon_diff = lon_max - lon_min\n",
    "\n",
    "    # Using `log()` to scale zoom based on distances at slower rates for larger geographic areas\n",
    "    zoom = min(7 - math.log(lat_diff + 0.1), 7 - math.log(lon_diff + 0.1))\n",
    "\n",
    "    # Creating the map figure\n",
    "    fig = go.Figure(go.Scattermapbox(\n",
    "        lat=lat_loc,\n",
    "        lon=lon_loc,\n",
    "        mode='markers',\n",
    "        hovertext=hover_text,\n",
    "        marker=dict(size=10)\n",
    "    ))\n",
    "\n",
    "    # Updating layout with map style and properties\n",
    "    fig.update_layout(\n",
    "        mapbox={\n",
    "            'style': 'open-street-map',\n",
    "            'center': {'lon': lon_mean, 'lat': lat_mean},\n",
    "            'zoom': zoom\n",
    "        },\n",
    "        margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0},\n",
    "        height=500\n",
    "    )\n",
    "\n",
    "    # Returning figure\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate OpenAI summary or recommendations\n",
    "def apply_davidlingo(gen_sent, reviews):\n",
    "    '''\n",
    "    Assesses the general sentiment and reviews for a given business to then conditionally output either summary of positive reviews, or recommendations based on neutral or negative reviews.\n",
    "\n",
    "    Note:\n",
    "        To be run after `apply_roberto()`, `general_sentiment()`, and `reviews_list()`.\n",
    "    '''\n",
    "    # Raises\n",
    "    \n",
    "    # Placeholder\n",
    "    gen_sent = gen_sent\n",
    "    reviews = reviews\n",
    "\n",
    "    # Placeholder\n",
    "    rev_recs = 'This is a placeholder for applying a final text object generated by an OpenAI LangChain.'\n",
    "    # Return final summary or recommendations\n",
    "    return rev_recs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Temporary Components;\n",
    "\n",
    "Starting features and figures for app loading state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporary default map\n",
    "\n",
    "# Create a default map centered on the US\n",
    "fig_placeholder = go.Figure(go.Scattermapbox())\n",
    "fig_placeholder.update_layout(\n",
    "    mapbox={\n",
    "        'style': \"open-street-map\",\n",
    "        'center': {'lon': -98.583, 'lat': 39.833},\n",
    "        'zoom': 2.5\n",
    "    },\n",
    "    margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0},\n",
    "    height=400\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## App Development;\n",
    "\n",
    "Initialization, construction, and launch of app.\n",
    "\n",
    "Still very much in development!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize app\n",
    "app = Dash(external_stylesheets=[dbc.themes.QUARTZ])\n",
    "\n",
    "# Declare a DataFrame to be used for the app\n",
    "app_df = roberto_df.copy()\n",
    "\n",
    "# Creating list of business names\n",
    "drop_opts = business_names_list(app_df, 'bus_id') # Replace args with live data\n",
    "\n",
    "# Creating a DataFrame of uniqur locations\n",
    "uniq_locs = unique_locs_df(app_df, 'bus_id', 'bus_add', 'bus_lat', 'bus_lon') # Replace args with live data\n",
    "\n",
    "# Loading markdown content for guide\n",
    "with open('Resources/SpooderApp_Guide.md', 'r') as file:\n",
    "    guide_content = file.read()\n",
    "\n",
    "# App layout\n",
    "app.layout = html.Div([\n",
    "    # Wrapping the whole GUI in a stack for uinform formatting\n",
    "    dbc.Stack(\n",
    "        [\n",
    "            # Blank col for spacing (1/12 of parent container)\n",
    "            dbc.Col('', width=1),\n",
    "            # Col with all of GUI\n",
    "            dbc.Col(\n",
    "                [\n",
    "                    # Row for header\n",
    "                    dbc.Row(\n",
    "                        # Header (as is evident by the `H1` method)\n",
    "                        html.H1(\n",
    "                            # Does whatever a SpooderApp™ can\n",
    "                            'SpooderApp™',\n",
    "                            # Placing in the middle of the page\n",
    "                            style={'textAlign':'center'}\n",
    "                        ),\n",
    "                        # Give us some room, please\n",
    "                        style={'margin-top': '20px', 'margin-bottom': '20px'}\n",
    "                    ),\n",
    "                    # Row for subheader\n",
    "                    dbc.Row(\n",
    "                        # Subheader (as is less evident by the `H3` method)\n",
    "                        html.H3(\n",
    "                            # Taglines are important\n",
    "                            'Leveraging business reviews to gain insights for potential improvements.',\n",
    "                            # Placing in the middle of the page\n",
    "                            style={'textAlign':'center'}\n",
    "                        ),\n",
    "                        # Buffer space\n",
    "                        style={'margin-bottom': '20px'}\n",
    "                    ),\n",
    "                    # Row for business name and ratings\n",
    "                    dbc.Row(\n",
    "                        [\n",
    "                            # Col for user input\n",
    "                            dbc.Col(\n",
    "                                # InputGroup for user input\n",
    "                                dbc.InputGroup(\n",
    "                                    [\n",
    "                                        # Dropdown menu for user input\n",
    "                                        dbc.DropdownMenu(\n",
    "                                            # Instructions for user input\n",
    "                                            label = 'Select a business',\n",
    "                                            # To know it's user input\n",
    "                                            id = 'business_dropdown',\n",
    "                                            # Selections for user input\n",
    "                                            children = [\n",
    "                                                dbc.DropdownMenuItem(\n",
    "                                                    name,\n",
    "                                                    id=f\"menu_item_{i}\",\n",
    "                                                    style={'color': 'grey'}\n",
    "                                                ) for i, name in enumerate(drop_opts)\n",
    "                                            ],\n",
    "                                            # Making it pretty ([insert sparkles here])\n",
    "                                            class_name='btn-info'\n",
    "                                        ),\n",
    "                                        # Not actually user input, but reflects it\n",
    "                                        dbc.InputGroupText(\n",
    "                                            # Blank until user input selected\n",
    "                                            children='',\n",
    "                                            # To know where to put user input\n",
    "                                            id='chld_nm',\n",
    "                                            # Making it pretty, but not AS pretty\n",
    "                                            class_name='form-control'\n",
    "                                        )\n",
    "                                    ],\n",
    "                                    # Be tall, but only so tall, please\n",
    "                                    style={'width': '100%', 'height': '60px'}\n",
    "                                ),\n",
    "                                # 6/12 of parent container, because math\n",
    "                                width=6\n",
    "                            ),\n",
    "                            # Col for average rating information\n",
    "                            dbc.Col(\n",
    "                                # Card display for averate rating information\n",
    "                                dbc.Card(\n",
    "                                    # Blank until user input selected\n",
    "                                    children='',\n",
    "                                    # To know where to put average rating information\n",
    "                                    id='avg_rtng',\n",
    "                                    # Making it pretty-ish\n",
    "                                    body=True,\n",
    "                                    # Be no taller than the column to your left\n",
    "                                    style={\n",
    "                                        'width': '100%',\n",
    "                                        'height': '60px',\n",
    "                                        'display': 'flex',\n",
    "                                        'align-items': 'left',\n",
    "                                        'justify-content': 'center'\n",
    "                                    }\n",
    "                                ),\n",
    "                                # 3/12 of parent container, or 1/4 but HTML/CSS doesn't like quarters as much\n",
    "                                width=3\n",
    "                            ),\n",
    "                            # Column for total reviews information\n",
    "                            dbc.Col(\n",
    "                                # Card display for total reviews information\n",
    "                                dbc.Card(\n",
    "                                    # Blank until user input selected\n",
    "                                    children='',\n",
    "                                    # To know where to put total reviews information\n",
    "                                    id='tot_rvws',\n",
    "                                    # Making it pretty-ish like its sibling to the left\n",
    "                                    body=True,\n",
    "                                    # You must be this short to display\n",
    "                                    style={\n",
    "                                        'width': '100%',\n",
    "                                        'height': '60px',\n",
    "                                        'display': 'flex',\n",
    "                                        'align-items': 'left',\n",
    "                                        'justify-content': 'center'\n",
    "                                    }\n",
    "                                ),\n",
    "                                # 3/12 of parent container, beacuse 12 - 6 - 3 leaves 3\n",
    "                                width=3\n",
    "                            )\n",
    "                        ],\n",
    "                        # Usually a good place to begin - The beginning\n",
    "                        justify='start',\n",
    "                        # Matching buffer space for that glossy, uniform look ([more sparkles])\n",
    "                        style={'margin-bottom': '20px'},\n",
    "                    ),\n",
    "                    # \"Row\" for map and accordion\n",
    "                    dbc.Stack(\n",
    "                        [\n",
    "                            # Col for map\n",
    "                            dbc.Col(\n",
    "                                # Map\n",
    "                                dcc.Graph(figure=fig_placeholder, id='bus_map'),\n",
    "                                # 5/12 of parent container, because the map wanted to be special\n",
    "                                width=5\n",
    "                            ),\n",
    "                            # Col for accordion\n",
    "                            dbc.Col(\n",
    "                                # Unfortunately, an accodion menu, not a Weird Al cameo\n",
    "                                dbc.Accordion(\n",
    "                                    [\n",
    "                                        # Menu item for reviews\n",
    "                                        dbc.AccordionItem(\n",
    "                                            # Paragraph - in the loosest sense - for reviews\n",
    "                                            html.P(\n",
    "                                                # To know where to put the reviews\n",
    "                                                id='reviews',\n",
    "                                                # Blank until user input selected\n",
    "                                                children='',\n",
    "                                                # Only be so tall, and scroll if longer\n",
    "                                                style={'max-height': '295px', 'overflow-y': 'auto'}\n",
    "                                            ),\n",
    "                                            # So you know it's got the reviews in it\n",
    "                                            title='Reviews'\n",
    "                                        ),\n",
    "                                        # Menu item for sentiment analysis\n",
    "                                        dbc.AccordionItem(\n",
    "                                            html.P(\n",
    "                                                # To know where to put the sentiment analysis\n",
    "                                                id='sentiment',\n",
    "                                                # Blank until user input selected\n",
    "                                                children='',\n",
    "                                                # Overkill, since this will only ever be a single line of text\n",
    "                                                style={'max-height': '295px', 'overflow-y': 'auto'}\n",
    "                                            ),\n",
    "                                            # To identify it as the container for the sentiment analysis\n",
    "                                            title='Sentiment Analysis'\n",
    "                                        ),\n",
    "                                        # Menu item for recommendations\n",
    "                                        dbc.AccordionItem(\n",
    "                                            html.P(\n",
    "                                                # To know where to put the OpenAI feedback\n",
    "                                                id='feedback',\n",
    "                                                # Blank until user input selected\n",
    "                                                children='',\n",
    "                                                # Only be so tall, and scroll if longer\n",
    "                                                style={'max-height': '295px', 'overflow-y': 'auto'}\n",
    "                                            ),\n",
    "                                            # For the purposes of labeling it as the recepticle for feedback\n",
    "                                            title='Feedback'\n",
    "                                        )\n",
    "                                    ]\n",
    "                                ),\n",
    "                                # Again, a good palce to begin\n",
    "                                align='start',\n",
    "                                # 7/12 of parent container, because that's what was left and it looks good\n",
    "                                width=7\n",
    "                            )\n",
    "                        ],\n",
    "                        # That's what was meant by \"row\", earlier - go this way <-->\n",
    "                        direction='horizontal',\n",
    "                        # Little bit of breathing room in there, too, please\n",
    "                        gap=1\n",
    "                    ),\n",
    "                    # Row for markdown guide\n",
    "                    dbc.Row(\n",
    "                        # Markdown guide\n",
    "                        dcc.Markdown(\n",
    "                            # Content for the markdown guide\n",
    "                            guide_content,\n",
    "                            # Making the markdown guide pretty\n",
    "                            style={\n",
    "                                'margin-top': '50px',\n",
    "                                'padding': '20px',\n",
    "                                'background-color': 'rgba(255, 255, 255, 0.35)', # This one is super important!\n",
    "                                'border-radius': '10px'\n",
    "                            }\n",
    "                        )\n",
    "                    )\n",
    "                ],\n",
    "                # 10/12 of parent container, because this really is the star of the show, right here\n",
    "                width=10\n",
    "            ),\n",
    "             # Blank col for spacing (1/12 of parent container)\n",
    "            dbc.Col('', width=1),\n",
    "        ],\n",
    "        # Another go this way <--> bit\n",
    "        direction='horizontal',\n",
    "        # We like negative space, let's have more of that between things\n",
    "        gap=1\n",
    "    )\n",
    "])\n",
    "\n",
    "# Callback to populate the `DropdownMenu`\n",
    "@callback(\n",
    "    Output('chld_nm', 'children'),\n",
    "    Output('avg_rtng', 'children'),\n",
    "    Output('tot_rvws', 'children'),\n",
    "    Output('bus_map', 'figure'),\n",
    "    Output('reviews', 'children'),\n",
    "    Output('sentiment', 'children'),\n",
    "    Output('feedback', 'children'),\n",
    "    [Input(f\"menu_item_{i}\", \"n_clicks\") for i in range(len(drop_opts))],\n",
    "    [State(f\"menu_item_{i}\", \"children\") for i in range(len(drop_opts))]\n",
    ")\n",
    "def update_content(*args):\n",
    "    # Default states for elements\n",
    "    load_input = 'Use the dropdown menu on the left'\n",
    "    load_avg_rtng = 'Average Rating: '\n",
    "    load_tot_rvws = 'Total Available Reviews: '\n",
    "    load_fig = fig_placeholder\n",
    "    load_revs = 'Select a business to see reviews.'\n",
    "    load_sent = 'Select a business to generate sentiment analysis.'\n",
    "    load_rev_rec = 'Select a business to generate dynamic feedback.'\n",
    "\n",
    "    # Confirming a dropdown selection has been made\n",
    "    ctx = callback_context\n",
    "    if ctx.triggered:\n",
    "        # Finding which business was clicked\n",
    "        selected_item_id = ctx.triggered[0]['prop_id'].split('.')[0]\n",
    "        # Finding the index of the clicked business\n",
    "        selected_index = int(selected_item_id.split('_')[-1])\n",
    "        # Getting the selected business name\n",
    "        selected_business = args[len(drop_opts) + selected_index]\n",
    "\n",
    "        # Getting the average rating for the selected business\n",
    "        # NOTE: Since `avg_rating` is stores on a per-business basis,\n",
    "        # not a per-record basis, the first record's value will suffice\n",
    "        rvw_avg = app_df.loc[app_df['bus_id'] == selected_business, 'avg_rating'].iloc[0]\n",
    "        # Returning the average rating value\n",
    "        avg_rtng = f'Average Rating: {rvw_avg:.1f}'\n",
    "\n",
    "        # Gathering the reviews for the selected business\n",
    "        reviews = reviews_list(app_df, 'bus_id', selected_business, 'bus_add', 'review')\n",
    "        # Calculating the total number of reviews\n",
    "        if len(reviews) >= 1:\n",
    "            # If 1 or more, returning a count of available reviews\n",
    "            rev_tot = f'Total Available Reviews: {len(reviews)}'\n",
    "            # Preparing an empty list\n",
    "            rev_list = []\n",
    "            # Appending each review into `rev_list` with HTML formatting\n",
    "            for rev in reviews:\n",
    "                rev_list.append(html.P([rev.split(':\\n')[0], ':', html.Br(), rev.split(':\\n')[1], html.Br()]))\n",
    "        else:\n",
    "            rev_tot = 'Total Available Reviews: 0'\n",
    "            rev_list = 'Too few reviews available to display.'\n",
    "\n",
    "        # Preparing location details for the selected business\n",
    "        locations = location_details(uniq_locs,'bus_id', selected_business, 'bus_add','bus_lat', 'bus_lon')\n",
    "        # Building map based on locations for the selected business\n",
    "        fig = build_map(locations)\n",
    "\n",
    "        # Gather the general sentiment for the selected business\n",
    "        gen_sent = general_sentiment(app_df, 'bus_id', selected_business, 'sentiment', 'accuracy')\n",
    "\n",
    "        # Generate OpenAI response\n",
    "        rev_rec = apply_davidlingo(gen_sent, reviews)\n",
    "\n",
    "        # Returning the label corresponding to the clicked item\n",
    "        return selected_business, avg_rtng, rev_tot, fig, rev_list, gen_sent, rev_rec\n",
    "    # Returning original placeholder text if none selected\n",
    "    return load_input, load_avg_rtng, load_tot_rvws, load_fig, load_revs, load_sent, load_rev_rec\n",
    "\n",
    "# Launch app (in browser tab) (comment out if running in notebook)\n",
    "app.run(jupyter_mode='tab')\n",
    "# Launch app (in notebook) (uncomment to run)\n",
    "# app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*End Code Space*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Vanessa's Code Space**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*End Code Space*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Train Test Splitting**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Scaling and Encoding**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modeling**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Application (?)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Findings**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Citations and Licenses**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Licenses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_dev",
   "language": "python",
   "name": "ai_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
