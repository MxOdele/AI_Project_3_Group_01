{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SpooderApp™**\n",
    "#### *Leveraging business reviews to gain insights for potential improvements.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis;\n",
    "\n",
    "\n",
    "Consumer reviews are critical to the success of any business, yet many lack the resources to effectively analyze and act on this feedback. We hypothesize that by leveraging advanced Natural Language Processing (NLP) models, specifically through HuggingFace Transformers and OpenAI LangChain, we can accurately classify customer sentiment and generate actionable recommendations. Our goal is to empower businesses with detailed sentiment analysis and dynamic feedback, enabling them to enhance consumer satisfaction and overall performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Initialization**\n",
    "\n",
    "When executing the following code, it is recommended to uncomment any necessary packages not yet installed in your environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instillations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installing necessary libraries \n",
    "# NOTE: Uncomment any libraries not currently present in your environment for\n",
    "#       initial execution of this notebook\n",
    "\n",
    "# General utilities\n",
    "# %pip install pandas --quiet                  # Data manipulation and analysis\n",
    "# %pip install numpy --quiet                   # Numerical computations\n",
    "# %pip install scipy --quiet                   # Scientific computing\n",
    "# %pip install matplotlib --quiet              # Plotting and visualization\n",
    "# %pip install seaborn --quiet                 # Statistical data visualization\n",
    "# %pip install tqdm --quiet                    # Progress bar for loops\n",
    "# %pip install gdown --quiet                   # Downloading files from Google Drive\n",
    "# %pip install zipfile --quiet                 # Working with zip files\n",
    "# %pip install json --quiet                    # JSON handling\n",
    "\n",
    "# Machine Learning & NLP\n",
    "# %pip install torch --quiet                   # PyTorch for deep learning\n",
    "# %pip install transformers --quiet            # HuggingFace Transformers\n",
    "# %pip install datasets --quiet                # HuggingFace Datasets\n",
    "# %pip install scikit-learn --quiet            # Machine learning tools\n",
    "# %pip install nltk --quiet                    # Natural Language Toolkit for text processing\n",
    "# %pip install huggingface-hub --quiet         # Hugging Face Hub for model upload\n",
    "# %pip install accelerate --quiet              # Accelerate training\n",
    "# %pip install evaluate --quiet                # Metric evaluation\n",
    "\n",
    "# Web scraping\n",
    "# %pip install selenium --quiet                # Browser automation\n",
    "# %pip install webdriver-manager --quiet       # Manage WebDriver binaries\n",
    "# %pip install beautifulsoup4 --quiet          # Parsing HTML and XML\n",
    "\n",
    "# Environment & API\n",
    "# %pip install python-dotenv --quiet           # Load environment variables\n",
    "# %pip install langchain --quiet               # OpenAI LangChain for AI models\n",
    "\n",
    "# Dash (Web App Framework)\n",
    "# %pip install dash --quiet                       # Dash core components\n",
    "# %pip install dash-bootstrap-components --quiet  # Dash Bootstrap components\n",
    "\n",
    "# Plotting & Visualization\n",
    "# %pip install plotly --quiet                  # Interactive graphing library"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\joblu\\anaconda3\\envs\\ai_dev\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# General Utilities\n",
    "import pandas as pd               # Data manipulation and analysis\n",
    "import os                         # Operating system interfaces\n",
    "import re                         # Regular expressions\n",
    "import json                       # JSON handling\n",
    "import time                       # Time management\n",
    "import zipfile                    # Working with zip files\n",
    "import unicodedata                # Unicode character handling\n",
    "import numpy as np                # Numerical computations\n",
    "import scipy as sp                # Scientific computing\n",
    "import gdown                      # Google Drive file download\n",
    "from tqdm import tqdm             # Progress bar for loops\n",
    "\n",
    "# Plotting and Visualization\n",
    "import matplotlib.pyplot as plt   # Plotting and visualization\n",
    "import seaborn as sns             # Statistical data visualization\n",
    "import plotly.express as px       # Simple interactive plots\n",
    "import plotly.graph_objects as go # Detailed interactive plots\n",
    "\n",
    "# Machine Learning & NLP\n",
    "import torch                                          # PyTorch for deep learning\n",
    "from sklearn.model_selection import train_test_split  # Data splitting for training and testing\n",
    "from datasets import load_metric                      # Compute metrics for NLP models\n",
    "import nltk                                           # Natural Language Toolkit for text processing\n",
    "from nltk.corpus import stopwords                     # Stop words for text preprocessing\n",
    "from nltk.tokenize import word_tokenize               # Tokenization of text\n",
    "import transformers                                   # HuggingFace Transformers\n",
    "\n",
    "# Pretrained Model and Tokenization\n",
    "from transformers import DistilBertForSequenceClassification, DistilBertTokenizer  # DistilBERT model and tokenizer\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification         # Auto-tokenizer and model for sequence classification\n",
    "from transformers import DataCollatorWithPadding                                   # Dynamic padding for batched data\n",
    "from transformers import TrainingArguments, Trainer                                # Training arguments and trainer\n",
    "from transformers import pipeline                                                  # Inference pipeline\n",
    "\n",
    "# Hugging Face Hub\n",
    "from huggingface_hub import notebook_login  # Login to Hugging Face Hub\n",
    "\n",
    "# Dataset Formatting\n",
    "import accelerate                           # Accelerate training\n",
    "from datasets import Dataset                # Dataset handling\n",
    "from evaluate import load                   # Metric evaluation\n",
    "\n",
    "# Web Scraping\n",
    "from selenium import webdriver                                          # Browser automation\n",
    "from selenium.webdriver.chrome.service import Service as ChromeService  # WebDriver service for Chrome\n",
    "from selenium.webdriver.support.ui import WebDriverWait                 # WebDriver wait\n",
    "from selenium.webdriver.common.by import By                             # Locating elements by attributes\n",
    "from selenium.webdriver.support import expected_conditions as EC        # Expected conditions for WebDriver waits\n",
    "from webdriver_manager.chrome import ChromeDriverManager                # Manage WebDriver binaries\n",
    "from bs4 import BeautifulSoup                                           # Parsing HTML and XML\n",
    "\n",
    "# Environment & API\n",
    "from dotenv import load_dotenv              # Load environment variables\n",
    "from langchain_openai import ChatOpenAI      # OpenAI API for LangChain\n",
    "\n",
    "# Prompt Template and LLM Chain\n",
    "from langchain import PromptTemplate        # Prompt template for LangChain\n",
    "from langchain.chains import LLMChain       # LLM Chain for linking models\n",
    "\n",
    "# Dash (Web App Framework)\n",
    "from dash import Dash, dcc, html, callback, callback_context  # Dash core components and callbacks\n",
    "from dash.dependencies import Input, Output, State            # Dash dependencies for callbacks\n",
    "from dash.exceptions import PreventUpdate                     # Prevent updates in callbacks\n",
    "import dash_bootstrap_components as dbc                       # Dash Bootstrap components\n",
    "\n",
    "# Other\n",
    "import math                       # Mathematical functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Data**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "To prepare our sentiment analysis model, we leveraged the __[Yelp Open Dataset](https://www.yelp.com/dataset)__ to harness existing reviews and ratings. We also explored other available metrics during our EDA, before proceeding to preprocessing and model training.\n",
    "\n",
    "The [Yelp Open Dataset](#Yelp-Open-Dataset) provided `.json` files with businesses, reviews, and user data from their businesses. Given the lack of image classification, we opted to forego the photo dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieval\n",
    "\n",
    "Due to the large size of the provided files, direct pushes to GitHub were not a viable option. Instead, the files were converted to `.csv` formates (outlined in `Resources/json_convesion_for_gdown.ipynb`) and uploaded to a Google Drive for retrieval through `gdown`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to access datasets through `gdown`\n",
    "def fetch_data(set):\n",
    "    '''\n",
    "    Fetches a specific dataset from Google Drive using gdown and loads it into a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        set (str):      A string representing the dataset to be retrieved. Must be one of the following;\n",
    "                        'buesiness', 'checkin', 'reviews', 'tip', or 'user'\n",
    "    \n",
    "    Returns:\n",
    "        df (DataFrame): A DataFrame with the retrieved Yelp dataset.\n",
    "\n",
    "    Raises:\n",
    "        ValueError:     If an invalid dataset identifier is provided.\n",
    "        OSError:        If there is an issue with downloading the file or reading the CSV file.\n",
    "        Exception:      If any other unexpected error occurs during the download or file reading process.\n",
    "    '''\n",
    "    # Declaring `url` and `output` for dataset\n",
    "    match set:\n",
    "        case 'business':\n",
    "            url = 'https://drive.google.com/file/d/1t-_rOjZ8oMqPcMJunVaMgY3OEbhnuSCv/view?usp=sharing'\n",
    "            output = 'Resources/business_dataset.csv'\n",
    "        case 'checkin':\n",
    "            url = 'https://drive.google.com/file/d/1_AVWp31ymfvf4QgTiMN_WLAeapfr0omf/view?usp=sharing'\n",
    "            output = 'Resources/checkin_dataset.csv'\n",
    "        case 'reviews':\n",
    "            url = 'https://drive.google.com/file/d/1L8rFjhOQyU90Ycr9t_OLA70vCYM0e7ck/view?usp=sharing'\n",
    "            output = 'Resources/reviews_dataset.csv'\n",
    "        case 'tip':\n",
    "            url = 'https://drive.google.com/file/d/1LMkCi5AFC_58_m7ELmn1hR8YDykuXwqq/view?usp=sharing'\n",
    "            output = 'Resources/tip_dataset.csv'\n",
    "        case 'user':\n",
    "            url = 'https://drive.google.com/file/d/1kQ522qcod7AjD5DO9vj8qFcSKxwJCDrO/view?usp=sharing'\n",
    "            output = 'Resources/user_dataset.csv'\n",
    "        case _:\n",
    "            # Raises\n",
    "            raise ValueError('Invalid dataset selected, please try again')\n",
    "    \n",
    "    # Attempting to fetch dataset\n",
    "    try:\n",
    "        # Downloading dataset\n",
    "        gdown.download(url, output, fuzzy=True, quiet=True)\n",
    "\n",
    "        # Reading in the dataset\n",
    "        df = pd.read_csv(output, low_memory=False)\n",
    "\n",
    "    # Raises\n",
    "    except ImportError as e:\n",
    "        raise ImportError(f\"Required module not found: {e}\")\n",
    "    except OSError as e:\n",
    "        raise OSError(f\"Error occurred during file operation: {e}\")\n",
    "    except Exception as e:\n",
    "        raise Exception(f\"An unexpected error occurred: {e}\")\n",
    "    \n",
    "    # Returning the dataset\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetching and Reading In\n",
    "\n",
    "*Note: Once the* `fetch_data()` *function has been run for all five (5) datasets, you may comment out those lines of code (annotaed in cell, as well). For any additional executions, use the* `pd.read_csv()` *lines instead.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joblu\\AppData\\Local\\Temp\\ipykernel_40052\\2535528066.py:13: DtypeWarning: Columns (8) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  user_df = pd.read_csv('./Resources/user_dataset.csv')\n"
     ]
    }
   ],
   "source": [
    "# Fetching all datasets (uncomment for first run of code)\n",
    "# business_df = fetch_data('business')\n",
    "# checkin_df = fetch_data('checkin')\n",
    "# reviews_df = fetch_data('reviews')\n",
    "# tips_df = fetch_data('tip')\n",
    "# user_df = fetch_data('user')\n",
    "\n",
    "# Reading in all datasets (uncomment if data already fetched)\n",
    "business_df = pd.read_csv('./Resources/business_dataset.csv')\n",
    "checkin_df = pd.read_csv('./Resources/checkin_dataset.csv')\n",
    "reviews_df = pd.read_csv('./Resources/reviews_dataset.csv')\n",
    "tips_df = pd.read_csv('./Resources/tip_dataset.csv')\n",
    "user_df = pd.read_csv('./Resources/user_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA\n",
    "\n",
    "Each dataset was explored individually before final feature selection and concatenation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Business dataset\n",
    "\n",
    "Contains business data including location data, attributes, and categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>attributes</th>\n",
       "      <th>categories</th>\n",
       "      <th>hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Pns2l4eNsfO8kk83dixA6A</td>\n",
       "      <td>Abby Rappoport, LAC, CMQ</td>\n",
       "      <td>1616 Chapala St, Ste 2</td>\n",
       "      <td>Santa Barbara</td>\n",
       "      <td>CA</td>\n",
       "      <td>93101</td>\n",
       "      <td>34.426679</td>\n",
       "      <td>-119.711197</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>{'ByAppointmentOnly': 'True'}</td>\n",
       "      <td>Doctors, Traditional Chinese Medicine, Naturop...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mpf3x-BjTdTEA3yCZrAYPw</td>\n",
       "      <td>The UPS Store</td>\n",
       "      <td>87 Grasso Plaza Shopping Center</td>\n",
       "      <td>Affton</td>\n",
       "      <td>MO</td>\n",
       "      <td>63123</td>\n",
       "      <td>38.551126</td>\n",
       "      <td>-90.335695</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': 'True'}</td>\n",
       "      <td>Shipping Centers, Local Services, Notaries, Ma...</td>\n",
       "      <td>{'Monday': '0:0-0:0', 'Tuesday': '8:0-18:30', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tUFrWirKiKi_TAnsVWINQQ</td>\n",
       "      <td>Target</td>\n",
       "      <td>5255 E Broadway Blvd</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>AZ</td>\n",
       "      <td>85711</td>\n",
       "      <td>32.223236</td>\n",
       "      <td>-110.880452</td>\n",
       "      <td>3.5</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>{'BikeParking': 'True', 'BusinessAcceptsCredit...</td>\n",
       "      <td>Department Stores, Shopping, Fashion, Home &amp; G...</td>\n",
       "      <td>{'Monday': '8:0-22:0', 'Tuesday': '8:0-22:0', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MTSW4McQd7CbVtyjqoe9mw</td>\n",
       "      <td>St Honore Pastries</td>\n",
       "      <td>935 Race St</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>19107</td>\n",
       "      <td>39.955505</td>\n",
       "      <td>-75.155564</td>\n",
       "      <td>4.0</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RestaurantsDelivery': 'False', 'OutdoorSeati...</td>\n",
       "      <td>Restaurants, Food, Bubble Tea, Coffee &amp; Tea, B...</td>\n",
       "      <td>{'Monday': '7:0-20:0', 'Tuesday': '7:0-20:0', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mWMc6_wTdE0EUBKIGXDVfA</td>\n",
       "      <td>Perkiomen Valley Brewery</td>\n",
       "      <td>101 Walnut St</td>\n",
       "      <td>Green Lane</td>\n",
       "      <td>PA</td>\n",
       "      <td>18054</td>\n",
       "      <td>40.338183</td>\n",
       "      <td>-75.471659</td>\n",
       "      <td>4.5</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': 'True', 'Wheelc...</td>\n",
       "      <td>Brewpubs, Breweries, Food</td>\n",
       "      <td>{'Wednesday': '14:0-22:0', 'Thursday': '16:0-2...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                      name  \\\n",
       "0  Pns2l4eNsfO8kk83dixA6A  Abby Rappoport, LAC, CMQ   \n",
       "1  mpf3x-BjTdTEA3yCZrAYPw             The UPS Store   \n",
       "2  tUFrWirKiKi_TAnsVWINQQ                    Target   \n",
       "3  MTSW4McQd7CbVtyjqoe9mw        St Honore Pastries   \n",
       "4  mWMc6_wTdE0EUBKIGXDVfA  Perkiomen Valley Brewery   \n",
       "\n",
       "                           address           city state postal_code  \\\n",
       "0           1616 Chapala St, Ste 2  Santa Barbara    CA       93101   \n",
       "1  87 Grasso Plaza Shopping Center         Affton    MO       63123   \n",
       "2             5255 E Broadway Blvd         Tucson    AZ       85711   \n",
       "3                      935 Race St   Philadelphia    PA       19107   \n",
       "4                    101 Walnut St     Green Lane    PA       18054   \n",
       "\n",
       "    latitude   longitude  stars  review_count  is_open  \\\n",
       "0  34.426679 -119.711197    5.0             7        0   \n",
       "1  38.551126  -90.335695    3.0            15        1   \n",
       "2  32.223236 -110.880452    3.5            22        0   \n",
       "3  39.955505  -75.155564    4.0            80        1   \n",
       "4  40.338183  -75.471659    4.5            13        1   \n",
       "\n",
       "                                          attributes  \\\n",
       "0                      {'ByAppointmentOnly': 'True'}   \n",
       "1             {'BusinessAcceptsCreditCards': 'True'}   \n",
       "2  {'BikeParking': 'True', 'BusinessAcceptsCredit...   \n",
       "3  {'RestaurantsDelivery': 'False', 'OutdoorSeati...   \n",
       "4  {'BusinessAcceptsCreditCards': 'True', 'Wheelc...   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Doctors, Traditional Chinese Medicine, Naturop...   \n",
       "1  Shipping Centers, Local Services, Notaries, Ma...   \n",
       "2  Department Stores, Shopping, Fashion, Home & G...   \n",
       "3  Restaurants, Food, Bubble Tea, Coffee & Tea, B...   \n",
       "4                          Brewpubs, Breweries, Food   \n",
       "\n",
       "                                               hours  \n",
       "0                                                NaN  \n",
       "1  {'Monday': '0:0-0:0', 'Tuesday': '8:0-18:30', ...  \n",
       "2  {'Monday': '8:0-22:0', 'Tuesday': '8:0-22:0', ...  \n",
       "3  {'Monday': '7:0-20:0', 'Tuesday': '7:0-20:0', ...  \n",
       "4  {'Wednesday': '14:0-22:0', 'Thursday': '16:0-2...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previewing the data\n",
    "business_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150346 entries, 0 to 150345\n",
      "Data columns (total 14 columns):\n",
      " #   Column        Non-Null Count   Dtype  \n",
      "---  ------        --------------   -----  \n",
      " 0   business_id   150346 non-null  object \n",
      " 1   name          150346 non-null  object \n",
      " 2   address       145219 non-null  object \n",
      " 3   city          150346 non-null  object \n",
      " 4   state         150346 non-null  object \n",
      " 5   postal_code   150273 non-null  object \n",
      " 6   latitude      150346 non-null  float64\n",
      " 7   longitude     150346 non-null  float64\n",
      " 8   stars         150346 non-null  float64\n",
      " 9   review_count  150346 non-null  int64  \n",
      " 10  is_open       150346 non-null  int64  \n",
      " 11  attributes    136602 non-null  object \n",
      " 12  categories    150243 non-null  object \n",
      " 13  hours         127123 non-null  object \n",
      "dtypes: float64(3), int64(2), object(9)\n",
      "memory usage: 16.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Confirming additional data details\n",
    "business_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkin dataset\n",
    "\n",
    "Contains checkins on a business."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>---kPU91CF4Lq2-WlRu9Lw</td>\n",
       "      <td>2020-03-13 21:10:56, 2020-06-02 22:18:06, 2020...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>--0iUa4sNDFiZFrAdIWhZQ</td>\n",
       "      <td>2010-09-13 21:43:09, 2011-05-04 23:08:15, 2011...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>--30_8IhuyMHbSOcNWd6DQ</td>\n",
       "      <td>2013-06-14 23:29:17, 2014-08-13 23:20:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>--7PUidqRWpRSpXebiyxTg</td>\n",
       "      <td>2011-02-15 17:12:00, 2011-07-28 02:46:10, 2012...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>--7jw19RH9JKXgFohspgQw</td>\n",
       "      <td>2014-04-21 20:42:11, 2014-04-28 21:04:46, 2014...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id                                               date\n",
       "0  ---kPU91CF4Lq2-WlRu9Lw  2020-03-13 21:10:56, 2020-06-02 22:18:06, 2020...\n",
       "1  --0iUa4sNDFiZFrAdIWhZQ  2010-09-13 21:43:09, 2011-05-04 23:08:15, 2011...\n",
       "2  --30_8IhuyMHbSOcNWd6DQ           2013-06-14 23:29:17, 2014-08-13 23:20:22\n",
       "3  --7PUidqRWpRSpXebiyxTg  2011-02-15 17:12:00, 2011-07-28 02:46:10, 2012...\n",
       "4  --7jw19RH9JKXgFohspgQw  2014-04-21 20:42:11, 2014-04-28 21:04:46, 2014..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previewing the data\n",
    "checkin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 131930 entries, 0 to 131929\n",
      "Data columns (total 2 columns):\n",
      " #   Column       Non-Null Count   Dtype \n",
      "---  ------       --------------   ----- \n",
      " 0   business_id  131930 non-null  object\n",
      " 1   date         131930 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 2.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Confirming additional data details\n",
    "checkin_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: We determined this dataset would not add any value to our training data.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reviews dataset\n",
    "\n",
    "Contains full review text data including the user_id that wrote the review and the business_id the review is written for."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KU_O5udG6zpxOg-VcAEodg</td>\n",
       "      <td>mh_-eMZ6K5RLWhZyISBhwA</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>If you decide to eat here, just be aware it is...</td>\n",
       "      <td>2018-07-07 22:09:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BiTunyQ73aT9WBnpR9DZGw</td>\n",
       "      <td>OyoGAe7OKpv6SyGZT5g77Q</td>\n",
       "      <td>7ATYjTIgM3jUlt4UM3IypQ</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>I've taken a lot of spin classes over the year...</td>\n",
       "      <td>2012-01-03 15:28:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>saUsX_uimxRlCVr67Z4Jig</td>\n",
       "      <td>8g_iMtfSiwikVnbP2etR0A</td>\n",
       "      <td>YjUWPpI6HXG530lwP-fb2A</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Family diner. Had the buffet. Eclectic assortm...</td>\n",
       "      <td>2014-02-05 20:30:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AqPFMleE6RsU23_auESxiA</td>\n",
       "      <td>_7bHUi9Uuf5__HHc_Q8guQ</td>\n",
       "      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Wow!  Yummy, different,  delicious.   Our favo...</td>\n",
       "      <td>2015-01-04 00:01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sx8TMOWLNuJBWer-0pcmoA</td>\n",
       "      <td>bcjbaE6dDog4jkNY91ncLQ</td>\n",
       "      <td>e4Vwtrqf-wpJfwesgvdgxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cute interior and owner (?) gave us tour of up...</td>\n",
       "      <td>2017-01-14 20:54:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                review_id                 user_id             business_id  \\\n",
       "0  KU_O5udG6zpxOg-VcAEodg  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw   \n",
       "1  BiTunyQ73aT9WBnpR9DZGw  OyoGAe7OKpv6SyGZT5g77Q  7ATYjTIgM3jUlt4UM3IypQ   \n",
       "2  saUsX_uimxRlCVr67Z4Jig  8g_iMtfSiwikVnbP2etR0A  YjUWPpI6HXG530lwP-fb2A   \n",
       "3  AqPFMleE6RsU23_auESxiA  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA   \n",
       "4  Sx8TMOWLNuJBWer-0pcmoA  bcjbaE6dDog4jkNY91ncLQ  e4Vwtrqf-wpJfwesgvdgxQ   \n",
       "\n",
       "   stars  useful  funny  cool  \\\n",
       "0      3       0      0     0   \n",
       "1      5       1      0     1   \n",
       "2      3       0      0     0   \n",
       "3      5       1      0     1   \n",
       "4      4       1      0     1   \n",
       "\n",
       "                                                text                 date  \n",
       "0  If you decide to eat here, just be aware it is...  2018-07-07 22:09:11  \n",
       "1  I've taken a lot of spin classes over the year...  2012-01-03 15:28:18  \n",
       "2  Family diner. Had the buffet. Eclectic assortm...  2014-02-05 20:30:30  \n",
       "3  Wow!  Yummy, different,  delicious.   Our favo...  2015-01-04 00:01:03  \n",
       "4  Cute interior and owner (?) gave us tour of up...  2017-01-14 20:54:15  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previewing the data\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6990280 entries, 0 to 6990279\n",
      "Data columns (total 9 columns):\n",
      " #   Column       Dtype \n",
      "---  ------       ----- \n",
      " 0   review_id    object\n",
      " 1   user_id      object\n",
      " 2   business_id  object\n",
      " 3   stars        int64 \n",
      " 4   useful       int64 \n",
      " 5   funny        int64 \n",
      " 6   cool         int64 \n",
      " 7   text         object\n",
      " 8   date         object\n",
      "dtypes: int64(4), object(5)\n",
      "memory usage: 480.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Confirming additional data details\n",
    "reviews_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Na count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "review_id      0\n",
       "user_id        0\n",
       "business_id    0\n",
       "stars          0\n",
       "useful         0\n",
       "funny          0\n",
       "cool           0\n",
       "text           0\n",
       "date           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifying missing records\n",
    "reviews_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping features:\n",
    "- **review_id**\n",
    "- **useful**\n",
    "- **funny**\n",
    "- **cool**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping features\n",
    "reviews_df.drop(columns = ['review_id','useful','funny','cool'],\n",
    "                inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming features:\n",
    "- **text** to **review**\n",
    "\n",
    "*Note: This change was reverted before model training.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>review</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mh_-eMZ6K5RLWhZyISBhwA</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>3</td>\n",
       "      <td>If you decide to eat here, just be aware it is...</td>\n",
       "      <td>2018-07-07 22:09:11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OyoGAe7OKpv6SyGZT5g77Q</td>\n",
       "      <td>7ATYjTIgM3jUlt4UM3IypQ</td>\n",
       "      <td>5</td>\n",
       "      <td>I've taken a lot of spin classes over the year...</td>\n",
       "      <td>2012-01-03 15:28:18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8g_iMtfSiwikVnbP2etR0A</td>\n",
       "      <td>YjUWPpI6HXG530lwP-fb2A</td>\n",
       "      <td>3</td>\n",
       "      <td>Family diner. Had the buffet. Eclectic assortm...</td>\n",
       "      <td>2014-02-05 20:30:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_7bHUi9Uuf5__HHc_Q8guQ</td>\n",
       "      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n",
       "      <td>5</td>\n",
       "      <td>Wow!  Yummy, different,  delicious.   Our favo...</td>\n",
       "      <td>2015-01-04 00:01:03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bcjbaE6dDog4jkNY91ncLQ</td>\n",
       "      <td>e4Vwtrqf-wpJfwesgvdgxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>Cute interior and owner (?) gave us tour of up...</td>\n",
       "      <td>2017-01-14 20:54:15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id             business_id  stars  \\\n",
       "0  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw      3   \n",
       "1  OyoGAe7OKpv6SyGZT5g77Q  7ATYjTIgM3jUlt4UM3IypQ      5   \n",
       "2  8g_iMtfSiwikVnbP2etR0A  YjUWPpI6HXG530lwP-fb2A      3   \n",
       "3  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA      5   \n",
       "4  bcjbaE6dDog4jkNY91ncLQ  e4Vwtrqf-wpJfwesgvdgxQ      4   \n",
       "\n",
       "                                              review                 date  \n",
       "0  If you decide to eat here, just be aware it is...  2018-07-07 22:09:11  \n",
       "1  I've taken a lot of spin classes over the year...  2012-01-03 15:28:18  \n",
       "2  Family diner. Had the buffet. Eclectic assortm...  2014-02-05 20:30:30  \n",
       "3  Wow!  Yummy, different,  delicious.   Our favo...  2015-01-04 00:01:03  \n",
       "4  Cute interior and owner (?) gave us tour of up...  2017-01-14 20:54:15  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renaming features\n",
    "reviews_df.rename(columns = {'text':'review'},inplace = True)\n",
    "\n",
    "#Confirming columns renamed\n",
    "reviews_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Dropped:*\n",
    "- **review_id:** *Eliminated due to low informational value.*\n",
    "- **useful:** *Eliminated due to low relevance.*\n",
    "- **funny:** *Eliminated due to low relevance.*\n",
    "- **cool:** *Eliminated due to low relevance.*\n",
    "\n",
    "*Essential:*\n",
    "- **business_id:** *Used as an identifier for concatenation.*\n",
    "- **stars:** *Used as eventual model target.*\n",
    "- **review:** *Used as feature for multiple models.*\n",
    "\n",
    "*Retained:*\n",
    "- **date:** *Retained for potential time series analysis.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tips dataset\n",
    "\n",
    "Contains tips written by a user on a business. Tips are shorter than reviews and tend to convey quick suggestions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>text</th>\n",
       "      <th>date</th>\n",
       "      <th>compliment_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGNUgVwnZUey3gcPCJ76iw</td>\n",
       "      <td>3uLgwr0qeCNMjKenHJwPGQ</td>\n",
       "      <td>Avengers time with the ladies.</td>\n",
       "      <td>2012-05-18 02:17:21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NBN4MgHP9D3cw--SnauTkA</td>\n",
       "      <td>QoezRbYQncpRqyrLH6Iqjg</td>\n",
       "      <td>They have lots of good deserts and tasty cuban...</td>\n",
       "      <td>2013-02-05 18:35:10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-copOvldyKh1qr-vzkDEvw</td>\n",
       "      <td>MYoRNLb5chwjQe3c_k37Gg</td>\n",
       "      <td>It's open even when you think it isn't</td>\n",
       "      <td>2013-08-18 00:56:08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FjMQVZjSqY8syIO-53KFKw</td>\n",
       "      <td>hV-bABTK-glh5wj31ps_Jw</td>\n",
       "      <td>Very decent fried chicken</td>\n",
       "      <td>2017-06-27 23:05:38</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ld0AperBXk1h6UbqmM80zw</td>\n",
       "      <td>_uN0OudeJ3Zl_tf6nxg5ww</td>\n",
       "      <td>Appetizers.. platter special for lunch</td>\n",
       "      <td>2012-10-06 19:43:09</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id             business_id  \\\n",
       "0  AGNUgVwnZUey3gcPCJ76iw  3uLgwr0qeCNMjKenHJwPGQ   \n",
       "1  NBN4MgHP9D3cw--SnauTkA  QoezRbYQncpRqyrLH6Iqjg   \n",
       "2  -copOvldyKh1qr-vzkDEvw  MYoRNLb5chwjQe3c_k37Gg   \n",
       "3  FjMQVZjSqY8syIO-53KFKw  hV-bABTK-glh5wj31ps_Jw   \n",
       "4  ld0AperBXk1h6UbqmM80zw  _uN0OudeJ3Zl_tf6nxg5ww   \n",
       "\n",
       "                                                text                 date  \\\n",
       "0                     Avengers time with the ladies.  2012-05-18 02:17:21   \n",
       "1  They have lots of good deserts and tasty cuban...  2013-02-05 18:35:10   \n",
       "2             It's open even when you think it isn't  2013-08-18 00:56:08   \n",
       "3                          Very decent fried chicken  2017-06-27 23:05:38   \n",
       "4             Appetizers.. platter special for lunch  2012-10-06 19:43:09   \n",
       "\n",
       "   compliment_count  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previewing the data\n",
    "tips_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 908915 entries, 0 to 908914\n",
      "Data columns (total 5 columns):\n",
      " #   Column            Non-Null Count   Dtype \n",
      "---  ------            --------------   ----- \n",
      " 0   user_id           908915 non-null  object\n",
      " 1   business_id       908915 non-null  object\n",
      " 2   text              908901 non-null  object\n",
      " 3   date              908915 non-null  object\n",
      " 4   compliment_count  908915 non-null  int64 \n",
      "dtypes: int64(1), object(4)\n",
      "memory usage: 34.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Confirming additional data details\n",
    "tips_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping features:\n",
    "- **compliment_count**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping features\n",
    "tips_df.drop(columns = ['compliment_count'],\n",
    "             inplace =True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming features:\n",
    "- **text** to **recommendations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>recommendations</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGNUgVwnZUey3gcPCJ76iw</td>\n",
       "      <td>3uLgwr0qeCNMjKenHJwPGQ</td>\n",
       "      <td>Avengers time with the ladies.</td>\n",
       "      <td>2012-05-18 02:17:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NBN4MgHP9D3cw--SnauTkA</td>\n",
       "      <td>QoezRbYQncpRqyrLH6Iqjg</td>\n",
       "      <td>They have lots of good deserts and tasty cuban...</td>\n",
       "      <td>2013-02-05 18:35:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-copOvldyKh1qr-vzkDEvw</td>\n",
       "      <td>MYoRNLb5chwjQe3c_k37Gg</td>\n",
       "      <td>It's open even when you think it isn't</td>\n",
       "      <td>2013-08-18 00:56:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FjMQVZjSqY8syIO-53KFKw</td>\n",
       "      <td>hV-bABTK-glh5wj31ps_Jw</td>\n",
       "      <td>Very decent fried chicken</td>\n",
       "      <td>2017-06-27 23:05:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ld0AperBXk1h6UbqmM80zw</td>\n",
       "      <td>_uN0OudeJ3Zl_tf6nxg5ww</td>\n",
       "      <td>Appetizers.. platter special for lunch</td>\n",
       "      <td>2012-10-06 19:43:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id             business_id  \\\n",
       "0  AGNUgVwnZUey3gcPCJ76iw  3uLgwr0qeCNMjKenHJwPGQ   \n",
       "1  NBN4MgHP9D3cw--SnauTkA  QoezRbYQncpRqyrLH6Iqjg   \n",
       "2  -copOvldyKh1qr-vzkDEvw  MYoRNLb5chwjQe3c_k37Gg   \n",
       "3  FjMQVZjSqY8syIO-53KFKw  hV-bABTK-glh5wj31ps_Jw   \n",
       "4  ld0AperBXk1h6UbqmM80zw  _uN0OudeJ3Zl_tf6nxg5ww   \n",
       "\n",
       "                                     recommendations                 date  \n",
       "0                     Avengers time with the ladies.  2012-05-18 02:17:21  \n",
       "1  They have lots of good deserts and tasty cuban...  2013-02-05 18:35:10  \n",
       "2             It's open even when you think it isn't  2013-08-18 00:56:08  \n",
       "3                          Very decent fried chicken  2017-06-27 23:05:38  \n",
       "4             Appetizers.. platter special for lunch  2012-10-06 19:43:09  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Renaming columns\n",
    "tips_df.rename(columns = {'text':'recommendations'},inplace = True)\n",
    "\n",
    "#Confirming columns renamed\n",
    "tips_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Dropped:*\n",
    "- **compliment_count:** *Eliminated due to low informational value.*\n",
    "\n",
    "*Retained:*\n",
    "- **recommendations:** *Retained for potential use as a target variable, since dataset has similar poitential for insights to improve the customer experience.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### User dataset\n",
    "\n",
    "Contains user data including the user's friend mapping and all the metadata associated with the user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>name</th>\n",
       "      <th>review_count</th>\n",
       "      <th>yelping_since</th>\n",
       "      <th>useful</th>\n",
       "      <th>funny</th>\n",
       "      <th>cool</th>\n",
       "      <th>elite</th>\n",
       "      <th>friends</th>\n",
       "      <th>fans</th>\n",
       "      <th>...</th>\n",
       "      <th>compliment_more</th>\n",
       "      <th>compliment_profile</th>\n",
       "      <th>compliment_cute</th>\n",
       "      <th>compliment_list</th>\n",
       "      <th>compliment_note</th>\n",
       "      <th>compliment_plain</th>\n",
       "      <th>compliment_cool</th>\n",
       "      <th>compliment_funny</th>\n",
       "      <th>compliment_writer</th>\n",
       "      <th>compliment_photos</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qVc8ODYU5SZjKXVBgXdI7w</td>\n",
       "      <td>Walker</td>\n",
       "      <td>585</td>\n",
       "      <td>2007-01-25 16:47:26</td>\n",
       "      <td>7217</td>\n",
       "      <td>1259</td>\n",
       "      <td>5994</td>\n",
       "      <td>2007</td>\n",
       "      <td>NSCy54eWehBJyZdG2iE84w, pe42u7DcCH2QmI81NX-8qA...</td>\n",
       "      <td>267</td>\n",
       "      <td>...</td>\n",
       "      <td>65</td>\n",
       "      <td>55</td>\n",
       "      <td>56</td>\n",
       "      <td>18</td>\n",
       "      <td>232</td>\n",
       "      <td>844</td>\n",
       "      <td>467</td>\n",
       "      <td>467</td>\n",
       "      <td>239</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>j14WgRoU_-2ZE1aw1dXrJg</td>\n",
       "      <td>Daniel</td>\n",
       "      <td>4333</td>\n",
       "      <td>2009-01-25 04:35:42</td>\n",
       "      <td>43091</td>\n",
       "      <td>13066</td>\n",
       "      <td>27281</td>\n",
       "      <td>2009,2010,2011,2012,2013,2014,2015,2016,2017,2...</td>\n",
       "      <td>ueRPE0CX75ePGMqOFVj6IQ, 52oH4DrRvzzl8wh5UXyU0A...</td>\n",
       "      <td>3138</td>\n",
       "      <td>...</td>\n",
       "      <td>264</td>\n",
       "      <td>184</td>\n",
       "      <td>157</td>\n",
       "      <td>251</td>\n",
       "      <td>1847</td>\n",
       "      <td>7054</td>\n",
       "      <td>3131</td>\n",
       "      <td>3131</td>\n",
       "      <td>1521</td>\n",
       "      <td>1946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2WnXYQFK0hXEoTxPtV2zvg</td>\n",
       "      <td>Steph</td>\n",
       "      <td>665</td>\n",
       "      <td>2008-07-25 10:41:00</td>\n",
       "      <td>2086</td>\n",
       "      <td>1010</td>\n",
       "      <td>1003</td>\n",
       "      <td>2009,2010,2011,2012,2013</td>\n",
       "      <td>LuO3Bn4f3rlhyHIaNfTlnA, j9B4XdHUhDfTKVecyWQgyA...</td>\n",
       "      <td>52</td>\n",
       "      <td>...</td>\n",
       "      <td>13</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>66</td>\n",
       "      <td>96</td>\n",
       "      <td>119</td>\n",
       "      <td>119</td>\n",
       "      <td>35</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SZDeASXq7o05mMNLshsdIA</td>\n",
       "      <td>Gwen</td>\n",
       "      <td>224</td>\n",
       "      <td>2005-11-29 04:38:33</td>\n",
       "      <td>512</td>\n",
       "      <td>330</td>\n",
       "      <td>299</td>\n",
       "      <td>2009,2010,2011</td>\n",
       "      <td>enx1vVPnfdNUdPho6PH_wg, 4wOcvMLtU6a9Lslggq74Vg...</td>\n",
       "      <td>28</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>16</td>\n",
       "      <td>26</td>\n",
       "      <td>26</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hA5lMy-EnncsH4JoR-hFGQ</td>\n",
       "      <td>Karen</td>\n",
       "      <td>79</td>\n",
       "      <td>2007-01-05 19:40:59</td>\n",
       "      <td>29</td>\n",
       "      <td>15</td>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PBK4q9KEEBHhFvSXCUirIw, 3FWPpM7KU1gXeOM_ZbYMbA...</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id    name  review_count        yelping_since  useful  \\\n",
       "0  qVc8ODYU5SZjKXVBgXdI7w  Walker           585  2007-01-25 16:47:26    7217   \n",
       "1  j14WgRoU_-2ZE1aw1dXrJg  Daniel          4333  2009-01-25 04:35:42   43091   \n",
       "2  2WnXYQFK0hXEoTxPtV2zvg   Steph           665  2008-07-25 10:41:00    2086   \n",
       "3  SZDeASXq7o05mMNLshsdIA    Gwen           224  2005-11-29 04:38:33     512   \n",
       "4  hA5lMy-EnncsH4JoR-hFGQ   Karen            79  2007-01-05 19:40:59      29   \n",
       "\n",
       "   funny   cool                                              elite  \\\n",
       "0   1259   5994                                               2007   \n",
       "1  13066  27281  2009,2010,2011,2012,2013,2014,2015,2016,2017,2...   \n",
       "2   1010   1003                           2009,2010,2011,2012,2013   \n",
       "3    330    299                                     2009,2010,2011   \n",
       "4     15      7                                                NaN   \n",
       "\n",
       "                                             friends  fans  ...  \\\n",
       "0  NSCy54eWehBJyZdG2iE84w, pe42u7DcCH2QmI81NX-8qA...   267  ...   \n",
       "1  ueRPE0CX75ePGMqOFVj6IQ, 52oH4DrRvzzl8wh5UXyU0A...  3138  ...   \n",
       "2  LuO3Bn4f3rlhyHIaNfTlnA, j9B4XdHUhDfTKVecyWQgyA...    52  ...   \n",
       "3  enx1vVPnfdNUdPho6PH_wg, 4wOcvMLtU6a9Lslggq74Vg...    28  ...   \n",
       "4  PBK4q9KEEBHhFvSXCUirIw, 3FWPpM7KU1gXeOM_ZbYMbA...     1  ...   \n",
       "\n",
       "   compliment_more  compliment_profile  compliment_cute  compliment_list  \\\n",
       "0               65                  55               56               18   \n",
       "1              264                 184              157              251   \n",
       "2               13                  10               17                3   \n",
       "3                4                   1                6                2   \n",
       "4                1                   0                0                0   \n",
       "\n",
       "   compliment_note  compliment_plain  compliment_cool  compliment_funny  \\\n",
       "0              232               844              467               467   \n",
       "1             1847              7054             3131              3131   \n",
       "2               66                96              119               119   \n",
       "3               12                16               26                26   \n",
       "4                1                 1                0                 0   \n",
       "\n",
       "   compliment_writer  compliment_photos  \n",
       "0                239                180  \n",
       "1               1521               1946  \n",
       "2                 35                 18  \n",
       "3                 10                  9  \n",
       "4                  0                  0  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previewing the data\n",
    "user_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1987897 entries, 0 to 1987896\n",
      "Data columns (total 22 columns):\n",
      " #   Column              Dtype  \n",
      "---  ------              -----  \n",
      " 0   user_id             object \n",
      " 1   name                object \n",
      " 2   review_count        int64  \n",
      " 3   yelping_since       object \n",
      " 4   useful              int64  \n",
      " 5   funny               int64  \n",
      " 6   cool                int64  \n",
      " 7   elite               object \n",
      " 8   friends             object \n",
      " 9   fans                int64  \n",
      " 10  average_stars       float64\n",
      " 11  compliment_hot      int64  \n",
      " 12  compliment_more     int64  \n",
      " 13  compliment_profile  int64  \n",
      " 14  compliment_cute     int64  \n",
      " 15  compliment_list     int64  \n",
      " 16  compliment_note     int64  \n",
      " 17  compliment_plain    int64  \n",
      " 18  compliment_cool     int64  \n",
      " 19  compliment_funny    int64  \n",
      " 20  compliment_writer   int64  \n",
      " 21  compliment_photos   int64  \n",
      "dtypes: float64(1), int64(16), object(5)\n",
      "memory usage: 333.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Confirming additional data details\n",
    "user_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: We decided this dataset was not to be included in the training data to preserve user anonimity.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenation\n",
    "\n",
    "Merging the `reviews` and `business` data sets to create a single DataFrame to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring `data_df` as the merge of `reviews_df` and `business_df`\n",
    "data_df = reviews_df.merge(business_df,how='left',on = 'business_id')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6990280 entries, 0 to 6990279\n",
      "Data columns (total 18 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   user_id       object \n",
      " 1   business_id   object \n",
      " 2   stars_x       int64  \n",
      " 3   review        object \n",
      " 4   date          object \n",
      " 5   name          object \n",
      " 6   address       object \n",
      " 7   city          object \n",
      " 8   state         object \n",
      " 9   postal_code   object \n",
      " 10  latitude      float64\n",
      " 11  longitude     float64\n",
      " 12  stars_y       float64\n",
      " 13  review_count  int64  \n",
      " 14  is_open       int64  \n",
      " 15  attributes    object \n",
      " 16  categories    object \n",
      " 17  hours         object \n",
      "dtypes: float64(3), int64(3), object(12)\n",
      "memory usage: 960.0+ MB\n"
     ]
    }
   ],
   "source": [
    "# Confirming additional data details\n",
    "data_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars_x</th>\n",
       "      <th>review</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars_y</th>\n",
       "      <th>review_count</th>\n",
       "      <th>is_open</th>\n",
       "      <th>attributes</th>\n",
       "      <th>categories</th>\n",
       "      <th>hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mh_-eMZ6K5RLWhZyISBhwA</td>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>3</td>\n",
       "      <td>If you decide to eat here, just be aware it is...</td>\n",
       "      <td>2018-07-07 22:09:11</td>\n",
       "      <td>Turning Point of North Wales</td>\n",
       "      <td>1460 Bethlehem Pike</td>\n",
       "      <td>North Wales</td>\n",
       "      <td>PA</td>\n",
       "      <td>19454</td>\n",
       "      <td>40.210196</td>\n",
       "      <td>-75.223639</td>\n",
       "      <td>3.0</td>\n",
       "      <td>169</td>\n",
       "      <td>1</td>\n",
       "      <td>{'NoiseLevel': \"u'average'\", 'HasTV': 'False',...</td>\n",
       "      <td>Restaurants, Breakfast &amp; Brunch, Food, Juice B...</td>\n",
       "      <td>{'Monday': '7:30-15:0', 'Tuesday': '7:30-15:0'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>OyoGAe7OKpv6SyGZT5g77Q</td>\n",
       "      <td>7ATYjTIgM3jUlt4UM3IypQ</td>\n",
       "      <td>5</td>\n",
       "      <td>I've taken a lot of spin classes over the year...</td>\n",
       "      <td>2012-01-03 15:28:18</td>\n",
       "      <td>Body Cycle Spinning Studio</td>\n",
       "      <td>1923 Chestnut St, 2nd Fl</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>19119</td>\n",
       "      <td>39.952103</td>\n",
       "      <td>-75.172753</td>\n",
       "      <td>5.0</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>{'BusinessAcceptsCreditCards': 'True', 'GoodFo...</td>\n",
       "      <td>Active Life, Cycling Classes, Trainers, Gyms, ...</td>\n",
       "      <td>{'Monday': '6:30-20:30', 'Tuesday': '6:30-20:3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8g_iMtfSiwikVnbP2etR0A</td>\n",
       "      <td>YjUWPpI6HXG530lwP-fb2A</td>\n",
       "      <td>3</td>\n",
       "      <td>Family diner. Had the buffet. Eclectic assortm...</td>\n",
       "      <td>2014-02-05 20:30:30</td>\n",
       "      <td>Kettle Restaurant</td>\n",
       "      <td>748 W Starr Pass Blvd</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>AZ</td>\n",
       "      <td>85713</td>\n",
       "      <td>32.207233</td>\n",
       "      <td>-110.980864</td>\n",
       "      <td>3.5</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>{'RestaurantsReservations': 'True', 'BusinessP...</td>\n",
       "      <td>Restaurants, Breakfast &amp; Brunch</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_7bHUi9Uuf5__HHc_Q8guQ</td>\n",
       "      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n",
       "      <td>5</td>\n",
       "      <td>Wow!  Yummy, different,  delicious.   Our favo...</td>\n",
       "      <td>2015-01-04 00:01:03</td>\n",
       "      <td>Zaika</td>\n",
       "      <td>2481 Grant Ave</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>19114</td>\n",
       "      <td>40.079848</td>\n",
       "      <td>-75.025080</td>\n",
       "      <td>4.0</td>\n",
       "      <td>181</td>\n",
       "      <td>1</td>\n",
       "      <td>{'Caters': 'True', 'Ambience': \"{'romantic': F...</td>\n",
       "      <td>Halal, Pakistani, Restaurants, Indian</td>\n",
       "      <td>{'Tuesday': '11:0-21:0', 'Wednesday': '11:0-21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bcjbaE6dDog4jkNY91ncLQ</td>\n",
       "      <td>e4Vwtrqf-wpJfwesgvdgxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>Cute interior and owner (?) gave us tour of up...</td>\n",
       "      <td>2017-01-14 20:54:15</td>\n",
       "      <td>Melt</td>\n",
       "      <td>2549 Banks St</td>\n",
       "      <td>New Orleans</td>\n",
       "      <td>LA</td>\n",
       "      <td>70119</td>\n",
       "      <td>29.962102</td>\n",
       "      <td>-90.087958</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>{'BusinessParking': \"{'garage': False, 'street...</td>\n",
       "      <td>Sandwiches, Beer, Wine &amp; Spirits, Bars, Food, ...</td>\n",
       "      <td>{'Monday': '0:0-0:0', 'Friday': '11:0-17:0', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id             business_id  stars_x  \\\n",
       "0  mh_-eMZ6K5RLWhZyISBhwA  XQfwVwDr-v0ZS3_CbbE5Xw        3   \n",
       "1  OyoGAe7OKpv6SyGZT5g77Q  7ATYjTIgM3jUlt4UM3IypQ        5   \n",
       "2  8g_iMtfSiwikVnbP2etR0A  YjUWPpI6HXG530lwP-fb2A        3   \n",
       "3  _7bHUi9Uuf5__HHc_Q8guQ  kxX2SOes4o-D3ZQBkiMRfA        5   \n",
       "4  bcjbaE6dDog4jkNY91ncLQ  e4Vwtrqf-wpJfwesgvdgxQ        4   \n",
       "\n",
       "                                              review                 date  \\\n",
       "0  If you decide to eat here, just be aware it is...  2018-07-07 22:09:11   \n",
       "1  I've taken a lot of spin classes over the year...  2012-01-03 15:28:18   \n",
       "2  Family diner. Had the buffet. Eclectic assortm...  2014-02-05 20:30:30   \n",
       "3  Wow!  Yummy, different,  delicious.   Our favo...  2015-01-04 00:01:03   \n",
       "4  Cute interior and owner (?) gave us tour of up...  2017-01-14 20:54:15   \n",
       "\n",
       "                           name                   address          city state  \\\n",
       "0  Turning Point of North Wales       1460 Bethlehem Pike   North Wales    PA   \n",
       "1    Body Cycle Spinning Studio  1923 Chestnut St, 2nd Fl  Philadelphia    PA   \n",
       "2             Kettle Restaurant     748 W Starr Pass Blvd        Tucson    AZ   \n",
       "3                         Zaika            2481 Grant Ave  Philadelphia    PA   \n",
       "4                          Melt             2549 Banks St   New Orleans    LA   \n",
       "\n",
       "  postal_code   latitude   longitude  stars_y  review_count  is_open  \\\n",
       "0       19454  40.210196  -75.223639      3.0           169        1   \n",
       "1       19119  39.952103  -75.172753      5.0           144        0   \n",
       "2       85713  32.207233 -110.980864      3.5            47        1   \n",
       "3       19114  40.079848  -75.025080      4.0           181        1   \n",
       "4       70119  29.962102  -90.087958      4.0            32        0   \n",
       "\n",
       "                                          attributes  \\\n",
       "0  {'NoiseLevel': \"u'average'\", 'HasTV': 'False',...   \n",
       "1  {'BusinessAcceptsCreditCards': 'True', 'GoodFo...   \n",
       "2  {'RestaurantsReservations': 'True', 'BusinessP...   \n",
       "3  {'Caters': 'True', 'Ambience': \"{'romantic': F...   \n",
       "4  {'BusinessParking': \"{'garage': False, 'street...   \n",
       "\n",
       "                                          categories  \\\n",
       "0  Restaurants, Breakfast & Brunch, Food, Juice B...   \n",
       "1  Active Life, Cycling Classes, Trainers, Gyms, ...   \n",
       "2                    Restaurants, Breakfast & Brunch   \n",
       "3              Halal, Pakistani, Restaurants, Indian   \n",
       "4  Sandwiches, Beer, Wine & Spirits, Bars, Food, ...   \n",
       "\n",
       "                                               hours  \n",
       "0  {'Monday': '7:30-15:0', 'Tuesday': '7:30-15:0'...  \n",
       "1  {'Monday': '6:30-20:30', 'Tuesday': '6:30-20:3...  \n",
       "2                                                NaN  \n",
       "3  {'Tuesday': '11:0-21:0', 'Wednesday': '11:0-21...  \n",
       "4  {'Monday': '0:0-0:0', 'Friday': '11:0-17:0', '...  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previewing the data\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Na count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id              0\n",
       "business_id          0\n",
       "stars_x              0\n",
       "review               0\n",
       "date                 0\n",
       "name                 0\n",
       "address          84801\n",
       "city                 0\n",
       "state                0\n",
       "postal_code        972\n",
       "latitude             0\n",
       "longitude            0\n",
       "stars_y              0\n",
       "review_count         0\n",
       "is_open              0\n",
       "attributes      183723\n",
       "categories         689\n",
       "hours           398286\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifying missing records\n",
    "data_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>attributes</th>\n",
       "      <th>categories</th>\n",
       "      <th>hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>percentage</th>\n",
       "      <td>2.6283</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>5.6977</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            attributes  categories   hours\n",
       "percentage      2.6283      0.0099  5.6977"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifying missing records as percentages for specific features\n",
    "# Calculating percentages\n",
    "na_prcnt = data_df[['attributes','categories','hours']].isna().sum()/data_df.shape[0]*100\n",
    "\n",
    "# Converting to a DataFrame\n",
    "nas_df = pd.DataFrame(na_prcnt, columns=['percentage'])\n",
    "\n",
    "# Transposing values\n",
    "nas_df = nas_df.transpose()\n",
    "\n",
    "# Rounding values\n",
    "nas_df.round(4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Na Count Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Generating a bar plot of NA records\n",
    "sns.barplot(data = nas_df).set_title('NA percentage')\n",
    "\n",
    "# Saving the figure (commented out after initial save)\n",
    "plt.savefig('Images/NA_Percentage_Plot.png')\n",
    "\n",
    "# Displaying the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: Ultimately, we decided to drop all three columns.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping features with NA records:\n",
    "- **attributes**\n",
    "- **categories**\n",
    "- **hours**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping features\n",
    "data_df.drop(columns = ['attributes','categories','hours'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "user_id             0\n",
       "business_id         0\n",
       "stars_x             0\n",
       "review              0\n",
       "date                0\n",
       "name                0\n",
       "address         84801\n",
       "city                0\n",
       "state               0\n",
       "postal_code       972\n",
       "latitude            0\n",
       "longitude           0\n",
       "stars_y             0\n",
       "review_count        0\n",
       "is_open             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifying missing records\n",
    "data_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparing similar features\n",
    "\n",
    "Exploring the features `stars_x` and `stars_y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars_x</th>\n",
       "      <th>stars_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>4.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>3.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars_x  stars_y\n",
       "2        3      3.5\n",
       "3        5      4.0\n",
       "5        1      4.0\n",
       "6        5      4.5\n",
       "7        5      3.5"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previewing data with different values in both features\n",
    "data_df.loc[data_df['stars_x'] != data_df['stars_y']][['stars_x','stars_y']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars_x</th>\n",
       "      <th>stars_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6080</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6911</th>\n",
       "      <td>4</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6927</th>\n",
       "      <td>3</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13378</th>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       stars_x  stars_y\n",
       "0            3      3.0\n",
       "6080         2      3.0\n",
       "6911         4      3.0\n",
       "6927         3      3.0\n",
       "13378        2      3.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previewing values for the same business\n",
    "data_df.loc[data_df['business_id']=='XQfwVwDr-v0ZS3_CbbE5Xw'][['stars_x','stars_y']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.07"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the average value for `star_x` for the same business\n",
    "round(data_df.loc[data_df['business_id']=='XQfwVwDr-v0ZS3_CbbE5Xw']['stars_x'].mean(),2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`star_y` seems to represent a business' average rating."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming features\n",
    "- **stars_y** to **stars_avg**\n",
    "- **stars_x** to **stars**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming features\n",
    "data_df.rename(columns={'stars_y':'stars_avg','stars_x':'stars'},inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Declaring plots\n",
    "fig,ax = plt.subplots()\n",
    "\n",
    "# Plotting figure\n",
    "sns.countplot(data_df,\n",
    "             x='is_open',\n",
    "             hue = 'is_open',\n",
    "             ax = ax).set_title('`is_open` Feature Count')\n",
    "\n",
    "# Saving the figure (commented out after initial save)\n",
    "plt.savefig('Images/is_open_Feature_Count.png')\n",
    "\n",
    "# Displaying the figure\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping features:\n",
    "- **is_open**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping features\n",
    "data_df.drop(columns = ['is_open'],inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: We decided to drop this feature due low informational value and feature imbalance.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging with tips dataset\n",
    "\n",
    "Exploring to potential gain from merging the tips dataset, since it, too, contains customer recommendations to improve experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>recommendations</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AGNUgVwnZUey3gcPCJ76iw</td>\n",
       "      <td>3uLgwr0qeCNMjKenHJwPGQ</td>\n",
       "      <td>Avengers time with the ladies.</td>\n",
       "      <td>2012-05-18 02:17:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NBN4MgHP9D3cw--SnauTkA</td>\n",
       "      <td>QoezRbYQncpRqyrLH6Iqjg</td>\n",
       "      <td>They have lots of good deserts and tasty cuban...</td>\n",
       "      <td>2013-02-05 18:35:10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-copOvldyKh1qr-vzkDEvw</td>\n",
       "      <td>MYoRNLb5chwjQe3c_k37Gg</td>\n",
       "      <td>It's open even when you think it isn't</td>\n",
       "      <td>2013-08-18 00:56:08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FjMQVZjSqY8syIO-53KFKw</td>\n",
       "      <td>hV-bABTK-glh5wj31ps_Jw</td>\n",
       "      <td>Very decent fried chicken</td>\n",
       "      <td>2017-06-27 23:05:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ld0AperBXk1h6UbqmM80zw</td>\n",
       "      <td>_uN0OudeJ3Zl_tf6nxg5ww</td>\n",
       "      <td>Appetizers.. platter special for lunch</td>\n",
       "      <td>2012-10-06 19:43:09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id             business_id  \\\n",
       "0  AGNUgVwnZUey3gcPCJ76iw  3uLgwr0qeCNMjKenHJwPGQ   \n",
       "1  NBN4MgHP9D3cw--SnauTkA  QoezRbYQncpRqyrLH6Iqjg   \n",
       "2  -copOvldyKh1qr-vzkDEvw  MYoRNLb5chwjQe3c_k37Gg   \n",
       "3  FjMQVZjSqY8syIO-53KFKw  hV-bABTK-glh5wj31ps_Jw   \n",
       "4  ld0AperBXk1h6UbqmM80zw  _uN0OudeJ3Zl_tf6nxg5ww   \n",
       "\n",
       "                                     recommendations                 date  \n",
       "0                     Avengers time with the ladies.  2012-05-18 02:17:21  \n",
       "1  They have lots of good deserts and tasty cuban...  2013-02-05 18:35:10  \n",
       "2             It's open even when you think it isn't  2013-08-18 00:56:08  \n",
       "3                          Very decent fried chicken  2017-06-27 23:05:38  \n",
       "4             Appetizers.. platter special for lunch  2012-10-06 19:43:09  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previewing the data\n",
    "tips_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 908915 entries, 0 to 908914\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count   Dtype \n",
      "---  ------           --------------   ----- \n",
      " 0   user_id          908915 non-null  object\n",
      " 1   business_id      908915 non-null  object\n",
      " 2   recommendations  908901 non-null  object\n",
      " 3   date             908915 non-null  object\n",
      "dtypes: object(4)\n",
      "memory usage: 27.7+ MB\n"
     ]
    }
   ],
   "source": [
    "# Confirming additional data details\n",
    "tips_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106193"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Finding the quantity of unique values in `business_id` in `tips_df`\n",
    "display(tips_df['business_id'].unique().shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150346"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Finding the quantity of unique values in `business_id` in `data_df`\n",
    "data_df['business_id'].unique().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset of **business_id** in `data_df` not found in `tips_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>review</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars_avg</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>yFuE8SPF-d1GXJUWYgKtzg</td>\n",
       "      <td>X8lfGPagfLzfOsx0k08NRQ</td>\n",
       "      <td>5</td>\n",
       "      <td>Took my vehicle here for some work a few years...</td>\n",
       "      <td>2017-05-13 14:15:29</td>\n",
       "      <td>Landa Muffler &amp; Brake</td>\n",
       "      <td>816 E 4th St</td>\n",
       "      <td>Reno</td>\n",
       "      <td>NV</td>\n",
       "      <td>89512</td>\n",
       "      <td>39.531787</td>\n",
       "      <td>-119.802696</td>\n",
       "      <td>3.5</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>dKoIp8vsKFH4cbmGSYy2IQ</td>\n",
       "      <td>0ICfbEImE0gUZc4kSZ7QHg</td>\n",
       "      <td>5</td>\n",
       "      <td>Replaced 2 old 70s lennox with 2 new ones.  Th...</td>\n",
       "      <td>2013-11-14 04:58:09</td>\n",
       "      <td>Reliance The Furnace Company</td>\n",
       "      <td>8545 Coronet Road</td>\n",
       "      <td>Edmonton</td>\n",
       "      <td>AB</td>\n",
       "      <td>T6E 4N7</td>\n",
       "      <td>53.499624</td>\n",
       "      <td>-113.456746</td>\n",
       "      <td>2.5</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>IMd3NQbclta91pFKk3AJZg</td>\n",
       "      <td>qO9dNNIvNbCBd8ZgjxMxgQ</td>\n",
       "      <td>5</td>\n",
       "      <td>Farmhouse, rustic, chic.Helpful staff with gre...</td>\n",
       "      <td>2017-04-08 00:33:11</td>\n",
       "      <td>HOME Santa Barbara</td>\n",
       "      <td>14 Parker Way</td>\n",
       "      <td>Santa Barbara</td>\n",
       "      <td>CA</td>\n",
       "      <td>93101</td>\n",
       "      <td>34.414912</td>\n",
       "      <td>-119.694171</td>\n",
       "      <td>4.5</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>B6G4f3UX1Z5_CpyV1xXm8Q</td>\n",
       "      <td>AgbRp5NLsP1-J1fdg6Hdcw</td>\n",
       "      <td>5</td>\n",
       "      <td>Awesome little shop.  The owner really knows h...</td>\n",
       "      <td>2017-05-13 17:15:09</td>\n",
       "      <td>Hands On Bicycle</td>\n",
       "      <td>1453 Gulf To Bay Blvd</td>\n",
       "      <td>Clearwater</td>\n",
       "      <td>FL</td>\n",
       "      <td>33755</td>\n",
       "      <td>27.963000</td>\n",
       "      <td>-82.777749</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>XN1ms_EBRYMF5GYSjfUHDQ</td>\n",
       "      <td>rJzLJL33mFyrM_90kAQKuw</td>\n",
       "      <td>5</td>\n",
       "      <td>I'm so incredibly happy with our pictures! Ang...</td>\n",
       "      <td>2017-12-02 18:40:48</td>\n",
       "      <td>Angela Clifton Photography</td>\n",
       "      <td>18205 Atherstone Trl</td>\n",
       "      <td>Land O Lakes</td>\n",
       "      <td>FL</td>\n",
       "      <td>34638</td>\n",
       "      <td>28.208604</td>\n",
       "      <td>-82.516107</td>\n",
       "      <td>5.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   user_id             business_id  stars  \\\n",
       "33  yFuE8SPF-d1GXJUWYgKtzg  X8lfGPagfLzfOsx0k08NRQ      5   \n",
       "54  dKoIp8vsKFH4cbmGSYy2IQ  0ICfbEImE0gUZc4kSZ7QHg      5   \n",
       "56  IMd3NQbclta91pFKk3AJZg  qO9dNNIvNbCBd8ZgjxMxgQ      5   \n",
       "76  B6G4f3UX1Z5_CpyV1xXm8Q  AgbRp5NLsP1-J1fdg6Hdcw      5   \n",
       "86  XN1ms_EBRYMF5GYSjfUHDQ  rJzLJL33mFyrM_90kAQKuw      5   \n",
       "\n",
       "                                               review                 date  \\\n",
       "33  Took my vehicle here for some work a few years...  2017-05-13 14:15:29   \n",
       "54  Replaced 2 old 70s lennox with 2 new ones.  Th...  2013-11-14 04:58:09   \n",
       "56  Farmhouse, rustic, chic.Helpful staff with gre...  2017-04-08 00:33:11   \n",
       "76  Awesome little shop.  The owner really knows h...  2017-05-13 17:15:09   \n",
       "86  I'm so incredibly happy with our pictures! Ang...  2017-12-02 18:40:48   \n",
       "\n",
       "                            name                address           city state  \\\n",
       "33         Landa Muffler & Brake           816 E 4th St           Reno    NV   \n",
       "54  Reliance The Furnace Company      8545 Coronet Road       Edmonton    AB   \n",
       "56            HOME Santa Barbara          14 Parker Way  Santa Barbara    CA   \n",
       "76              Hands On Bicycle  1453 Gulf To Bay Blvd     Clearwater    FL   \n",
       "86    Angela Clifton Photography   18205 Atherstone Trl   Land O Lakes    FL   \n",
       "\n",
       "   postal_code   latitude   longitude  stars_avg  review_count  \n",
       "33       89512  39.531787 -119.802696        3.5            29  \n",
       "54     T6E 4N7  53.499624 -113.456746        2.5            27  \n",
       "56       93101  34.414912 -119.694171        4.5            13  \n",
       "76       33755  27.963000  -82.777749        5.0            13  \n",
       "86       34638  28.208604  -82.516107        5.0             9  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Declaring `no_tips_df` as a subset of data not found in `tips_df`\n",
    "no_tips_df = data_df[~data_df['business_id'].isin(tips_df['business_id'])]\n",
    "\n",
    "# Previewing the data\n",
    "no_tips_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantity of **business_id** in `data_df` not found in `tips_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of business_ids in tips_df not found in data_df: 44153\n"
     ]
    }
   ],
   "source": [
    "# Counting the unique `business_id`s in `no_tips_df`\n",
    "not_found = no_tips_df['business_id'].unique().shape[0]\n",
    "\n",
    "# Printing the result\n",
    "print(f'Number of business_ids in tips_df not found in data_df: {not_found}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>recommendations</th>\n",
       "      <th>date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [user_id, business_id, recommendations, date]\n",
       "Index: []"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Locating a speciting `business_id` in `tips_df`\n",
    "tips_df.loc[tips_df['business_id'] == no_tips_df['business_id'].iloc[33]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging `tips_df` and `data_df` as `test_df`\n",
    "test_df = pd.merge(tips_df,data_df,\n",
    "                   on = ['business_id','user_id'],\n",
    "                   how = 'inner')\n",
    "                         "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>business_id</th>\n",
       "      <th>recommendations</th>\n",
       "      <th>date_x</th>\n",
       "      <th>stars</th>\n",
       "      <th>review</th>\n",
       "      <th>date_y</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars_avg</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FjMQVZjSqY8syIO-53KFKw</td>\n",
       "      <td>hV-bABTK-glh5wj31ps_Jw</td>\n",
       "      <td>Very decent fried chicken</td>\n",
       "      <td>2017-06-27 23:05:38</td>\n",
       "      <td>2</td>\n",
       "      <td>Do not get the schezuan chicken. 1) it's not b...</td>\n",
       "      <td>2018-05-08 01:31:54</td>\n",
       "      <td>Wok Out Restaurant</td>\n",
       "      <td>1444 S Belcher Rd, Ste B</td>\n",
       "      <td>Clearwater</td>\n",
       "      <td>FL</td>\n",
       "      <td>33764</td>\n",
       "      <td>27.943694</td>\n",
       "      <td>-82.746285</td>\n",
       "      <td>3.5</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ld0AperBXk1h6UbqmM80zw</td>\n",
       "      <td>_uN0OudeJ3Zl_tf6nxg5ww</td>\n",
       "      <td>Appetizers.. platter special for lunch</td>\n",
       "      <td>2012-10-06 19:43:09</td>\n",
       "      <td>1</td>\n",
       "      <td>So sad.....the menu is the same, but the taste...</td>\n",
       "      <td>2015-09-26 21:28:21</td>\n",
       "      <td>Siam Cuisine</td>\n",
       "      <td>265 White Bridge Pike</td>\n",
       "      <td>Nashville</td>\n",
       "      <td>TN</td>\n",
       "      <td>37209</td>\n",
       "      <td>36.143308</td>\n",
       "      <td>-86.858303</td>\n",
       "      <td>4.0</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ld0AperBXk1h6UbqmM80zw</td>\n",
       "      <td>_uN0OudeJ3Zl_tf6nxg5ww</td>\n",
       "      <td>Appetizers.. platter special for lunch</td>\n",
       "      <td>2012-10-06 19:43:09</td>\n",
       "      <td>4</td>\n",
       "      <td>Yummie...best thai food in the west side of Na...</td>\n",
       "      <td>2013-11-16 13:28:55</td>\n",
       "      <td>Siam Cuisine</td>\n",
       "      <td>265 White Bridge Pike</td>\n",
       "      <td>Nashville</td>\n",
       "      <td>TN</td>\n",
       "      <td>37209</td>\n",
       "      <td>36.143308</td>\n",
       "      <td>-86.858303</td>\n",
       "      <td>4.0</td>\n",
       "      <td>153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>trf3Qcz8qvCDKXiTgjUcEg</td>\n",
       "      <td>7Rm9Ba50bw23KTA8RedZYg</td>\n",
       "      <td>Chili Cup + Single Cheeseburger with onion, pi...</td>\n",
       "      <td>2012-03-13 04:00:52</td>\n",
       "      <td>4</td>\n",
       "      <td>Bottom Line:  All your typical Steak n' Shake ...</td>\n",
       "      <td>2010-10-23 21:32:13</td>\n",
       "      <td>Steak ’n Shake</td>\n",
       "      <td>1300 Lemay Ferry Rd</td>\n",
       "      <td>St. Louis</td>\n",
       "      <td>MO</td>\n",
       "      <td>63125</td>\n",
       "      <td>38.531844</td>\n",
       "      <td>-90.288109</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SMGAlRjyfuYu-c-22zIyOg</td>\n",
       "      <td>kH-0iXqkL7b8UXNpguBMKg</td>\n",
       "      <td>Saturday, Dec 7th 2013, ride Patco's Silver Sl...</td>\n",
       "      <td>2013-12-03 23:42:15</td>\n",
       "      <td>4</td>\n",
       "      <td>Patco (sometimes referred to as the \"High Spee...</td>\n",
       "      <td>2013-12-02 13:24:17</td>\n",
       "      <td>PATCO</td>\n",
       "      <td>901 Berlin Rd N</td>\n",
       "      <td>Lindenwold</td>\n",
       "      <td>NJ</td>\n",
       "      <td>08021</td>\n",
       "      <td>39.834038</td>\n",
       "      <td>-75.000662</td>\n",
       "      <td>3.5</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  user_id             business_id  \\\n",
       "0  FjMQVZjSqY8syIO-53KFKw  hV-bABTK-glh5wj31ps_Jw   \n",
       "1  ld0AperBXk1h6UbqmM80zw  _uN0OudeJ3Zl_tf6nxg5ww   \n",
       "2  ld0AperBXk1h6UbqmM80zw  _uN0OudeJ3Zl_tf6nxg5ww   \n",
       "3  trf3Qcz8qvCDKXiTgjUcEg  7Rm9Ba50bw23KTA8RedZYg   \n",
       "4  SMGAlRjyfuYu-c-22zIyOg  kH-0iXqkL7b8UXNpguBMKg   \n",
       "\n",
       "                                     recommendations               date_x  \\\n",
       "0                          Very decent fried chicken  2017-06-27 23:05:38   \n",
       "1             Appetizers.. platter special for lunch  2012-10-06 19:43:09   \n",
       "2             Appetizers.. platter special for lunch  2012-10-06 19:43:09   \n",
       "3  Chili Cup + Single Cheeseburger with onion, pi...  2012-03-13 04:00:52   \n",
       "4  Saturday, Dec 7th 2013, ride Patco's Silver Sl...  2013-12-03 23:42:15   \n",
       "\n",
       "   stars                                             review  \\\n",
       "0      2  Do not get the schezuan chicken. 1) it's not b...   \n",
       "1      1  So sad.....the menu is the same, but the taste...   \n",
       "2      4  Yummie...best thai food in the west side of Na...   \n",
       "3      4  Bottom Line:  All your typical Steak n' Shake ...   \n",
       "4      4  Patco (sometimes referred to as the \"High Spee...   \n",
       "\n",
       "                date_y                name                   address  \\\n",
       "0  2018-05-08 01:31:54  Wok Out Restaurant  1444 S Belcher Rd, Ste B   \n",
       "1  2015-09-26 21:28:21        Siam Cuisine     265 White Bridge Pike   \n",
       "2  2013-11-16 13:28:55        Siam Cuisine     265 White Bridge Pike   \n",
       "3  2010-10-23 21:32:13      Steak ’n Shake       1300 Lemay Ferry Rd   \n",
       "4  2013-12-02 13:24:17               PATCO           901 Berlin Rd N   \n",
       "\n",
       "         city state postal_code   latitude  longitude  stars_avg  review_count  \n",
       "0  Clearwater    FL       33764  27.943694 -82.746285        3.5            59  \n",
       "1   Nashville    TN       37209  36.143308 -86.858303        4.0           153  \n",
       "2   Nashville    TN       37209  36.143308 -86.858303        4.0           153  \n",
       "3   St. Louis    MO       63125  38.531844 -90.288109        2.0            23  \n",
       "4  Lindenwold    NJ       08021  39.834038 -75.000662        3.5            74  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previewing the data\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 440640 entries, 0 to 440639\n",
      "Data columns (total 16 columns):\n",
      " #   Column           Non-Null Count   Dtype  \n",
      "---  ------           --------------   -----  \n",
      " 0   user_id          440640 non-null  object \n",
      " 1   business_id      440640 non-null  object \n",
      " 2   recommendations  440635 non-null  object \n",
      " 3   date_x           440640 non-null  object \n",
      " 4   stars            440640 non-null  int64  \n",
      " 5   review           440640 non-null  object \n",
      " 6   date_y           440640 non-null  object \n",
      " 7   name             440640 non-null  object \n",
      " 8   address          438455 non-null  object \n",
      " 9   city             440640 non-null  object \n",
      " 10  state            440640 non-null  object \n",
      " 11  postal_code      440556 non-null  object \n",
      " 12  latitude         440640 non-null  float64\n",
      " 13  longitude        440640 non-null  float64\n",
      " 14  stars_avg        440640 non-null  float64\n",
      " 15  review_count     440640 non-null  int64  \n",
      "dtypes: float64(3), int64(2), object(11)\n",
      "memory usage: 53.8+ MB\n"
     ]
    }
   ],
   "source": [
    "# Confirming additional data details\n",
    "test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison\n",
    "\n",
    "Comparing **review** agains **recommendations**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>recommendations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Do not get the schezuan chicken. 1) it's not b...</td>\n",
       "      <td>Very decent fried chicken</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>So sad.....the menu is the same, but the taste...</td>\n",
       "      <td>Appetizers.. platter special for lunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yummie...best thai food in the west side of Na...</td>\n",
       "      <td>Appetizers.. platter special for lunch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bottom Line:  All your typical Steak n' Shake ...</td>\n",
       "      <td>Chili Cup + Single Cheeseburger with onion, pi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Patco (sometimes referred to as the \"High Spee...</td>\n",
       "      <td>Saturday, Dec 7th 2013, ride Patco's Silver Sl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  \\\n",
       "0  Do not get the schezuan chicken. 1) it's not b...   \n",
       "1  So sad.....the menu is the same, but the taste...   \n",
       "2  Yummie...best thai food in the west side of Na...   \n",
       "3  Bottom Line:  All your typical Steak n' Shake ...   \n",
       "4  Patco (sometimes referred to as the \"High Spee...   \n",
       "\n",
       "                                     recommendations  \n",
       "0                          Very decent fried chicken  \n",
       "1             Appetizers.. platter special for lunch  \n",
       "2             Appetizers.. platter special for lunch  \n",
       "3  Chili Cup + Single Cheeseburger with onion, pi...  \n",
       "4  Saturday, Dec 7th 2013, ride Patco's Silver Sl...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previewing the data for the two selected features\n",
    "test_df[['review','recommendations']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: The* `data_df` *DataFrame has approximately* ***7 million*** *entries, and the* `tips_df` *DataFrame has about* ***1 million***. *After merging them we end up the a little under* ***500 thousand***. *The comparison above shows little difference between a* ***review*** *from the reviews dataset and a* ***recommendation*** *from the tips dataset. As shown above, we stand to loose a significant amount of data if a merge is performed, we we decided against it.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finalizing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping featires:\n",
    "- **user_id** *(to preserve user anonymity)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping features\n",
    "data_df.drop(columns = ['user_id'],inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>business_id</th>\n",
       "      <th>stars</th>\n",
       "      <th>review</th>\n",
       "      <th>date</th>\n",
       "      <th>name</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>stars_avg</th>\n",
       "      <th>review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XQfwVwDr-v0ZS3_CbbE5Xw</td>\n",
       "      <td>3</td>\n",
       "      <td>If you decide to eat here, just be aware it is...</td>\n",
       "      <td>2018-07-07 22:09:11</td>\n",
       "      <td>Turning Point of North Wales</td>\n",
       "      <td>1460 Bethlehem Pike</td>\n",
       "      <td>North Wales</td>\n",
       "      <td>PA</td>\n",
       "      <td>19454</td>\n",
       "      <td>40.210196</td>\n",
       "      <td>-75.223639</td>\n",
       "      <td>3.0</td>\n",
       "      <td>169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7ATYjTIgM3jUlt4UM3IypQ</td>\n",
       "      <td>5</td>\n",
       "      <td>I've taken a lot of spin classes over the year...</td>\n",
       "      <td>2012-01-03 15:28:18</td>\n",
       "      <td>Body Cycle Spinning Studio</td>\n",
       "      <td>1923 Chestnut St, 2nd Fl</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>19119</td>\n",
       "      <td>39.952103</td>\n",
       "      <td>-75.172753</td>\n",
       "      <td>5.0</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>YjUWPpI6HXG530lwP-fb2A</td>\n",
       "      <td>3</td>\n",
       "      <td>Family diner. Had the buffet. Eclectic assortm...</td>\n",
       "      <td>2014-02-05 20:30:30</td>\n",
       "      <td>Kettle Restaurant</td>\n",
       "      <td>748 W Starr Pass Blvd</td>\n",
       "      <td>Tucson</td>\n",
       "      <td>AZ</td>\n",
       "      <td>85713</td>\n",
       "      <td>32.207233</td>\n",
       "      <td>-110.980864</td>\n",
       "      <td>3.5</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kxX2SOes4o-D3ZQBkiMRfA</td>\n",
       "      <td>5</td>\n",
       "      <td>Wow!  Yummy, different,  delicious.   Our favo...</td>\n",
       "      <td>2015-01-04 00:01:03</td>\n",
       "      <td>Zaika</td>\n",
       "      <td>2481 Grant Ave</td>\n",
       "      <td>Philadelphia</td>\n",
       "      <td>PA</td>\n",
       "      <td>19114</td>\n",
       "      <td>40.079848</td>\n",
       "      <td>-75.025080</td>\n",
       "      <td>4.0</td>\n",
       "      <td>181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e4Vwtrqf-wpJfwesgvdgxQ</td>\n",
       "      <td>4</td>\n",
       "      <td>Cute interior and owner (?) gave us tour of up...</td>\n",
       "      <td>2017-01-14 20:54:15</td>\n",
       "      <td>Melt</td>\n",
       "      <td>2549 Banks St</td>\n",
       "      <td>New Orleans</td>\n",
       "      <td>LA</td>\n",
       "      <td>70119</td>\n",
       "      <td>29.962102</td>\n",
       "      <td>-90.087958</td>\n",
       "      <td>4.0</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              business_id  stars  \\\n",
       "0  XQfwVwDr-v0ZS3_CbbE5Xw      3   \n",
       "1  7ATYjTIgM3jUlt4UM3IypQ      5   \n",
       "2  YjUWPpI6HXG530lwP-fb2A      3   \n",
       "3  kxX2SOes4o-D3ZQBkiMRfA      5   \n",
       "4  e4Vwtrqf-wpJfwesgvdgxQ      4   \n",
       "\n",
       "                                              review                 date  \\\n",
       "0  If you decide to eat here, just be aware it is...  2018-07-07 22:09:11   \n",
       "1  I've taken a lot of spin classes over the year...  2012-01-03 15:28:18   \n",
       "2  Family diner. Had the buffet. Eclectic assortm...  2014-02-05 20:30:30   \n",
       "3  Wow!  Yummy, different,  delicious.   Our favo...  2015-01-04 00:01:03   \n",
       "4  Cute interior and owner (?) gave us tour of up...  2017-01-14 20:54:15   \n",
       "\n",
       "                           name                   address          city state  \\\n",
       "0  Turning Point of North Wales       1460 Bethlehem Pike   North Wales    PA   \n",
       "1    Body Cycle Spinning Studio  1923 Chestnut St, 2nd Fl  Philadelphia    PA   \n",
       "2             Kettle Restaurant     748 W Starr Pass Blvd        Tucson    AZ   \n",
       "3                         Zaika            2481 Grant Ave  Philadelphia    PA   \n",
       "4                          Melt             2549 Banks St   New Orleans    LA   \n",
       "\n",
       "  postal_code   latitude   longitude  stars_avg  review_count  \n",
       "0       19454  40.210196  -75.223639        3.0           169  \n",
       "1       19119  39.952103  -75.172753        5.0           144  \n",
       "2       85713  32.207233 -110.980864        3.5            47  \n",
       "3       19114  40.079848  -75.025080        4.0           181  \n",
       "4       70119  29.962102  -90.087958        4.0            32  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Previewing the data\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6990280 entries, 0 to 6990279\n",
      "Data columns (total 13 columns):\n",
      " #   Column        Dtype  \n",
      "---  ------        -----  \n",
      " 0   business_id   object \n",
      " 1   stars         int64  \n",
      " 2   review        object \n",
      " 3   date          object \n",
      " 4   name          object \n",
      " 5   address       object \n",
      " 6   city          object \n",
      " 7   state         object \n",
      " 8   postal_code   object \n",
      " 9   latitude      float64\n",
      " 10  longitude     float64\n",
      " 11  stars_avg     float64\n",
      " 12  review_count  int64  \n",
      "dtypes: float64(3), int64(2), object(8)\n",
      "memory usage: 693.3+ MB\n"
     ]
    }
   ],
   "source": [
    "# Confirming additional data details\n",
    "data_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Na count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id         0\n",
       "stars               0\n",
       "review              0\n",
       "date                0\n",
       "name                0\n",
       "address         84801\n",
       "city                0\n",
       "state               0\n",
       "postal_code       972\n",
       "latitude            0\n",
       "longitude           0\n",
       "stars_avg           0\n",
       "review_count        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifying missing records\n",
    "data_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizations\n",
    "\n",
    "Preparing some visualizations of the final dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ratings distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review counts per business"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business category distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions (Pt 1)\n",
    "\n",
    "The following user-defined functions will be used throughout the sampling, preproccing, an modeling of our data, each developed with their annotated purposes in mind:\n",
    "\n",
    "| **Function** | **Notes** |\n",
    "| :--- | :--- |\n",
    "| `sample_stars()` | Selects subsets of a DataFrame based on user rating value thresholds |\n",
    "| `remove_accented_chars()` | Removes accented characters from text |\n",
    "| `clean_text()` | Removes web formatting from text |\n",
    "| `pre_process_reviews()` | Removes stop words from text |\n",
    "| `tokenizer_function()` | Tokenizes text |\n",
    "| `compute_metrics()` | Computes metrics to assist with evaluating model performance |\n",
    "\n",
    "Functions outlined in more detail below require a DataFrame with the following features:\n",
    "\n",
    "| **Feature** | **Notes** |\n",
    "| :--- | :--- |\n",
    "| `rating` | An int or float column with submitted user review scores |\n",
    "| `rev_col` | A text column with available reviews |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to select various subsets of data\n",
    "def sample_stars(df, val):\n",
    "    '''\n",
    "    Samples a specific subset of a DataFrame based on the value of the 'stars' column.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): Any DataFrame with sufficient data.\n",
    "        val (int):      An integer representing the specific star rating to filter and sample from the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "        df (DataFrame): A subset of the input DataFrame filtered by the specified star rating.\n",
    "\n",
    "    Raises:\n",
    "        KeyError:       If 'stars' is not a valid column name in the DataFrame.\n",
    "        TypeError:      If `df` is not a DataFrame or if `val` is not an integer.\n",
    "        ValueError:     If `val` is not within the acceptable range (1 to 5).\n",
    "        ValueError:     If there are not enough records in the DataFrame to sample the requested amount.\n",
    "    '''\n",
    "    # Raises\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError('The input `df` must be a pandas DataFrame.')\n",
    "    if 'stars' not in df.columns:\n",
    "        raise KeyError(\"Column 'stars' not found in DataFrame.\")\n",
    "    if not isinstance(val, int):\n",
    "        raise TypeError('The `val` parameter must be passed as an integer.')\n",
    "    if val < 1 or val > 5:\n",
    "        raise ValueError('The `val` parameter must be an integer between 1 and 5.')\n",
    "    \n",
    "    # Filtering and sampling the DataFrame\n",
    "    df = df[df['stars'] == val].copy()\n",
    "\n",
    "    # Sampling the DataFrame based on specified star rating to balance end dataset\n",
    "    if val >= 4:\n",
    "        df = df.sample(1000)\n",
    "    elif val <= 2:\n",
    "        df = df.sample(1000)\n",
    "    else:\n",
    "        df = df.sample(2000)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Retuning the DataFrame\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove accented characters\n",
    "def remove_accented_chars(text):\n",
    "    '''\n",
    "    Removes accecnted characters.\n",
    "\n",
    "    Args:\n",
    "        text (str):     A corpus of text.\n",
    "\n",
    "    Returns:\n",
    "        text (str):     A processed corpus of text.\n",
    "    '''\n",
    "    # Removing accented characters\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "\n",
    "    # Returning `text`\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion to remove web formatting\n",
    "def clean_text(text):\n",
    "    '''\n",
    "    Removes Urls',mentions, hashtags, and multiple spaces from text.\n",
    "\n",
    "    Args:\n",
    "        text (str):     A corpus of text.\n",
    "    \n",
    "    Returns:\n",
    "        text (str):     A processed corpus of text.\n",
    "    '''\n",
    "    # Removing URLs\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "    # Removing mentions\n",
    "    text = re.sub(r\"@\\S+\", \"\", text)\n",
    "    # Removing hashtags\n",
    "    text = re.sub(r\"#\\S+\", \"\", text)\n",
    "    # Removing multiple spaces with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    # Retuning `text`\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Funtion to remove stop words from a corups\n",
    "def pre_process_reviews(reviews):\n",
    "    '''\n",
    "    Removes stop words from corpus.\n",
    "\n",
    "    Args:\n",
    "        reviews (str):      A corpus of text.\n",
    "    \n",
    "    Returns:\n",
    "        reviews (str):     A processed corpus of text.\n",
    "    '''\n",
    "    # Setting stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Declaring an empty list for processed reviews\n",
    "    norm_reviews = []\n",
    "\n",
    "    # Looping\n",
    "    for review in tqdm(reviews):\n",
    "        # Clean text\n",
    "        review = clean_text(review)\n",
    "        # remove extra newlines and convert them to spaces\n",
    "        review = review.translate(review.maketrans(\"\\n\\t\\r\", \"   \"))\n",
    "        # lower case\n",
    "        review = review.lower()\n",
    "        # remove accents\n",
    "        review = remove_accented_chars(review)\n",
    "        # remove special characters\n",
    "        review = re.sub(r'[^a-zA-Z0-9\\s]', '', review, flags=re.I|re.A)\n",
    "        # remove extra whitespaces\n",
    "        review = re.sub(' +', ' ', review)\n",
    "        # remove leading and training whitespaces\n",
    "        review = review.strip()\n",
    "\n",
    "        review_tokens = word_tokenize(review)\n",
    "        review = [w for w in review_tokens if not w in stop_words]\n",
    "        review = ' '.join(review)\n",
    "\n",
    "        # Appending to `norm_reviews`\n",
    "        norm_reviews.append(review)\n",
    "    \n",
    "    # Returning `norm_reviews`\n",
    "    return norm_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to tokenize a corpus\n",
    "def tokenizer_function(review):\n",
    "    '''\n",
    "    Tokenizes corpus\n",
    "    \n",
    "    Args:\n",
    "        reviews (str):              A corpus of text.\n",
    "    \n",
    "    Returns:\n",
    "        return_tensors (pythorch):  A tokenized corpus of text.\n",
    "    '''\n",
    "    # Extracting text\n",
    "    text = review['text']\n",
    "\n",
    "    # Tokenize text with truncation and padding\n",
    "    tokenized_inputs = tokenizer(\n",
    "        text,\n",
    "        # Truncate to max_length from the right by default\n",
    "        truncation=True,\n",
    "        # Pad to the maximum length\n",
    "        padding=\"max_length\",\n",
    "        # Maximum sequence length for BERT models\n",
    "        max_length=512,\n",
    "        # Assuming you are using PyTorch; change to 'np' if necessary\n",
    "        return_tensors='pt'\n",
    "    )\n",
    "\n",
    "    # Returning `tokenized_inputs`\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load multiple metrics\n",
    "accuracy_metric = load(\"accuracy\")\n",
    "precision_metric = load(\"precision\")\n",
    "recall_metric = load(\"recall\")\n",
    "f1_metric = load(\"f1\")\n",
    "\n",
    "# Function to compute the metrics of our model\n",
    "def compute_metrics(pred):\n",
    "    '''\n",
    "    Computes metrics to assist in evaluating model perfomance.\n",
    "\n",
    "    Args:\n",
    "        pred (tuple):   A series representing modeled predictions and a boolian indicator.\n",
    "    \n",
    "    Returns:\n",
    "        return (dict):  A dictionary containing model performance metrics.\n",
    "    \n",
    "    Raises:\n",
    "        TypeError:      If `pred` is not a tuple or if the elements of `pred` are not numpy arrays.\n",
    "        ValueError:     If the shape of the predictions does not match the shape of the labels.\n",
    "    '''\n",
    "    # Raises\n",
    "    if not isinstance(pred, tuple):\n",
    "        raise TypeError(\"The `pred` argument must be a tuple.\")\n",
    "    if not isinstance(pred[0], np.ndarray) or not isinstance(pred[1], np.ndarray):\n",
    "        raise TypeError(\"The elements of `pred` must be numpy arrays.\")\n",
    "    if pred[0].shape[0] != pred[1].shape[0]:\n",
    "        raise ValueError(\"The number of predictions must match the number of labels.\")\n",
    "    \n",
    "    # Unpacked tuple\n",
    "    predictions, labels = pred\n",
    "    predictions = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # Metrics\n",
    "    # Accuracy\n",
    "    accuracy = accuracy_metric.compute(predictions=predictions, references=labels)\n",
    "    # Precision\n",
    "    precision = precision_metric.compute(predictions=predictions, references=labels, average='weighted')\n",
    "    # Recall\n",
    "    recall = recall_metric.compute(predictions=predictions, references=labels, average='weighted')\n",
    "    # F1 score\n",
    "    f1 = f1_metric.compute(predictions=predictions, references=labels, average='weighted')\n",
    "\n",
    "    # Returning a dictionary containing all metrics\n",
    "    return {\n",
    "        \"accuracy\": accuracy[\"accuracy\"],\n",
    "        \"precision\": precision[\"precision\"],\n",
    "        \"recall\": recall[\"recall\"],\n",
    "        \"f1\": f1[\"f1\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Modeling**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing a subset of data\n",
    "\n",
    "Due to the imbalance of submitted user ratings, we decided to narrow our training data to reflect a balanced spread of \"positive\", \"neutral\", and \"negative\" reviews. To accomplish this, we selected an equal number of records with 5 or 4 star ratings, 3 star ratings, and 2 or 1 star ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring subsets of data\n",
    "sample_5 = sample_stars(data_df,5)\n",
    "sample_4 = sample_stars(data_df,4)\n",
    "sample_3 = sample_stars(data_df,3)\n",
    "sample_2 = sample_stars(data_df,2)\n",
    "sample_1 = sample_stars(data_df,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concatenating data samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6000, 13)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenating sample sets into a single DataFrame\n",
    "sample_data_df = pd.concat(\n",
    "    [\n",
    "        sample_1,\n",
    "        sample_2,\n",
    "        sample_3,\n",
    "        sample_4,\n",
    "        sample_5\n",
    "    ], axis=0, ignore_index=True\n",
    ")\n",
    "\n",
    "# Confirming total records in `sample_data_df`\n",
    "sample_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stars\n",
       "3    2000\n",
       "1    1000\n",
       "2    1000\n",
       "4    1000\n",
       "5    1000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirming appropriate quantities of each star values were pulled\n",
    "sample_data_df['stars'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual encoding\n",
    "\n",
    "Our goal was to break down reviews into \"positive\", \"neutral\", or \"negative\" sentiments. As such, we manually encoded the value of `stars` as follows;\n",
    "\n",
    "| **Stars** | **Label** | **Sentiment Meaning** |\n",
    "| :--- | :--- | :--- |\n",
    "| **5** | **2** | \"Positive\" |\n",
    "| **4** | **2** | \"Positive\" |\n",
    "| **3** | **1** | \"Neutral\" |\n",
    "| **2** | **0** | \"Negative\" |\n",
    "| **1** | **0** | \"Negative\" |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manually encoding `stars` value to create sentiment labels\n",
    "sample_data_df['stars']= sample_data_df['stars'].replace(to_replace=[1,2], value=0)\n",
    "sample_data_df['stars']= sample_data_df['stars'].replace(to_replace=3, value=1)\n",
    "sample_data_df['stars']= sample_data_df['stars'].replace(to_replace=[4,5], value=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stars\n",
       "0    2000\n",
       "1    2000\n",
       "2    2000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirming equal label class counts\n",
    "sample_data_df['stars'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Na count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "business_id      0\n",
       "stars            0\n",
       "review           0\n",
       "date             0\n",
       "name             0\n",
       "address         43\n",
       "city             0\n",
       "state            0\n",
       "postal_code      1\n",
       "latitude         0\n",
       "longitude        0\n",
       "stars_avg        0\n",
       "review_count     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifying missing records\n",
    "sample_data_df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Note: Since this dataset is for training the sentiment analysis model, only, NA values in fields other than* `stars` *and* `review` *are ultimately irrelevent to the model training. As such, no records were in need of being dropped.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming featires:\n",
    "- **review** to **text**\n",
    "- **stars** to **label**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming features\n",
    "sample_data_df.rename(columns={'review':'text','stars':'label'},inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Test Split\n",
    "\n",
    "Our sample set was prepared for training with `train_test_split()` set to a `random_state=` of **42**, because life, the universe, and everything."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring `X` as features\n",
    "X = sample_data_df['text']\n",
    "# Declaring `y` as target\n",
    "y = sample_data_df['label']\n",
    "\n",
    "# Splitting the data into training and testing sets with a `test_size` of 0.3\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size = 0.3,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the pipeline\n",
    "\n",
    "Our approach to sentiment analysis centered around utilizing a BERT-based Transormer. As such, steps were taken to establish, then tune the hyperparameters of, our pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "Once split, each dataset was passed through our established preprocessing functions to prepare for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4200/4200 [00:00<00:00, 4305.80it/s]\n",
      "100%|██████████| 1800/1800 [00:00<00:00, 4344.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing training reviews\n",
    "norm_train_reviews = pre_process_reviews(X_train)\n",
    "\n",
    "# Preprocessing testing reviews\n",
    "norm_test_reviews = pre_process_reviews(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Formatting training target data as a Dataset\n",
    "train_dataset = Dataset.from_dict({'label':y_train.to_list(),'text':norm_train_reviews})\n",
    "# Formatting testing target data as a Dataset\n",
    "test_dataset = Dataset.from_dict({'label':y_test.to_list(),'text':norm_test_reviews})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating the model\n",
    "\n",
    "Each step below brought us one step closer to building our model, now lovingly referred to as `roberto`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building the model\n",
    "\n",
    "Here we set `roberto`'s initial definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.bias', 'pre_classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#Pretrained model\n",
    "model_checkpoint = 'distilbert-base-uncased'\n",
    "\n",
    "#Defining label classes\n",
    "id_to_label = {0:'Negative', 1:'Neutral', 2:'Positive'}\n",
    "label_to_id = {'Negative':0, 'Neutral': 1,'Positive':2}\n",
    "\n",
    "#Model definiftion\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels = 3,\n",
    "    id2label = id_to_label,\n",
    "    label2id =label_to_id \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tokenizing\n",
    "\n",
    "And here we prepared the necessary steps for `roberto`'s tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eab701209aec4db0b4e46f56c91f9a61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "95a2902d87c94ae99c253845387f801c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/4200 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Model tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(model_checkpoint)\n",
    "#Padding token\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
    "    model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "## Mapping Preprocessed data set to tokinezed data\n",
    "tokenized_train_dataset = train_dataset.map(tokenizer_function, batched=True)\n",
    "tokenized_test_dataset = train_dataset.map(tokenizer_function, batched=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Collator\n",
    "\n",
    "`roberto` needed a collator, too."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dynamic padding\n",
    "data_collator = DataCollatorWithPadding(tokenizer = tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training arguments\n",
    "\n",
    "While not argumentative by nature, `roberto` needed controllable hyperparameters to tune through the training process. Here we did that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\joblu\\anaconda3\\envs\\ai_dev\\lib\\site-packages\\transformers\\training_args.py:1525: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "##Trainig arguments hypter-parameters,which will be used to train the model\n",
    "\n",
    "#Output directory\n",
    "output_dir = 'model_sentiment'\n",
    "#Learning Rate\n",
    "lr = 2e-5\n",
    "#Batch size\n",
    "batch_size = 32\n",
    "#Epochs\n",
    "EPOCHS = 3\n",
    "\n",
    "#Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = output_dir,\n",
    "    learning_rate = lr,\n",
    "    per_device_train_batch_size = batch_size,\n",
    "    per_device_eval_batch_size = batch_size*2,\n",
    "    num_train_epochs = EPOCHS,\n",
    "    weight_decay = 0.01,\n",
    "    save_strategy = 'epoch',\n",
    "    evaluation_strategy = 'epoch',\n",
    "    logging_steps = 10,\n",
    "    load_best_model_at_end = True,\n",
    "    # Enable mixed precision\n",
    "    fp16=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trainer\n",
    "\n",
    "As we were trained to do, we etablished a proper trainer for `roberto` below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Trainer instatiation\n",
    "trainer = Trainer(\n",
    "                  model = model,\n",
    "                  args = training_args,\n",
    "                  train_dataset = tokenized_train_dataset,\n",
    "                  eval_dataset = tokenized_test_dataset,\n",
    "                  tokenizer = tokenizer,\n",
    "                  compute_metrics = compute_metrics,\n",
    "                  data_collator = data_collator\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training\n",
    "\n",
    "It all came down to this. `roberto`'s moment t make us proud!\n",
    "\n",
    "*Note: We commented this next cell out seeing as it took six (6) hours to train* `roebrto`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tuning the model with sample set of balanced data\n",
    "# (commented out to prevent re-training)\n",
    "\n",
    "# trained_model_results = trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`roberto`... did not make us proud at first...\n",
    "\n",
    "#### Training and Hypertuning;\n",
    "\n",
    "Here are the initial and final accuracy values during `roberto`'s development;\\\n",
    "Initial fine-tuning of pretrained model yielded accuracy values of ~40-50%.\\\n",
    "Final yielded accruacy values are around ~81%.\n",
    "\n",
    "Steps taken to improve accuracy (in something close to resembling order of application);\n",
    "* Changed pre-trained model from `distilbert-base-uncased` to `MarieAngeA13/Sentiment-Analysis-BERT`\n",
    "* Adjusted sample sizes of data <br> (from ~100 records total to a balanced sample set of 1000 with equal representation for all ratings) <br> (it would be another iteration before that sample set would be a balanced represntaion of the *labels*, though)\n",
    "* Updates to text cleaning to include more web-present syntax <br> (eg; mentions, multiple spaces, hashtags, and web address elements) <br> (because reviews aren't literary works, typically)\n",
    "* Adjustted syntax and arguments of tokenizer function and the application of it\n",
    "* Adjusted training arguments to better align with our BERT-based model <br> (*spoiler: this gets undone pretty soon after*)\n",
    "* Added additional metrics for better understanding of neccessary optimization\n",
    "* Increased sample data size, again, and removed subset step entirely <br> (started at 10,000 only to then decrease that sample size to 600 because of time, but it was still a larger sample than where it started)\n",
    "* Adjusted batch size and epochs <br> (twice)\n",
    "* Moved back to `distilbert-base-uncased` and adjusted learning tokenizers, learning rate, logging steps, and such hyperparameters accordingly <br> (because sometimes less Bert is better Bert)\n",
    "* Bargained with Eldritch beings in the hopes of a single soul buying even just a 10% boost to accuracy <br> (which is to say the sample size was changed to 3,000) <br> (also added and evaluation step to get a better idea of performance)\n",
    "* Exchanged soul because the deal was pretty tempting <br> (3,000 records had an accuracy of ~78%, so set the model to train overnight with 6,000 records in the hopes of an above 80% result)\n",
    "\n",
    "In the end, though? Yeah. `roberto` made us ***VERY*** proud!\n",
    "\n",
    "Copied output from final evaluation;\n",
    "\n",
    "> {'eval_loss': 0.4815390408039093, 'eval_accuracy': 0.8169047619047619, 'eval_precision': 0.8175331785953032, 'eval_recall': 0.8169047619047619, 'eval_f1': 0.8171466024398222, 'eval_runtime': 1743.5234, 'eval_samples_per_second': 2.409, 'eval_steps_per_second': 0.038, 'epoch': 3.0}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluation\n",
    "\n",
    "How we tested `roberto`'s performance. Don't worry, we saved the best results just above here.\n",
    "\n",
    "*Note: We commented this out because there are no model metrics to review if the training cell is not run.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model (commented out due to trainer already being trained)\n",
    "# evaluation_metrics = trainer.evaluate()\n",
    "\n",
    "# Print the final score (commented out due to trainer already being trained)\n",
    "# print(evaluation_metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving Model & Tokenizer\n",
    "\n",
    "Once we had an adequately trained `roberto`, we saved out model off for later fetching.\n",
    "\n",
    "*Note: We commented this out because there is no model to save if the training cell is not run.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the model and toekenizer\n",
    "# (commented out to prevent overwriting, # fetching handled through `gdown` and `zipfile`)\n",
    "# trainer.save_model(model_path)\n",
    "\n",
    "# tokenizer.save_pretrained(tokenizer_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetching and unzipping model\n",
    "\n",
    "So... Long story short, training a model on six-thousand (**6,000**) records makes for a sizable directory. Much as we circumnavicated Git's file size push restrictions with the datasets, we utlized `gdown` to fetch our model from being stored on Google Drive.\n",
    "\n",
    "*Note: The cell below is only necessary to be run during this notebook's first execution. It may be commented out for any subsequent execution.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From (original): https://drive.google.com/uc?id=1tzYRkjv3wWpfg21pJ02SEYNXEcj-TVH3\n",
      "From (redirected): https://drive.google.com/uc?id=1tzYRkjv3wWpfg21pJ02SEYNXEcj-TVH3&confirm=t&uuid=02b25855-bfc5-496e-9eb0-9294c359f7ca\n",
      "To: c:\\Users\\joblu\\Documents\\Columbia\\Activities\\Assignments\\Module 23-24 Group Project\\AI_Project_3_Group_01\\Resources\\Sentiment_Analysis.zip\n",
      "100%|██████████| 247M/247M [00:05<00:00, 42.9MB/s] \n"
     ]
    }
   ],
   "source": [
    "# Fetching model through `gdown`\n",
    "url = 'https://drive.google.com/file/d/1tzYRkjv3wWpfg21pJ02SEYNXEcj-TVH3/view?usp=sharing'\n",
    "output = 'Resources/Sentiment_Analysis.zip'\n",
    "# Download model\n",
    "gdown.download(url, output, fuzzy=True, quiet=False)\n",
    "\n",
    "# Extracting model\n",
    "with zipfile.ZipFile(output, 'r') as zip_ref:\n",
    "    zip_ref.extractall('./Sentiment_Analysis')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Paths\n",
    "\n",
    "Once saved or fetched, pathing to `roberto` is necessary for later use. Here we set our paths.\n",
    "\n",
    "*Note: If you unzip a file, it puts itself in a folder named for its zip, so... Yeah, the redundant filepath is a byproduct of default zip behavior.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declaring the model path\n",
    "model_path = 'Sentiment_Analysis/Sentiment_Analysis/model'\n",
    "\n",
    "# Declaring the tokenizer path\n",
    "tokenizer_path =  'Sentiment_Analysis/Sentiment_Analysis/tokenizer'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The end result\n",
    "\n",
    "Finally complete, `roberto` comes together with all the necessary pieces of its pipeline in place. **Behold!** `roberto`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading Model\n",
    "model = DistilBertForSequenceClassification.from_pretrained(model_path)\n",
    "#Loading Tokenizer\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(tokenizer_path)\n",
    "\n",
    "# Because of his dedication, our exhaustion which led us (Vanessa) to mispronunciate his name him honor of our TA Alberto Aigner \n",
    "# we have named our Pipeline 'roberto'\n",
    "roberto = pipeline('sentiment-analysis',model=model,tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions (Pt 2)\n",
    "\n",
    "While trained on Yelp! data, and developed for Google Reviews, the goal of the application is to be as univerally applicable to business reviews as possible - regardless of the source. The following functions were developed with their annotated purposes in mind:\n",
    "\n",
    "| **Function** | **Notes** |\n",
    "| :--- | :---|\n",
    "| `apply_roberto()` | Generates sentiment analysis for reviews in a given dataset, and a confidence in that sentiment |\n",
    "| `business_names_list()` | Generates a list of unique business names from a given dataset |\n",
    "| `reviews_list()` | Generates a list of all reviews submitted to a business for all its locations |\n",
    "| `general_sentiment()` | Classifies the general sentiment for a business' reviews and provides a mean confidence in that sentiment <br> *Note: To be run after a DataFrame has been passed through* `apply_roberto()` |\n",
    "\n",
    "Functions outlined in more detail below require a DataFrame with the following features:\n",
    "\n",
    "| **Feature** | **Notes** |\n",
    "| :--- | :--- |\n",
    "| `bus_name_col` | A text column with the name of a business |\n",
    "| `bus_add` | A text column with the street address of a business' location |\n",
    "| `rev_col` | A text column with available reviews |\n",
    "| `sent_lbl` | A text column with the generated sentiment classification <br> *Note: Generated through* `apply_roberto()` |\n",
    "| `sent_scr` | A text column with the generated sentiment classification <br> *Note: Generated through* `apply_roberto()` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply `roberto` to any DF\n",
    "def apply_roberto(df,rev_col):\n",
    "    '''\n",
    "    Applies the `roberto` model to generate sentiment analysis for the reviews in a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame):     Any DataFrame with sufficient data.\n",
    "        rev_col (str):      A string with the feature name that contains the review text.\n",
    "    \n",
    "    Returns:\n",
    "        df (DataFrame):     The same DataFrame with the appended sentiments and confidence scores.\n",
    "    \n",
    "    Raises:\n",
    "        KeyError:  If `rev_col` is not a valid column name in the DataFrame.\n",
    "        TypeError: If `df` is not a DataFrame or if `review_col` is not a string.\n",
    "    '''\n",
    "    #Raises\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError('The input `df` must be a pandas DataFrame.')\n",
    "    if not isinstance(rev_col, str):\n",
    "        raise TypeError('The `rev_col` parameter must be passed as a string.')\n",
    "    if rev_col not in df.columns:\n",
    "        raise KeyError(f\"Column '{rev_col}' not found in DataFrame.\")\n",
    "    \n",
    "    # Initializing features for results\n",
    "    df['sent_label'] = ''\n",
    "    df['sent_score'] = 0.0\n",
    "\n",
    "    # Iterating through `df`\n",
    "    for index,row in df.iterrows():\n",
    "        # Setting review text as `text`\n",
    "        text = row[rev_col]\n",
    "        # Generating results for a given review\n",
    "        result = roberto(text, truncation=True)[0]\n",
    "        # Appending the sentiment label\n",
    "        df.at[index, 'sent_label'] = result['label']\n",
    "        #Appending the sentiment score\n",
    "        df.at[index, 'sent_score'] = result['score']\n",
    "    \n",
    "    # Returning `df`\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve unique business names\n",
    "def business_names_list(df, bus_name_col):\n",
    "    '''\n",
    "    Places unique names from a list of businesses into a list.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame):     Any DataFrame with sufficient data.\n",
    "        bus_name_col (str): A string with the feature name that contains the business name.\n",
    "\n",
    "    Returns:\n",
    "        names (list):       A list of strings with only unique values.\n",
    "\n",
    "    Raises:\n",
    "        KeyError:           If `bus_name` is not a valid column name in the DataFrame.\n",
    "        TypeError:          If `df` is not a DataFrame or if `bus_name` is not a string.\n",
    "    '''\n",
    "    # Raises\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError('The input `df` must be a pandas DataFrame.')\n",
    "    if not isinstance(bus_name_col, str):\n",
    "        raise TypeError('The `bus_name` parameter must be passed as a string.')\n",
    "    if bus_name_col not in df.columns:\n",
    "        raise KeyError(f\"Column '{bus_name_col}' not found in DataFrame.\")\n",
    "\n",
    "    # Generating a list of business names\n",
    "    names = df[bus_name_col].unique().tolist()\n",
    "    \n",
    "    # Returning the list\n",
    "    return names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve all reviews\n",
    "def reviews_list(df, bus_name_col, bus_name, bus_add, rev_col):\n",
    "    '''\n",
    "    Places all reviews for a given business into a list, attributing each review to its specific location.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame):     Any DataFrame with sufficient data.\n",
    "        bus_name_col (str): A string with the feature name that contains the business name.\n",
    "        bus_name (str):     A string of a specific business' name for which to map the locations.\n",
    "        bus_add (str):      A string with the feature name that contains the business street address.\n",
    "        rev_col (str):      A string with the feature name that contains the review text.\n",
    "\n",
    "    Returns:\n",
    "        reviews (list):     A list of strings with all the reviews for a given business.\n",
    "\n",
    "    Raises:\n",
    "        KeyError:           If any passed str is not a valid column name in the DataFrame, or if `bus_name` is not a value in `bus_name_col`.\n",
    "        TypeError:          If `df` is not a DataFrame  if and feature is not a string, or if `bus_name` is not a string.\n",
    "    '''\n",
    "    # Raises\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError('The input `df` must be a pandas DataFrame.')\n",
    "    for param, name in zip(\n",
    "        [bus_name_col, bus_add, rev_col],\n",
    "        ['bus_name_col', 'bus_add', 'rev_col']\n",
    "    ):\n",
    "        if not isinstance(param, str):\n",
    "            raise TypeError(f\"The '{name}' parameter must be passed as a string.\")\n",
    "        if param not in df.columns:\n",
    "            raise KeyError(f\"Column '{param}' not found in DataFrame.\")\n",
    "    if not isinstance(bus_name, str):\n",
    "        raise TypeError('The `bus_name` parameter must be passed as a string.')\n",
    "    if bus_name not in df[bus_name_col].values:\n",
    "        raise KeyError(f\"Value '{bus_name}' not found in column '{bus_name_col}'.\")\n",
    "    \n",
    "    # Filtering `df`\n",
    "    filtered_df = df[[bus_add, rev_col]][df[bus_name_col] == bus_name].copy()\n",
    "\n",
    "    # Handling missing or empty reviews\n",
    "    filtered_df[rev_col] = filtered_df[rev_col].fillna('No review provided.')\n",
    "\n",
    "    # Creating a list of all reviews\n",
    "    reviews = filtered_df[bus_add] + ':\\n' + filtered_df[rev_col] + '\\n\\n'\n",
    "\n",
    "    # Converting to a list\n",
    "    reviews = reviews.to_list()\n",
    "\n",
    "    # Returning reviews\n",
    "    return reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generalize the overall sentiment\n",
    "def general_sentiment(df, bus_name_col, bus_name, sent_lbl, sent_scr):\n",
    "    '''\n",
    "    Compares the total positive, negative, and neutral reviews to classify an overall sentiment.\n",
    "\n",
    "    Note:\n",
    "        To be run after passing a DataFrame through `apply_roberto()`.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame):     Any DataFrame with sufficient data.\n",
    "        bus_name_col (str): A string with the feature name that contains the business name.\n",
    "        bus_name (str):     A string of a specific business' name for which to map the locations.\n",
    "        sent_lbl (str):     A string with the feature name that contains the modeled sentiment label.\n",
    "        sent_scr (str):     A string with the feature name that contains the modeled sentiment confidence.\n",
    "\n",
    "    Returns:\n",
    "        gen_sent (str):     A string with the overall sentiment, and the model's mean confidence in that classification.\n",
    "    \n",
    "    Raises:\n",
    "        KeyError:           If any passed str is not a valid column name in the DataFrame, or if `bus_name` is not a value in `bus_name_col`.\n",
    "        TypeError:          If `df` is not a DataFrame  if and feature is not a string, or if `bus_name` is not a string.\n",
    "    '''\n",
    "    # Raises\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError('The input `df` must be a pandas DataFrame.')\n",
    "    for param, name in zip(\n",
    "        [bus_name_col, sent_lbl, sent_scr],\n",
    "        ['bus_name_col', 'sent_lbl', 'sent_scr']\n",
    "    ):\n",
    "        if not isinstance(param, str):\n",
    "            raise TypeError(f\"The '{name}' parameter must be passed as a string.\")\n",
    "        if param not in df.columns:\n",
    "            raise KeyError(f\"Column '{param}' not found in DataFrame.\")\n",
    "    if not isinstance(bus_name, str):\n",
    "        raise TypeError('The `bus_name` parameter must be passed as a string.')\n",
    "    if bus_name not in df[bus_name_col].values:\n",
    "        raise KeyError(f\"Value '{bus_name}' not found in column '{bus_name_col}'.\")\n",
    "    \n",
    "    # Filtering `df`\n",
    "    filtered_df = df[[sent_lbl, sent_scr]][df[bus_name_col] == bus_name].copy()\n",
    "\n",
    "    # Converting `sentiment` to lower case\n",
    "    filtered_df[sent_lbl] = filtered_df[sent_lbl].str.lower()\n",
    "\n",
    "    # Calculating total `positive` sentiment\n",
    "    pos = filtered_df.loc[filtered_df[sent_lbl] == 'positive'].shape[0]\n",
    "    # Calculating total `neutral` sentiment\n",
    "    ntrl = filtered_df.loc[filtered_df[sent_lbl] == 'neutral'].shape[0]\n",
    "    # Calculating total `negative` sentiment\n",
    "    neg = filtered_df.loc[filtered_df[sent_lbl] == 'negative'].shape[0]\n",
    "\n",
    "    # Match case to generate general sentiment\n",
    "    match (pos, ntrl, neg):\n",
    "        case (p, n, ng) if p > n > ng:\n",
    "            sent = 'highly positive'\n",
    "        case (p, n, ng) if p > n + ng:\n",
    "            sent = 'strongly positive'\n",
    "        case (p, n, ng) if p + n > ng:\n",
    "            sent = 'moderately positive'\n",
    "        case (p, n, ng) if p < n > ng:\n",
    "            sent = 'generally neutral'\n",
    "        case (p, n, ng) if p < n < ng:\n",
    "            sent = 'moderately negative'\n",
    "        case (p, n, ng) if p + n < ng:\n",
    "            sent = 'strongly negative'\n",
    "        case (p, n, ng) if ng > n > p:\n",
    "            sent = 'highly negative'\n",
    "        case (p, n, ng) if p == n == ng:\n",
    "            sent = 'perfectly neutral'\n",
    "        case _:\n",
    "            sent = 'undetermined'\n",
    "    \n",
    "    # Calculate the mean confidence\n",
    "    conf = filtered_df[sent_scr].mean() * 100\n",
    "\n",
    "    # Generating the final sentiment\n",
    "    if pos + ntrl + neg != 0:\n",
    "        # Concatenating sentiment and confidence\n",
    "        gen_sent = f'The general sentiment is {sent}, with an average confidence of {conf:.1f}%.'\n",
    "    else:\n",
    "        # When no sentment available due to no reviews\n",
    "        gen_sent = 'Cannot confirm sentiment due to a lack of reviews.'\n",
    "\n",
    "    # Returning sentiment\n",
    "    return gen_sent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping\n",
    "\n",
    "Angelica, I'm leaving this and the bottom on you for refactoring... I'm so sorry. I trust you with your code more than me."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>bus_id</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>bus_add</th>\n",
       "      <th>bus_city</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The cakes are beautiful and delicious, but you...</td>\n",
       "      <td>5</td>\n",
       "      <td>Dulce De Leche Bakery</td>\n",
       "      <td>4.7</td>\n",
       "      <td>376 Central Ave</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>40.7476428</td>\n",
       "      <td>-74.0527625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The entire experience was excellent: well-brew...</td>\n",
       "      <td>5</td>\n",
       "      <td>Dulce De Leche Bakery</td>\n",
       "      <td>4.7</td>\n",
       "      <td>376 Central Ave</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>40.7476428</td>\n",
       "      <td>-74.0527625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Everything was great.\\n\\nFood, service, and th...</td>\n",
       "      <td>5</td>\n",
       "      <td>Dulce De Leche Bakery</td>\n",
       "      <td>4.7</td>\n",
       "      <td>376 Central Ave</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>40.7476428</td>\n",
       "      <td>-74.0527625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The soup is amazing. My family likes the Itali...</td>\n",
       "      <td>5</td>\n",
       "      <td>Dulce De Leche Bakery</td>\n",
       "      <td>4.7</td>\n",
       "      <td>376 Central Ave</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>40.7476428</td>\n",
       "      <td>-74.0527625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Absolutely love Dulce de Leche Bakery in Jerse...</td>\n",
       "      <td>5</td>\n",
       "      <td>Dulce De Leche Bakery</td>\n",
       "      <td>4.7</td>\n",
       "      <td>376 Central Ave</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>40.7476428</td>\n",
       "      <td>-74.0527625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>Absolutely amazing. We ordered  from their \"fa...</td>\n",
       "      <td>5</td>\n",
       "      <td>Texas Roadhouse</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2105 NJ-35 Suite 103</td>\n",
       "      <td>Holmdel</td>\n",
       "      <td>40.412299</td>\n",
       "      <td>-74.145973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>This place’s onion rings are my comfort food (...</td>\n",
       "      <td>5</td>\n",
       "      <td>Texas Roadhouse</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2105 NJ-35 Suite 103</td>\n",
       "      <td>Holmdel</td>\n",
       "      <td>40.412299</td>\n",
       "      <td>-74.145973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>Very good chain restaurant the food is always ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Texas Roadhouse</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2105 NJ-35 Suite 103</td>\n",
       "      <td>Holmdel</td>\n",
       "      <td>40.412299</td>\n",
       "      <td>-74.145973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>Loaded sweet potato and the rolls are the best...</td>\n",
       "      <td>5</td>\n",
       "      <td>Texas Roadhouse</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2105 NJ-35 Suite 103</td>\n",
       "      <td>Holmdel</td>\n",
       "      <td>40.412299</td>\n",
       "      <td>-74.145973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>Had the bone in ribeye with onion and mushroom...</td>\n",
       "      <td>5</td>\n",
       "      <td>Texas Roadhouse</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2105 NJ-35 Suite 103</td>\n",
       "      <td>Holmdel</td>\n",
       "      <td>40.412299</td>\n",
       "      <td>-74.145973</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>550 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review rating  \\\n",
       "0    The cakes are beautiful and delicious, but you...      5   \n",
       "1    The entire experience was excellent: well-brew...      5   \n",
       "2    Everything was great.\\n\\nFood, service, and th...      5   \n",
       "3    The soup is amazing. My family likes the Itali...      5   \n",
       "4    Absolutely love Dulce de Leche Bakery in Jerse...      5   \n",
       "..                                                 ...    ...   \n",
       "545  Absolutely amazing. We ordered  from their \"fa...      5   \n",
       "546  This place’s onion rings are my comfort food (...      5   \n",
       "547  Very good chain restaurant the food is always ...      4   \n",
       "548  Loaded sweet potato and the rolls are the best...      5   \n",
       "549  Had the bone in ribeye with onion and mushroom...      5   \n",
       "\n",
       "                    bus_id avg_rating               bus_add      bus_city  \\\n",
       "0    Dulce De Leche Bakery        4.7       376 Central Ave   Jersey City   \n",
       "1    Dulce De Leche Bakery        4.7       376 Central Ave   Jersey City   \n",
       "2    Dulce De Leche Bakery        4.7       376 Central Ave   Jersey City   \n",
       "3    Dulce De Leche Bakery        4.7       376 Central Ave   Jersey City   \n",
       "4    Dulce De Leche Bakery        4.7       376 Central Ave   Jersey City   \n",
       "..                     ...        ...                   ...           ...   \n",
       "545        Texas Roadhouse        4.4  2105 NJ-35 Suite 103       Holmdel   \n",
       "546        Texas Roadhouse        4.4  2105 NJ-35 Suite 103       Holmdel   \n",
       "547        Texas Roadhouse        4.4  2105 NJ-35 Suite 103       Holmdel   \n",
       "548        Texas Roadhouse        4.4  2105 NJ-35 Suite 103       Holmdel   \n",
       "549        Texas Roadhouse        4.4  2105 NJ-35 Suite 103       Holmdel   \n",
       "\n",
       "            lat          lon  \n",
       "0    40.7476428  -74.0527625  \n",
       "1    40.7476428  -74.0527625  \n",
       "2    40.7476428  -74.0527625  \n",
       "3    40.7476428  -74.0527625  \n",
       "4    40.7476428  -74.0527625  \n",
       "..          ...          ...  \n",
       "545   40.412299   -74.145973  \n",
       "546   40.412299   -74.145973  \n",
       "547   40.412299   -74.145973  \n",
       "548   40.412299   -74.145973  \n",
       "549   40.412299   -74.145973  \n",
       "\n",
       "[550 rows x 8 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define a function to create df with the business name, avg rating and address of each location\n",
    "def business_Overview(business_name,avg_rating,address1,lat,long,df):\n",
    "    df['bus_id'] = business_name\n",
    "    df['avg_rating'] = avg_rating\n",
    "    address_list = address1.split(',')\n",
    "    df['bus_add'] = address_list[0]\n",
    "    df['bus_city'] = address_list[1]\n",
    "    df['lat'] = lat\n",
    "    df['lon'] = long\n",
    "    return df\n",
    "\n",
    "# import business df with Google Maps url for web scrapping\n",
    "url_df = pd.read_csv('Resources/business_urls.csv')\n",
    "\n",
    "# pass the first 11 businesses from the business_urls file\n",
    "url_df = url_df.head(11)\n",
    "\n",
    "# create list of urls and lat/long for web scrapping step \n",
    "url = url_df['url'].tolist()\n",
    "lat = url_df['lat'].astype(str).tolist()\n",
    "long = url_df['long'].astype(str).tolist()\n",
    "\n",
    "# initiate driver\n",
    "driver = webdriver.Chrome(service = ChromeService(ChromeDriverManager().install()))\n",
    "\n",
    "#create for loop to parse through the different locations in the url list above\n",
    "c = 0\n",
    "df_list = []\n",
    "\n",
    "for i in range(0,len(url)):\n",
    "    c += 1\n",
    "    driver.get(url[i])\n",
    "    time.sleep(5)\n",
    "\n",
    "    # get parameters needed for business overview function\n",
    "    response = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    business_name = response.find('h1',class_='DUwDvf lfPIob').text\n",
    "    avg_rating = response.find('div',class_='fontDisplayLarge').text\n",
    "    address = response.find('div',class_= 'rogA2c').text\n",
    "    lat_ = lat[i]\n",
    "    long_ = long[i]\n",
    "    \n",
    "    # navigate to Reviews tab\n",
    "    driver.find_element(By.CLASS_NAME, \"RWPxGd\").click()\n",
    "    time.sleep(3)\n",
    "\n",
    "    #Find the total number of reviews\n",
    "    total_number_of_reviews = driver.find_element('xpath','//*[@id=\"QA0Szd\"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div[2]/div/div[2]/div[3]').text.split(\" \")[0]\n",
    "    total_number_of_reviews = int(total_number_of_reviews.replace(',','')) if ',' in total_number_of_reviews else int(total_number_of_reviews)\n",
    "\n",
    "    total_number_of_reviews = 50\n",
    "\n",
    "    #Find scroll layout\n",
    "    scrollable_div = driver.find_element('xpath','//*[@id=\"QA0Szd\"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]')\n",
    "\n",
    "    #Scroll as many times as necessary to load all reviews - 10 reviews shown at a time\n",
    "    for i in range(0,(round(total_number_of_reviews/10 - 1))):\n",
    "        driver.execute_script('arguments[0].scrollTop = arguments[0].scrollHeight', scrollable_div)\n",
    "        time.sleep(1)\n",
    "\n",
    "    # #parse HTML and Data Extraction\n",
    "    # loop over the number of reviews \n",
    "    next_item = driver.find_elements('xpath','//*[@id=\"QA0Szd\"]/div/div/div[1]/div[2]/div/div[1]/div/div/div[2]/div[9]/div[1]/div/div')\n",
    "    time.sleep(3)\n",
    "\n",
    "    #expand review by click on 'more' button\n",
    "    for i in next_item:\n",
    "        button = i.find_elements(By.TAG_NAME,'button')\n",
    "        for m in button:\n",
    "            if m.text == \"More\":\n",
    "                m.click()\n",
    "        time.sleep(5)\n",
    "\n",
    "    # parse through the HTML \n",
    "    response = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "    reviews = response.find_all('div',class_ = 'jftiEf')\n",
    "\n",
    "    # define function to gather relevant data from the reviews result set obtained by parsing through HTML\n",
    "    def get_review_summary(result_set):\n",
    "            rev_dict = {\n",
    "                'review' : [],\n",
    "                'rating' : []}\n",
    "\n",
    "            for result in result_set:\n",
    "                #review_name = result.find(class_='d4r55').text\n",
    "                review_text = result.find('span',class_='wiI7pd').text\n",
    "                review_rating = result.find(class_='kvMYJc')['aria-label']\n",
    "                review_rating = review_rating[0]\n",
    "                rev_dict['review'].append(review_text)\n",
    "                rev_dict['rating'].append(review_rating)\n",
    "            \n",
    "            import pandas as pd\n",
    "            return(pd.DataFrame(rev_dict))\n",
    "    \n",
    "    # gather relevant data using newly created function above \n",
    "    summary_df = get_review_summary(reviews)\n",
    "\n",
    "    # access the number of locations in the url list\n",
    "    df = business_Overview(business_name,avg_rating,address,lat_,long_,summary_df)\n",
    "\n",
    "    # append df to df list \n",
    "    df_list.append(df)\n",
    "\n",
    "\n",
    "#concat list of data frames into one \n",
    "spooder_df = pd.concat(df_list, ignore_index=True)\n",
    "spooder_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting spooder_df for later use (commented out because `.csv` in `Resources/`)\n",
    "spooder_df.to_csv('./Resources/spooder.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply the Sentiment Analysis Model to the Web Scrapped Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>rating</th>\n",
       "      <th>bus_id</th>\n",
       "      <th>avg_rating</th>\n",
       "      <th>bus_add</th>\n",
       "      <th>bus_city</th>\n",
       "      <th>lat</th>\n",
       "      <th>lon</th>\n",
       "      <th>sent_label</th>\n",
       "      <th>sent_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The cakes are beautiful and delicious, but you...</td>\n",
       "      <td>5</td>\n",
       "      <td>Dulce De Leche Bakery</td>\n",
       "      <td>4.7</td>\n",
       "      <td>376 Central Ave</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>40.7476428</td>\n",
       "      <td>-74.0527625</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.763528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The entire experience was excellent: well-brew...</td>\n",
       "      <td>5</td>\n",
       "      <td>Dulce De Leche Bakery</td>\n",
       "      <td>4.7</td>\n",
       "      <td>376 Central Ave</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>40.7476428</td>\n",
       "      <td>-74.0527625</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.889528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Everything was great.\\n\\nFood, service, and th...</td>\n",
       "      <td>5</td>\n",
       "      <td>Dulce De Leche Bakery</td>\n",
       "      <td>4.7</td>\n",
       "      <td>376 Central Ave</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>40.7476428</td>\n",
       "      <td>-74.0527625</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.810901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The soup is amazing. My family likes the Itali...</td>\n",
       "      <td>5</td>\n",
       "      <td>Dulce De Leche Bakery</td>\n",
       "      <td>4.7</td>\n",
       "      <td>376 Central Ave</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>40.7476428</td>\n",
       "      <td>-74.0527625</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.791038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Absolutely love Dulce de Leche Bakery in Jerse...</td>\n",
       "      <td>5</td>\n",
       "      <td>Dulce De Leche Bakery</td>\n",
       "      <td>4.7</td>\n",
       "      <td>376 Central Ave</td>\n",
       "      <td>Jersey City</td>\n",
       "      <td>40.7476428</td>\n",
       "      <td>-74.0527625</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.932732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>Absolutely amazing. We ordered  from their \"fa...</td>\n",
       "      <td>5</td>\n",
       "      <td>Texas Roadhouse</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2105 NJ-35 Suite 103</td>\n",
       "      <td>Holmdel</td>\n",
       "      <td>40.412299</td>\n",
       "      <td>-74.145973</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.650678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>546</th>\n",
       "      <td>This place’s onion rings are my comfort food (...</td>\n",
       "      <td>5</td>\n",
       "      <td>Texas Roadhouse</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2105 NJ-35 Suite 103</td>\n",
       "      <td>Holmdel</td>\n",
       "      <td>40.412299</td>\n",
       "      <td>-74.145973</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0.456376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>547</th>\n",
       "      <td>Very good chain restaurant the food is always ...</td>\n",
       "      <td>4</td>\n",
       "      <td>Texas Roadhouse</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2105 NJ-35 Suite 103</td>\n",
       "      <td>Holmdel</td>\n",
       "      <td>40.412299</td>\n",
       "      <td>-74.145973</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.725514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>548</th>\n",
       "      <td>Loaded sweet potato and the rolls are the best...</td>\n",
       "      <td>5</td>\n",
       "      <td>Texas Roadhouse</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2105 NJ-35 Suite 103</td>\n",
       "      <td>Holmdel</td>\n",
       "      <td>40.412299</td>\n",
       "      <td>-74.145973</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0.718005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>Had the bone in ribeye with onion and mushroom...</td>\n",
       "      <td>5</td>\n",
       "      <td>Texas Roadhouse</td>\n",
       "      <td>4.4</td>\n",
       "      <td>2105 NJ-35 Suite 103</td>\n",
       "      <td>Holmdel</td>\n",
       "      <td>40.412299</td>\n",
       "      <td>-74.145973</td>\n",
       "      <td>Positive</td>\n",
       "      <td>0.806610</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>550 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                review rating  \\\n",
       "0    The cakes are beautiful and delicious, but you...      5   \n",
       "1    The entire experience was excellent: well-brew...      5   \n",
       "2    Everything was great.\\n\\nFood, service, and th...      5   \n",
       "3    The soup is amazing. My family likes the Itali...      5   \n",
       "4    Absolutely love Dulce de Leche Bakery in Jerse...      5   \n",
       "..                                                 ...    ...   \n",
       "545  Absolutely amazing. We ordered  from their \"fa...      5   \n",
       "546  This place’s onion rings are my comfort food (...      5   \n",
       "547  Very good chain restaurant the food is always ...      4   \n",
       "548  Loaded sweet potato and the rolls are the best...      5   \n",
       "549  Had the bone in ribeye with onion and mushroom...      5   \n",
       "\n",
       "                    bus_id avg_rating               bus_add      bus_city  \\\n",
       "0    Dulce De Leche Bakery        4.7       376 Central Ave   Jersey City   \n",
       "1    Dulce De Leche Bakery        4.7       376 Central Ave   Jersey City   \n",
       "2    Dulce De Leche Bakery        4.7       376 Central Ave   Jersey City   \n",
       "3    Dulce De Leche Bakery        4.7       376 Central Ave   Jersey City   \n",
       "4    Dulce De Leche Bakery        4.7       376 Central Ave   Jersey City   \n",
       "..                     ...        ...                   ...           ...   \n",
       "545        Texas Roadhouse        4.4  2105 NJ-35 Suite 103       Holmdel   \n",
       "546        Texas Roadhouse        4.4  2105 NJ-35 Suite 103       Holmdel   \n",
       "547        Texas Roadhouse        4.4  2105 NJ-35 Suite 103       Holmdel   \n",
       "548        Texas Roadhouse        4.4  2105 NJ-35 Suite 103       Holmdel   \n",
       "549        Texas Roadhouse        4.4  2105 NJ-35 Suite 103       Holmdel   \n",
       "\n",
       "            lat          lon sent_label  sent_score  \n",
       "0    40.7476428  -74.0527625   Positive    0.763528  \n",
       "1    40.7476428  -74.0527625   Positive    0.889528  \n",
       "2    40.7476428  -74.0527625   Positive    0.810901  \n",
       "3    40.7476428  -74.0527625   Positive    0.791038  \n",
       "4    40.7476428  -74.0527625   Positive    0.932732  \n",
       "..          ...          ...        ...         ...  \n",
       "545   40.412299   -74.145973   Positive    0.650678  \n",
       "546   40.412299   -74.145973    Neutral    0.456376  \n",
       "547   40.412299   -74.145973   Positive    0.725514  \n",
       "548   40.412299   -74.145973   Negative    0.718005  \n",
       "549   40.412299   -74.145973   Positive    0.806610  \n",
       "\n",
       "[550 rows x 10 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# apply Roberto to web scrapping dataframe with Google Reviews\n",
    "roberto_df = apply_roberto(spooder_df,'review')\n",
    "roberto_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exporting roberto_df for later use (commented out because `.csv` in `Resources/`)\n",
    "roberto_df.to_csv('./Resources/roberto.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The general sentiment is highly positive, with an average confidence of 75.4%.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run function to get general sentiment per business to be used as input into chatgpt model \n",
    "general_sentiment_web_scrapping = general_sentiment(roberto_df, 'bus_id', 'Dulce de Leche Bakery', 'sent_label', 'sent_score')\n",
    "general_sentiment_web_scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['55 W Palisade Ave:\\nAwesome bakery right in the heart of Englewood. They are very busy, especially on weekends and holidays, but the staff keep the line moving quickly. All of their pastries are delicious, and their coffee is just right. The inside of the establishment is quite beautiful as well, with a minimalist open air decor and aesthetic. Highly recommend a visit!\\n\\n',\n",
       " '55 W Palisade Ave:\\nLove! Love! Love! My favorite bakery! The cakes (slice or whole) is always so fresh and delicious! I order the Dulce De Leche Chantilly Cake Slice and it’s honestly omg. The top frosting tastes like hot chocolate. The chocolate cake is …\\n\\n',\n",
       " \"55 W Palisade Ave:\\nThis place gets crazy! This place is spacious and gets busy quickly. The staff is awesome and professional. They definitely try to get you out in advance. They have all kinds I'd pastries and they make cakes. I ordered chicken empanadas and …\\n\\n\",\n",
       " '55 W Palisade Ave:\\nThe cake was beautiful and delicious! Perfect for the  Birthday theme!🤩 The staff were very helpful and friendly. The lady that helped me with the cake order was great 😊 The delivery driver was also very helpful and responsible. He send me pictures of the cake after it was delivered. They are highly recommended! …\\n\\n',\n",
       " '55 W Palisade Ave:\\nLegendary Dulce de leche has a branch in englewood.. it’s a nice bakery with v v positive vibes and very popular for their sweet and savory treats .. the cakes are very different and very flavorful.. I love the coffee, tiramisu and the …\\n\\n',\n",
       " '55 W Palisade Ave:\\nIt’s not expensive, but the taste is satisfying.  Sandwiches in the refrigerator were perfect for taking out for a snack after picnics, lunch, and kids’ outdoor activities. But the attitude of the cashier needs to something change.\\n\\n',\n",
       " '55 W Palisade Ave:\\nEverything I had from here was absolutely delicious - the pastries were flakey and buttery and all the fillings were just as good, the coffee and fresh juices are a delight as well. The staff works quickly and the seating area is spacious …\\n\\n',\n",
       " '55 W Palisade Ave:\\nI was impressed by how popular the cafe is on a Sunday morning, it had at least 40 people sitting and 20 in line, showing how popular it is! It was SO DELICIOUS the tres leches cake , liked the turkey sandwich and a smoothie too\\n\\n',\n",
       " '55 W Palisade Ave:\\nDelicious deserts and baked goods here. I ordered the sandwich 🥪 in my picture. I forgot what it’s called. I think it’s originally the ham and cheese, but I customized it to just spinach, cheese and tomatoes 🍅. For drink I ordered their green drink. It comes with spinach, cucumber 🥒, 🍋, ginger \\U0001fada, and 🍏 green apple. …\\n\\n',\n",
       " '55 W Palisade Ave:\\nThis place is out of control, breakfast for two with coffee and a sweet is literally $14.. would be triple anywhere else. Fun stuff to try\\n\\n']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# run function to add all reviews of a given business as a list\n",
    "review_list = reviews_list(roberto_df, 'bus_id', 'Dulce de Leche Bakery', 'bus_add', 'review')\n",
    "review_list[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Reviews from Selected Business to run ChatGPT Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables.\n",
    "load_dotenv()\n",
    "\n",
    "# Set the model name for our LLMs.\n",
    "OPENAI_MODEL = \"gpt-3.5-turbo\"\n",
    "# Store the API key in a variable.\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.11/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use RunnableSequence, e.g., `prompt | llm` instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      "The reviews for 55 W Palisade Ave highlight the bakery's delicious pastries, cakes, and coffee, along with its beautiful decor and efficient staff. Customers praise the variety of offerings, reasonable prices, and friendly service. However, some reviewers mention issues with service quality, cleanliness, and hair found in food. Overall, the bakery is popular and well-loved for its tasty treats and welcoming atmosphere.\n",
      "\n",
      "Recommendations for Improvement:\n",
      "1. Enhance Service Quality: Address issues with lazy service, improve staff attentiveness, and ensure a positive customer experience.\n",
      "2. Maintain Cleanliness: Take steps to ensure food hygiene and cleanliness standards are consistently met to avoid negative experiences.\n",
      "3. Address Food Quality Concerns: Pay attention to details like egg shells in sandwiches and ensure all food items are prepared and served to high standards.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model.\n",
    "llm=ChatOpenAI(openai_api_key=OPENAI_API_KEY, model_name=OPENAI_MODEL, temperature=0.3)\n",
    "\n",
    "# Define the format for the template.\n",
    "format = \"\"\"\n",
    "\n",
    "Provide a summary of the given reviews:{review_list} and three ways in which to improve the business. The summary should capture the main points and key details of the text \n",
    "while conveying the author's intended meaning accurately. The recommendations should be actionable, clear and conscise. Please ensure that the summary is well-organized and easy to read, \n",
    "with clear headings and subheadings to guide the reader through each section. The length of the summary should be appropriate to capture the main points and key details of the text, \n",
    "without including unnecessary information or becoming overly long.\n",
    "\n",
    "reviews = {review_list}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Construct the prompt template.\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"review_list\"],\n",
    "    template=format\n",
    ")\n",
    "\n",
    "# Construct a chain using this template.\n",
    "chain = LLMChain(llm=llm, prompt=prompt_template)\n",
    "\n",
    "# Define the input variable as a dictionary\n",
    "review_list = {\"review_list\": review_list}\n",
    "\n",
    "# Run the chain using the query as input and get the result.\n",
    "result = chain.invoke(review_list)\n",
    "results = result[\"text\"]\n",
    "\n",
    "# split the results by new lines to extract review summary and business recommendations\n",
    "results_list = results.split('\\n')\n",
    "reviews_summary = results_list[1]\n",
    "recommendations = results_list[4]\n",
    "\n",
    "\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions (Pt 3)\n",
    "\n",
    "While trained on Yelp! data, and developed for Google Reviews, the goal of the application is to be as univerally applicable to business reviews as possible - regardless of the source. The following functions were developed with their annotated purposes in mind:\n",
    "\n",
    "| **Function** | **Notes** |\n",
    "| :--- | :---|\n",
    "| `unique_locs_df()` | Creates a DataFrame with all unique locations in a given dataset |\n",
    "| `location_details()` | Generates a dictionary with geographic coordinates for all locations of a given business <br> *Note: To be run on the DataFrame generated by* `unique_locs_df()` |\n",
    "| `build_map()` | Constructs a Scattermapbox based on the locations from `location_details()` |\n",
    "| `apply_davidlingo()` | Generates the final summary of a business' reviews, or recommendations for improvement based off the reviews and overall sentiment <br> *Note: To be used with the ouputs of* `reviews_list()` *and* `general_sentiment()` |\n",
    "\n",
    "Each function outlined in more detail below requires a DataFrame with the following features:\n",
    "\n",
    "| **Feature** | **Notes** |\n",
    "| :--- | :--- |\n",
    "| `bus_name_col` | A text column with the name of a business |\n",
    "| `bus_add` | A text column with the street address of a business' location |\n",
    "| `bus_lat` | A float column with the latitude coordinate for a business' location |\n",
    "| `bus_lon` | A float column with the longitude coordinate for a business' location |\n",
    "| `rev_col` | A text column with available reviews |\n",
    "| `sent_lbl` | A text column with the generated sentiment classification <br> *Note: Generated through* `apply_roberto()` |\n",
    "| `sent_scr` | A text column with the generated sentiment classification <br> *Note: Generated through* `apply_roberto()` |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to retrieve unique business locations\n",
    "def unique_locs_df(df, bus_name_col, bus_add, bus_lat, bus_lon):\n",
    "    '''\n",
    "    Gathers unique adresses and coordinates for unique locations into a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame):     Any DataFrame with sufficient data.\n",
    "        bus_name_col (str): A string with the feature name that contains the business name.\n",
    "        bus_add (str):      A string with the feature name that contains the business street address.\n",
    "        bus_lat (str):      A string with the feature name that contains the latitude of a location.\n",
    "        bus_lon (str):      A string with the feature name that contains the longitude of a location.\n",
    "    \n",
    "    Returns:\n",
    "        loc (DataFrame):    A DataFrame with only unique locations.\n",
    "\n",
    "    Raises:\n",
    "        KeyError:           If any passed str is not a valid column name in the DataFrame.\n",
    "        TypeError:          If `df` is not a DataFrame or if and feature is not a string.\n",
    "    '''\n",
    "    # Raises\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError('The input `df` must be a pandas DataFrame.')\n",
    "    for param, name in zip(\n",
    "        [bus_name_col, bus_add, bus_lat, bus_lon],\n",
    "        ['bus_name_col', 'bus_add', 'bus_lat', 'bus_lon']\n",
    "    ):\n",
    "        if not isinstance(param, str):\n",
    "            raise TypeError(f\"The '{name}' parameter must be passed as a string.\")\n",
    "        if param not in df.columns:\n",
    "            raise KeyError(f\"Column '{param}' not found in DataFrame.\")\n",
    "    \n",
    "    # Generating a DataFrame of unique locations\n",
    "    locs = df[[bus_name_col, bus_add, bus_lat, bus_lon]].drop_duplicates()\n",
    "    \n",
    "    # Returning the DataFrame\n",
    "    return locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate a `locations` list of dictionaries\n",
    "def location_details(df, bus_name_col, bus_name, bus_add, bus_lat, bus_lon):\n",
    "    '''\n",
    "    Transfers the latitude, longitude, and a concatenated identifier into a dictionary for later use in generating a Scattermapbox figure.\n",
    "\n",
    "    Note:\n",
    "        Advised to run `location_details()` on the DataFrame generated by `unique_locs_df()`\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame):     Any DataFrame with sufficient data.\n",
    "        bus_name_col (str): A string with the feature name that contains the business name.\n",
    "        bus_name (str):     A string of a specific business' name for which to map the locations.\n",
    "        bus_add (str):      A string with the feature name that contains the business street address.\n",
    "        bus_lat (str):      A string with the feature name that contains the latitude of a location.\n",
    "        bus_lon (str):      A string with the feature name that contains the longitude of a location.\n",
    "\n",
    "    Returns:\n",
    "        locs (dict):        A list of dictionaries with the necessary details for building a figure.\n",
    "    \n",
    "    Raises:\n",
    "        KeyError:           If any passed str is not a valid column name in the DataFrame.\n",
    "        TypeError:          If `df` is not a DataFrame or if and feature is not a string.\n",
    "        ValueError:         If `bus_name` is not a value in `bus_col_name`.\n",
    "    '''\n",
    "    # Raises\n",
    "    if not isinstance(df, pd.DataFrame):\n",
    "        raise TypeError('The input `df` must be a pandas DataFrame.')\n",
    "    for param, name in zip(\n",
    "        [bus_name_col, bus_add, bus_lat, bus_lon],\n",
    "        ['bus_name_col', 'bus_add', 'bus_lat', 'bus_lon']\n",
    "    ):\n",
    "        if not isinstance(param, str):\n",
    "            raise TypeError(f\"The '{name}' parameter must be passed as a string.\")\n",
    "        if param not in df.columns:\n",
    "            raise KeyError(f\"Column '{param}' not found in DataFrame.\")\n",
    "    if bus_name not in df[bus_name_col].values:\n",
    "        raise ValueError(f\"'{bus_name}' not found in column '{bus_name_col}'.\")\n",
    "    \n",
    "    # Creating a list of features to retain\n",
    "    retain = [bus_name_col, bus_add, bus_lat, bus_lon]\n",
    "\n",
    "    # Filtering `df`\n",
    "    filtered_df = df[retain][df[bus_name_col] == bus_name].copy()\n",
    "\n",
    "    # Intializing a `name` feature\n",
    "\n",
    "    # Creating a concatenated `name` feature with a business' name and location address\n",
    "    filtered_df['loc_name'] = filtered_df[bus_name_col] + ' - ' + filtered_df[bus_add]\n",
    "\n",
    "    # Renaming features\n",
    "    filtered_df.rename(columns={bus_lat: 'lat', bus_lon: 'lon'}, inplace=True)\n",
    "\n",
    "    # Dropping features\n",
    "    filtered_df.drop([bus_name_col, bus_add], axis=1, inplace=True)\n",
    "\n",
    "    # Converting `filtered_df` to a dictionary\n",
    "    locs = filtered_df.to_dict('records')\n",
    "\n",
    "    # Returning list of dictionaries\n",
    "    return locs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to build a map\n",
    "def build_map(locs):\n",
    "    '''\n",
    "    Generates and updates a Scattermapbox figure based on the location details previously generated.\n",
    "\n",
    "    Note:\n",
    "        To be run on the dictionary returned by `location_details()`.\n",
    "\n",
    "    Args:\n",
    "        locs (dict):    A dictionary containing the latitude and longitude coordinates, as well as the business name and street address, of all given locations for that business.\n",
    "    \n",
    "    Returns:\n",
    "        fig (fig):      A Scattermapbox formated to an appropriate zoom level and centered on all given locations for a business.\n",
    "    \n",
    "    Raises:\n",
    "        TypeError:      If `locs` is not a list of dictionaries, or if the dictionaries do not contain the expected keys.\n",
    "        KeyError:       If any of the expected keys are missing from the dictionaries.\n",
    "        ValueError:     If `locs` is empty, or if latitude and longitude values are not valid numbers.\n",
    "    '''\n",
    "    # Raises\n",
    "    if not isinstance(locs, list) or not all(isinstance(loc, dict) for loc in locs):\n",
    "        raise TypeError(\"`locs` must be a list of dictionaries.\")\n",
    "    required_keys = {'lat', 'lon', 'loc_name'}\n",
    "    for loc in locs:\n",
    "        if not required_keys.issubset(loc):\n",
    "            raise KeyError(f\"Each dictionary in `locs` must contain the keys: {required_keys}.\")\n",
    "    if not locs:\n",
    "        raise ValueError(\"`locs` cannot be an empty list.\")\n",
    "\n",
    "    # Generating location text\n",
    "    hover_text = [loc['loc_name'] for loc in locs]\n",
    "\n",
    "    # Generating location lat and lon\n",
    "    lat_loc = [loc['lat'] for loc in locs]\n",
    "    lon_loc = [loc['lon'] for loc in locs]\n",
    "\n",
    "    # Calculating middle point for lat and lon\n",
    "    lat_mean = sum(lat_loc)/len(lat_loc)\n",
    "    lon_mean = sum(lon_loc)/len(lon_loc)\n",
    "\n",
    "    # Calculating borders of locatoins\n",
    "    lat_min, lat_max = min(lat_loc), max(lat_loc)\n",
    "    lon_min, lon_max = min(lon_loc), max(lon_loc)\n",
    "\n",
    "    # Calculating size of borders\n",
    "    lat_diff = lat_max - lat_min\n",
    "    lon_diff = lon_max - lon_min\n",
    "\n",
    "    # Using `log()` to scale zoom based on distances at slower rates for larger geographic areas\n",
    "    zoom = min(7 - math.log(lat_diff + 0.1), 7 - math.log(lon_diff + 0.1))\n",
    "\n",
    "    # Creating the map figure\n",
    "    fig = go.Figure(go.Scattermapbox(\n",
    "        lat=lat_loc,\n",
    "        lon=lon_loc,\n",
    "        mode='markers',\n",
    "        hovertext=hover_text,\n",
    "        marker=dict(size=10)\n",
    "    ))\n",
    "\n",
    "    # Updating layout with map style and properties\n",
    "    fig.update_layout(\n",
    "        mapbox={\n",
    "            'style': 'open-street-map',\n",
    "            'center': {'lon': lon_mean, 'lat': lat_mean},\n",
    "            'zoom': zoom\n",
    "        },\n",
    "        margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0},\n",
    "        height=500\n",
    "    )\n",
    "\n",
    "    # Returning figure\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate OpenAI summary or recommendations\n",
    "def apply_davidlingo(gen_sent, reviews):\n",
    "    '''\n",
    "    Assesses the general sentiment and reviews for a given business to then conditionally output either summary of positive reviews, or recommendations based on neutral or negative reviews.\n",
    "\n",
    "    Note:\n",
    "        To be run after `apply_roberto()`, `general_sentiment()`, and `reviews_list()`.\n",
    "    '''\n",
    "    # Raises\n",
    "    \n",
    "    # Placeholder\n",
    "    gen_sent = gen_sent\n",
    "    reviews = reviews\n",
    "\n",
    "    # Placeholder\n",
    "    rev_recs = 'This is a placeholder for applying a final text object generated by an OpenAI LangChain.'\n",
    "    # Return final summary or recommendations\n",
    "    return rev_recs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **SpooderApp™**\n",
    "\n",
    "With `roberto` and `davidlingo` at the ready, it was time to build them a home. It was time... for `SpooderApp™`!\n",
    "\n",
    "`SpooderApp™`, developed in __[Dash](https://dash.plotly.com/)__, is the interactive medium through which users will interact with our models directly. With data scraped from our curated list of businesses, we set out to build `SpooderApp™` as a demonstrative tool to prove our hypothesis correct. That yes, we *can* leverage reviews into accurate sentiment analysis and actionable feedback for businesses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Temporary Components;\n",
    "\n",
    "To prepare `SpooderApp™`'s loading state, a few components needed to be etablished prior to initializing the interface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Map\n",
    "\n",
    "*Loading the map on the US map because, well... We're largely american students, so it made sense?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a default map centered on the US\n",
    "fig_placeholder = go.Figure(go.Scattermapbox())\n",
    "fig_placeholder.update_layout(\n",
    "    mapbox={\n",
    "        'style': \"open-street-map\",\n",
    "        'center': {'lon': -98.583, 'lat': 39.833},\n",
    "        'zoom': 2.5\n",
    "    },\n",
    "    margin={\"r\":0,\"t\":0,\"l\":0,\"b\":0},\n",
    "    height=400\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DataFrame\n",
    "\n",
    "*Making the interchanging of datasets simple without needed to refactor the app, itself*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Declare a DataFrame to be used for the app\n",
    "app_df = roberto_df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### List of business names\n",
    "\n",
    "*For user input selection*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating list of business names\n",
    "drop_opts = business_names_list(app_df, 'bus_id') # Replace args with live data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Location details\n",
    "\n",
    "*For making the rest of the code below easier*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame of uniqur locations\n",
    "uniq_locs = unique_locs_df(app_df, 'bus_id', 'bus_add', 'bus_lat', 'bus_lon') # Replace args with live data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## App Development;\n",
    "\n",
    "The stage was set, the players at the ready... It was time for `SpooderApp™` to truly shine.\n",
    "\n",
    "*Note: While a monstrous cell, all components of* `SpooderApp™` *were developed in once cell for simplicity and consistency's sake.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize app\n",
    "app = Dash(external_stylesheets=[dbc.themes.QUARTZ])\n",
    "\n",
    "# Loading markdown content for guide\n",
    "with open('Resources/SpooderApp_Guide.md', 'r') as file:\n",
    "    guide_content = file.read()\n",
    "\n",
    "# App layout\n",
    "app.layout = html.Div([\n",
    "    # Wrapping the whole GUI in a stack for uinform formatting\n",
    "    dbc.Stack(\n",
    "        [\n",
    "            # Blank col for spacing (1/12 of parent container)\n",
    "            dbc.Col('', width=1),\n",
    "            # Col with all of GUI\n",
    "            dbc.Col(\n",
    "                [\n",
    "                    # Row for header\n",
    "                    dbc.Row(\n",
    "                        # Header (as is evident by the `H1` method)\n",
    "                        html.H1(\n",
    "                            # Does whatever a SpooderApp™ can\n",
    "                            'SpooderApp™',\n",
    "                            # Placing in the middle of the page\n",
    "                            style={'textAlign':'center'}\n",
    "                        ),\n",
    "                        # Give us some room, please\n",
    "                        style={'margin-top': '20px', 'margin-bottom': '20px'}\n",
    "                    ),\n",
    "                    # Row for subheader\n",
    "                    dbc.Row(\n",
    "                        # Subheader (as is less evident by the `H3` method)\n",
    "                        html.H3(\n",
    "                            # Taglines are important\n",
    "                            'Leveraging business reviews to gain insights for potential improvements.',\n",
    "                            # Placing in the middle of the page\n",
    "                            style={'textAlign':'center'}\n",
    "                        ),\n",
    "                        # Buffer space\n",
    "                        style={'margin-bottom': '20px'}\n",
    "                    ),\n",
    "                    # Row for business name and ratings\n",
    "                    dbc.Row(\n",
    "                        [\n",
    "                            # Col for user input\n",
    "                            dbc.Col(\n",
    "                                # InputGroup for user input\n",
    "                                dbc.InputGroup(\n",
    "                                    [\n",
    "                                        # Dropdown menu for user input\n",
    "                                        dbc.DropdownMenu(\n",
    "                                            # Instructions for user input\n",
    "                                            label = 'Select a business',\n",
    "                                            # To know it's user input\n",
    "                                            id = 'business_dropdown',\n",
    "                                            # Selections for user input\n",
    "                                            children = [\n",
    "                                                dbc.DropdownMenuItem(\n",
    "                                                    name,\n",
    "                                                    id=f\"menu_item_{i}\",\n",
    "                                                    style={'color': 'grey'}\n",
    "                                                ) for i, name in enumerate(drop_opts)\n",
    "                                            ],\n",
    "                                            # Making it pretty ([insert sparkles here])\n",
    "                                            class_name='btn-info'\n",
    "                                        ),\n",
    "                                        # Not actually user input, but reflects it\n",
    "                                        dbc.InputGroupText(\n",
    "                                            # Blank until user input selected\n",
    "                                            children='',\n",
    "                                            # To know where to put user input\n",
    "                                            id='chld_nm',\n",
    "                                            # Making it pretty, but not AS pretty\n",
    "                                            class_name='form-control'\n",
    "                                        )\n",
    "                                    ],\n",
    "                                    # Be tall, but only so tall, please\n",
    "                                    style={'width': '100%', 'height': '60px'}\n",
    "                                ),\n",
    "                                # 6/12 of parent container, because math\n",
    "                                width=6\n",
    "                            ),\n",
    "                            # Col for average rating information\n",
    "                            dbc.Col(\n",
    "                                # Card display for averate rating information\n",
    "                                dbc.Card(\n",
    "                                    # Blank until user input selected\n",
    "                                    children='',\n",
    "                                    # To know where to put average rating information\n",
    "                                    id='avg_rtng',\n",
    "                                    # Making it pretty-ish\n",
    "                                    body=True,\n",
    "                                    # Be no taller than the column to your left\n",
    "                                    style={\n",
    "                                        'width': '100%',\n",
    "                                        'height': '60px',\n",
    "                                        'display': 'flex',\n",
    "                                        'align-items': 'left',\n",
    "                                        'justify-content': 'center'\n",
    "                                    }\n",
    "                                ),\n",
    "                                # 3/12 of parent container, or 1/4 but HTML/CSS doesn't like quarters as much\n",
    "                                width=3\n",
    "                            ),\n",
    "                            # Column for total reviews information\n",
    "                            dbc.Col(\n",
    "                                # Card display for total reviews information\n",
    "                                dbc.Card(\n",
    "                                    # Blank until user input selected\n",
    "                                    children='',\n",
    "                                    # To know where to put total reviews information\n",
    "                                    id='tot_rvws',\n",
    "                                    # Making it pretty-ish like its sibling to the left\n",
    "                                    body=True,\n",
    "                                    # You must be this short to display\n",
    "                                    style={\n",
    "                                        'width': '100%',\n",
    "                                        'height': '60px',\n",
    "                                        'display': 'flex',\n",
    "                                        'align-items': 'left',\n",
    "                                        'justify-content': 'center'\n",
    "                                    }\n",
    "                                ),\n",
    "                                # 3/12 of parent container, beacuse 12 - 6 - 3 leaves 3\n",
    "                                width=3\n",
    "                            )\n",
    "                        ],\n",
    "                        # Usually a good place to begin - The beginning\n",
    "                        justify='start',\n",
    "                        # Matching buffer space for that glossy, uniform look ([more sparkles])\n",
    "                        style={'margin-bottom': '20px'},\n",
    "                    ),\n",
    "                    # \"Row\" for map and accordion\n",
    "                    dbc.Stack(\n",
    "                        [\n",
    "                            # Col for map\n",
    "                            dbc.Col(\n",
    "                                # Map\n",
    "                                dcc.Graph(figure=fig_placeholder, id='bus_map'),\n",
    "                                # 5/12 of parent container, because the map wanted to be special\n",
    "                                width=5\n",
    "                            ),\n",
    "                            # Col for accordion\n",
    "                            dbc.Col(\n",
    "                                # Unfortunately, an accodion menu, not a Weird Al cameo\n",
    "                                dbc.Accordion(\n",
    "                                    [\n",
    "                                        # Menu item for reviews\n",
    "                                        dbc.AccordionItem(\n",
    "                                            # Paragraph - in the loosest sense - for reviews\n",
    "                                            html.P(\n",
    "                                                # To know where to put the reviews\n",
    "                                                id='reviews',\n",
    "                                                # Blank until user input selected\n",
    "                                                children='',\n",
    "                                                # Only be so tall, and scroll if longer\n",
    "                                                style={'max-height': '295px', 'overflow-y': 'auto'}\n",
    "                                            ),\n",
    "                                            # So you know it's got the reviews in it\n",
    "                                            title='Reviews'\n",
    "                                        ),\n",
    "                                        # Menu item for sentiment analysis\n",
    "                                        dbc.AccordionItem(\n",
    "                                            html.P(\n",
    "                                                # To know where to put the sentiment analysis\n",
    "                                                id='sentiment',\n",
    "                                                # Blank until user input selected\n",
    "                                                children='',\n",
    "                                                # Overkill, since this will only ever be a single line of text\n",
    "                                                style={'max-height': '295px', 'overflow-y': 'auto'}\n",
    "                                            ),\n",
    "                                            # To identify it as the container for the sentiment analysis\n",
    "                                            title='Sentiment Analysis'\n",
    "                                        ),\n",
    "                                        # Menu item for recommendations\n",
    "                                        dbc.AccordionItem(\n",
    "                                            html.P(\n",
    "                                                # To know where to put the OpenAI feedback\n",
    "                                                id='feedback',\n",
    "                                                # Blank until user input selected\n",
    "                                                children='',\n",
    "                                                # Only be so tall, and scroll if longer\n",
    "                                                style={'max-height': '295px', 'overflow-y': 'auto'}\n",
    "                                            ),\n",
    "                                            # For the purposes of labeling it as the recepticle for feedback\n",
    "                                            title='Feedback'\n",
    "                                        )\n",
    "                                    ]\n",
    "                                ),\n",
    "                                # Again, a good palce to begin\n",
    "                                align='start',\n",
    "                                # 7/12 of parent container, because that's what was left and it looks good\n",
    "                                width=7\n",
    "                            )\n",
    "                        ],\n",
    "                        # That's what was meant by \"row\", earlier - go this way <-->\n",
    "                        direction='horizontal',\n",
    "                        # Little bit of breathing room in there, too, please\n",
    "                        gap=1\n",
    "                    ),\n",
    "                    # Row for markdown guide\n",
    "                    dbc.Row(\n",
    "                        # Markdown guide\n",
    "                        dcc.Markdown(\n",
    "                            # Content for the markdown guide\n",
    "                            guide_content,\n",
    "                            # Making the markdown guide pretty\n",
    "                            style={\n",
    "                                'margin-top': '50px',\n",
    "                                'padding': '20px',\n",
    "                                'background-color': 'rgba(255, 255, 255, 0.35)', # This one is super important!\n",
    "                                'border-radius': '10px'\n",
    "                            }\n",
    "                        )\n",
    "                    )\n",
    "                ],\n",
    "                # 10/12 of parent container, because this really is the star of the show, right here\n",
    "                width=10\n",
    "            ),\n",
    "             # Blank col for spacing (1/12 of parent container)\n",
    "            dbc.Col('', width=1),\n",
    "        ],\n",
    "        # Another go this way <--> bit\n",
    "        direction='horizontal',\n",
    "        # We like negative space, let's have more of that between things\n",
    "        gap=1\n",
    "    )\n",
    "])\n",
    "\n",
    "# Callback to populate the `DropdownMenu`\n",
    "@callback(\n",
    "    Output('chld_nm', 'children'),\n",
    "    Output('avg_rtng', 'children'),\n",
    "    Output('tot_rvws', 'children'),\n",
    "    Output('bus_map', 'figure'),\n",
    "    Output('reviews', 'children'),\n",
    "    Output('sentiment', 'children'),\n",
    "    Output('feedback', 'children'),\n",
    "    [Input(f\"menu_item_{i}\", \"n_clicks\") for i in range(len(drop_opts))],\n",
    "    [State(f\"menu_item_{i}\", \"children\") for i in range(len(drop_opts))]\n",
    ")\n",
    "def update_content(*args):\n",
    "    # Default states for elements\n",
    "    load_input = 'Use the dropdown menu on the left'\n",
    "    load_avg_rtng = 'Average Rating: '\n",
    "    load_tot_rvws = 'Total Available Reviews: '\n",
    "    load_fig = fig_placeholder\n",
    "    load_revs = 'Select a business to see reviews.'\n",
    "    load_sent = 'Select a business to generate sentiment analysis.'\n",
    "    load_rev_rec = 'Select a business to generate dynamic feedback.'\n",
    "\n",
    "    # Confirming a dropdown selection has been made\n",
    "    ctx = callback_context\n",
    "    if ctx.triggered:\n",
    "        # Finding which business was clicked\n",
    "        selected_item_id = ctx.triggered[0]['prop_id'].split('.')[0]\n",
    "        # Finding the index of the clicked business\n",
    "        selected_index = int(selected_item_id.split('_')[-1])\n",
    "        # Getting the selected business name\n",
    "        selected_business = args[len(drop_opts) + selected_index]\n",
    "\n",
    "        # Getting the average rating for the selected business\n",
    "        # NOTE: Since `avg_rating` is stores on a per-business basis,\n",
    "        # not a per-record basis, the first record's value will suffice\n",
    "        rvw_avg = app_df.loc[app_df['bus_id'] == selected_business, 'avg_rating'].iloc[0]\n",
    "        # Returning the average rating value\n",
    "        avg_rtng = f'Average Rating: {rvw_avg:.1f}'\n",
    "\n",
    "        # Gathering the reviews for the selected business\n",
    "        reviews = reviews_list(app_df, 'bus_id', selected_business, 'bus_add', 'review')\n",
    "        # Calculating the total number of reviews\n",
    "        if len(reviews) >= 1:\n",
    "            # If 1 or more, returning a count of available reviews\n",
    "            rev_tot = f'Total Available Reviews: {len(reviews)}'\n",
    "            # Preparing an empty list\n",
    "            rev_list = []\n",
    "            # Appending each review into `rev_list` with HTML formatting\n",
    "            for rev in reviews:\n",
    "                rev_list.append(html.P([rev.split(':\\n')[0], ':', html.Br(), rev.split(':\\n')[1], html.Br()]))\n",
    "        else:\n",
    "            rev_tot = 'Total Available Reviews: 0'\n",
    "            rev_list = 'Too few reviews available to display.'\n",
    "\n",
    "        # Preparing location details for the selected business\n",
    "        locations = location_details(uniq_locs,'bus_id', selected_business, 'bus_add','bus_lat', 'bus_lon')\n",
    "        # Building map based on locations for the selected business\n",
    "        fig = build_map(locations)\n",
    "\n",
    "        # Gather the general sentiment for the selected business\n",
    "        gen_sent = general_sentiment(app_df, 'bus_id', selected_business, 'sentiment', 'accuracy')\n",
    "\n",
    "        # Generate OpenAI response\n",
    "        rev_rec = apply_davidlingo(gen_sent, reviews)\n",
    "\n",
    "        # Returning the label corresponding to the clicked item\n",
    "        return selected_business, avg_rtng, rev_tot, fig, rev_list, gen_sent, rev_rec\n",
    "    # Returning original placeholder text if none selected\n",
    "    return load_input, load_avg_rtng, load_tot_rvws, load_fig, load_revs, load_sent, load_rev_rec\n",
    "\n",
    "# Launch app (in browser tab) (comment out if running in notebook)\n",
    "app.run(jupyter_mode='tab')\n",
    "# Launch app (in notebook) (uncomment to run)\n",
    "# app.run_server(debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Final Thoughts**\n",
    "\n",
    "Any final notes go here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Citations**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Yelp Open Dataset\n",
    "\n",
    "Yelp Inc. (2021). Yelp Open Dataset. Retrieved from __[https://www.yelp.com/dataset](https://www.yelp.com/dataset)__\n",
    "\n",
    "This project utilizes the Yelp Open Dataset. The findings presented here have been submitted to Yelp for review and approval in accordance with the dataset's terms of use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai_dev",
   "language": "python",
   "name": "ai_dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
